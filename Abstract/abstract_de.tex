\addcontentsline{toc}{chapter}{Deutsche Zusammenfassung}
%\addcontentsline{toc}{chapter}{Acknowledgements}

\begin{abstract}
    %\centerline{\textit{``Towards Explainable Cancer Prognosis and Prediction Based on Neuro-symbolic
    %Learning and Reasoning''}}
    %\centerline{Md. Rezaul Karim}
    \small{
        \textbf{Hintergrund}: Deep Learning auf der Grundlage neuronaler Netze~(DNN) hat sich bei der automatisierten Entscheidungsfindung in zahlreichen Bereichen als äußerst erfolgreich erwiesen. Aufgrund der verschachtelten, nichtlinearen und komplexen Struktur sind DNN-Architekturen jedoch meist undurchsichtig und werden daher als ``Black-Box''-Methoden angesehen. Sie weisen nicht nur einen Mangel an Transparenz auf, sondern können auch zugrunde liegende Entscheidungen nicht begründen. Eine solche Undurchsichtigkeit wirft zahlreiche rechtliche, ethische und praktische Bedenken auf. KI-basierte Systeme wurden bereits in zahlreichen Bereichen wie der automatisierten Diagnose, und Behandlung im klinischen Umfeld eingesetzt. Wenn es uns jedoch nicht möglich ist zu erklären, wie eine klinische Entscheidung zustande kommt, können wir auch die Auswirkungen auf einen Patienten nicht schlecht abschätzen. Und der Tag, an dem solche KI-gesteuerten Systeme Lebensentscheidungen für den Menschen treffen werden, ist nicht sehr weit voraus. Krebs ist eine der weltweit tödlichsten Krankheiten. Sie wird durch abnormales Verhalten von Genen verursacht, welche die Zellteilung und das Zellwachstum kontrollieren. Da eine Krebsdiagnose von der genauen Vorhersage eines Krebstyps abhängt, ist eine genaue Analyse von Genomdaten und anderer klinischer Ergebnisse entscheidend, bevor eine Behandlung empfohlen werden. Die Analyse solcher Daten kann tiefgreifende Erkenntnisse über genetische Prädispositionen liefern und helfen den Krebs möglichst frühzeitig zu erkennen. Darüber hinaus besteht laut DSGVO ein ``Recht auf Erklärung'', welches die ``algorithmische Transparenz'' durchsetzt - das Recht des Patienten zu wissen warum und wie eine Entscheidung durch ein Entscheidungsunterstützungssystem~(DSS) getroffen wird. In diesem Fall, kann das Verfahren der neurosymbolischen Schlussfolgerung~(NSR) entsprechende Einblicke in die Entscheidungsgründe ermöglichen. 
        
        \vspace{1mm}
        \textbf{Motivations}: Einer der wichtigsten Unterschiede zwischen Maschinellem Lernen~(ML) und SR ist die Art und Weise der Lernens: Ein Lernalgorithmus lernt Regeln, um Korrelationen zwischen Eingangs- und Ausgangswerten herzustellen, bei SR hingegen werden die Regeln durch menschliche Eingaben erzeugt. Um ein erklärbares KI~(XAI)-System zu entwickeln, müssen die Beziehungen zwischen Phänomenen zunächst von Menschen in Form von Regeln beschrieben werden. Dann können diese Beziehungen in ein statisches und fest kodiertes Programm eingebettet werden. Die vom Menschen definierten Regel bilden dabei bestehende Expertenmeinungen ab. DNN-Architekturen befolgen hingegen ausschließlich Annahmen darüber, wie sie lernen sollten, und nicht darüber, zu welcher Schlussfolgerung sie gelangen sollen. Eine effektive Möglichkeit besteht darin die Annahmen so zu wählen, dass sie es dem System ermöglichen, möglichst flexibel zu lernen und genaue Entscheidungen über ihre Eingaben zu treffen. In diesem Fall kann die explizite Darstellung von Domänenwissen und Datenprovenienz durch die Schichten eines DNN den Weg zu XAI ebnen, bei dem Interpretierbarkeit, Entscheidungsregeln und SR eingesetzt werden, um menschlich verständliche Erklärungen zu erzeugen. Zugleich werden Verzerrungseffekte minimiert und die Fairness der Ergebnisse gesteigert. Diese Dissertation zielt auf folgendes ab: i) die Verbesserung der Erklärbarkeit, Fairness und Robustheit eines DSS durch den Einsatz von NSR und Entscheidungsregeln, ii) die Entdeckung und Verbreitung von Wissen über molekulare Mechanismen von Krebsgenenomen. 
        
        \vspace{1mm}
        
        \textbf{Methodik}: Wir trainieren verschiedene unimodale und multimodale DNN-Architekturen anhand von Genomdaten und klinischen Ergebnissen, um abstrakte Merkmale auf einer grobgranularen Ebene zu erlernen. Die Methode des neuronalen Ensembles ist effektiver als Methoden, die nur auf einem einzigen Modell basieren und werden angewandt um ein möglichst stabiles Modell zu erzeugen. Anschließend identifizieren wir Krebs-typische Schlüsselgene, indem wir klassenspezifische Regionen mit Hilfe von Class Activation Maps (Grad-CAM++) und Layer-wise Relevance Propagation (LRP) hervorheben. Darüber hinaus erzeugen wir auf Basis zuvor definierter Entscheidungsregel, entsprechende Erläuterungen für jede Entscheidung, wobei wir sowohl lokale als auch auf die globale Interpretierbarkeit einbeziehen. Um die Robustheit zu verbessern, stellen wir zudem verschiedene Arten von Angriffen auf die Modelle vor. Als Teil des SR haben wir durch Integration von Wissen und Fakten über Krebs aus externen Quellen, einen domänen-spezifischen Wissensgraphen (KG) geschaffen, der die semantische Schicht des Systems bildet. Der Reasoner charakterisiert und lernt hierarchische Beziehungen aus dem KG, und liefert Erklärungen für Vorhersagen durch die Minimierung von Vorhersageverzerrungen. Schließlich erzeugen wir faire Entscheidungsregeln, indem wir Begründungen und Vorhersagen kombinieren, um eine vertrauenswürdige die klinische Diagnose zu erzeugen.
        
        \vspace{1mm}
        
        \textbf{Results:} Ergebnisse: Quantitative und qualitative Analysen zeigen, dass unser Ansatz nicht nur eine hohe Konfidenz für die korrekte Vorhersage von Krebsarten mit einer durchschnittlichen Genauigkeit von 96,25\% aufweist, sondern auch menschlich interpretierbare Erklärungen der Vorhersagen liefert, indem er Spitzengene und Krebs-typische Schlüsselgene offenlegt. Wir hoffen, dass unser Ansatz einen nützlichen wissenschaftlicher Beitrag darstellt und zur schnelleren und sichereren Adaption von KI-unterstützten Anwendungen in der klinischen Praxis beitragen wird. 
    
    }
\end{abstract}