\addcontentsline{toc}{chapter}{Deutsche Zusammenfassung}
%\addcontentsline{toc}{chapter}{Acknowledgements}

\begin{abstract}
    %\centerline{\textit{``Towards Explainable Cancer Prognosis and Prediction Based on Neuro-symbolic
    %Learning and Reasoning''}}
    %\centerline{Md. Rezaul Karim}
    \small{
        \textbf{Hintergrund}: Deep Learning basierend auf Deep Neural Network Architectures~(DNNs) hat enorme Erfolge bei der automatisierten Entscheidungsfindung in zahlreichen Bereichen wie Industrie- und Chemieingenieurwesen, Computer Vision, Biowissenschaften, Gesundheitswesen, Finanzen, Verständnis natürlicher Sprache usw. gezeigt Für verschachtelte nichtlineare und komplexe Strukturen sind DNN-Architekturen meist undurchsichtig und werden als "Black-Box" -Methoden wahrgenommen. "Black-Box" -Modelle sind nicht nur nicht interpretierbar und transparent, sondern können auch nicht über ihre zugrunde liegenden Entscheidungen nachdenken. Darüber hinaus wirft diese Undurchsichtigkeit auch zahlreiche rechtliche, ethische und praktische Bedenken auf. Auf künstlicher Intelligenz~(KI) basierende Systeme wurden bereits für kritische Entscheidungen im Gesundheitswesen wie automatisierte Diagnosen, Behandlungen und Prognosen in einem klinischen Umfeld eingesetzt. Wenn wir jedoch nicht sehen können, wie eine klinische Entscheidung getroffen wird, können wir nicht wissen, welche Auswirkungen dies beispielsweise auf einen Krebspatienten haben wird. Andererseits ist Krebs eine der tödlichsten Krankheiten, die durch abnormales Verhalten von Genen verursacht werden, die die Zellteilung und das Wachstum steuern. Da die Bedeutung des genetischen Wissens bei der Krebsbehandlung zunehmend angesprochen wird, sind mehrere Projekte entstanden, die auf der Genomsequenzierung der nächsten Generation~(NGS) basieren und umfangreiche Omics-Daten liefern. Durch die Erfassung tiefer Einblicke in Omics-Daten können tiefgreifende Erkenntnisse gewonnen werden, um die genetische Veranlagung von Krebs aufzudecken, bevor er wächst. Da geeignete Diagnosen von einer genauen Vorhersage der Krebsarten abhängen, ist es dennoch wichtig, diese Daten zu analysieren, bevor eine personalisierte Diagnose und nachfolgende Behandlungen, Heilungen oder eine Neupositionierung des Arzneimittels bereitgestellt werden. 
        
        \vspace{1mm}
        \hspace*{3.5mm} \textbf{Motivations}: Die Entwicklung eines Entscheidungsunterstützungssystems~(DSS) zur Nutzung einer genauen und vertrauenswürdigen Krebsdiagnose ist eine unabdingbare Voraussetzung. Da jedoch weder die Entscheidung eines komplexen DNN-Modells auf die Eingaben zurückgeführt werden kann, noch klar ist, warum die Ausgaben so transformiert werden, wie sie sind, ist es fraglich, das Modell als "Black-Box" -Methode zu behandeln. Die explizite Darstellung von Domänenwissen und Datenherkunft durch die Schichten eines DNN kann jedoch nicht nur den Weg zu einem erklärbaren DSS ebnen, sondern auch dazu beitragen, die Transparenz und Interpretierbarkeit der von Menschen verständlichen Entscheidungsregeln zu verbessern. Basierend auf dieser Motivation zielt diese Arbeit darauf ab: i) die algorithmische Transparenz und Erklärbarkeit eines Black-Box-DSS für die Krebsdiagnose zu verbessern, ii) das Wissen über molekulare Mechanismen der Karzinogenese zu entdecken und zu verbreiten.
        
        \vspace{1mm}
        
        \hspace*{3.5mm} \textbf{Methodik}: Sowohl unimodale als auch multimodale DNN-Architekturen werden zunächst anhand von Genomdaten konstruiert und trainiert, um abstrakte Merkmale auf hoher Ebene zu erlernen. Die Methode des neuronalen Ensembles wird dann verwendet, um das stabilste Modell aus mehreren Modellschnappschüssen zu erhalten. Um die algorithmische Transparenz und Interpretierbarkeit der Modelle zu verbessern, wurden verschiedene Sondierungstechniken~(z. B. Klassenaktivierungskarten und schichtweise Relevanzvermehrung) eingesetzt und krebsspezifische Markergene identifiziert. Um die Robustheit des Gegners zu verbessern, wurden sowohl reaktive als auch proaktive Maßnahmen unter Berücksichtigung verschiedener Angriffsszenarien ergriffen. Anschließend wird eine Modellsurrogationsstrategie angewendet, um die Black-Box-Modelle zu approximieren und genaue Erklärungen in Bezug auf Entscheidungsregeln zu generieren, wobei sowohl die lokale als auch die globale Interpretierbarkeit im Mittelpunkt stehen. Um die biologische Relevanz identifizierter Biomarker zu validieren, werden Funktionsanalysen durchgeführt. Als Teil des symbolischen Denkens wird ein domänenspezifischer Wissensgraph~(KG) erstellt, indem Wissen und Fakten über Krebs aus externen Quellen integriert werden. Anschließend wird ein semantischer Reasoner verwendet, um hierarchische Beziehungen von der KG zu lernen, um die Assoziation~(d. H. Argumentation) von krebsspezifischen Biomarkern mit verschiedenen Krebsarten zu validieren. Die Entscheidungsregeln werden dann aktualisiert, indem die Argumentation mit den Vorhersagen kombiniert wird, um die Verzerrungen bei der Diagnoseentscheidung zu verringern. Schließlich wird die Erklärbarkeit des Gesamtansatzes durch Berechnen der Vollständigkeit und Ausreichend- keit als Modelltreue bewertet.
        
        \vspace{1mm}
        
        \hspace*{3.5mm} \textbf{Results:} Quantitative und qualitative Analysen zeigen, dass unser Ansatz nicht nur ein hohes Vertrauen in die korrekte Vorhersage der Krebsarten mit einer durchschnittlichen Genauigkeit von 96,25\% aufweist, sondern auch vom Menschen interpretierbare Erklärungen für die Vorhersagen liefert, indem Top-Gene und krebsspezifische Treibergene freigelegt werden.
    
    }
\end{abstract}