\chapter{Related Work}\label{chapter:rw} 
\textit{``Knowing what you don’t know is more useful than being brilliant''}-Charlie Munger \\

\section{Overview}
In this chapter, we provide the summary of related works on interpretable machine learning approaches with a focus of cancer genomics and bioimaging. 

\section{Related Work}
\label{rw}
\subsection{Cancer typing methods}
Numerous approaches using mixed data types such as genomic data, bioimaging data, and clinical outcomes are used for analyzing genomics data and decision making for the cancer treatment~\cite{min}. For example, RNA-Seq data is used widely to identify rare and common transcripts, isoforms, and non-coding RNAs in cancer. Whereas, single-nucleotide polymorphism~(SNP) indicates small genomic variations in cancer patients and array-based DNA methylation data is used to provide epigenetic changes in the genome that are useful for early genetic changes of cancer e.g. early-stage detection of ovarian cancer is now possible~\cite{82Tomczak,95Gaul}. 

\hspace*{3.5mm}
Since DL algorithms can work better with such high dimensional data, recent studies focused on using deep neural networks~(DNN) architectures such as autoencoder, Restricted Boltzmann Machine~(RBM), Deep Belief Networks~(DBN), Multilayer Perceptron~(MLP), CNN, and Recurrent Neural Networks~(RNN) in cancer genomics. For example, literature~\cite{17Danaee} used Stacked Denoising Autoencoder to extract features from the RNA-seq data, which are then fed into SVM and shallow ANN to classify malignant or benign tumor of breasts~\cite{18Chen}. DeepCNA is another CNN-based approach proposed for cancer type prediction based on CNVs and chromatin 3D structure with CNN~\cite{yuan2018cancer}. Albeit, it is very efficient in the case where both CNA and 3D chromatin structures supplied, availability of such resources, however, not always possible as genomics-based cancer detection. 

\hspace*{3.5mm}
Besides, histology and radiological images are used for understanding the genetic and epigenetic cause in cancer analysis~\cite{yuan2018cancer,20Rajanna,23Zheng}. In particular, GISTIC, MutSig, and clustering algorithms are used to visualize genomic and transcription alterations in various cancers at advanced level~\cite{wb}. Besides, X-ray and CRT images~\cite{25Cruz} along with proteomic and genomic assays are also used, which shows great success in cancer prediction and prognosis~\cite{28Zhou}. Often these images are used to generate noninvasive, functional, and molecular imaging modality data called multispectral photoacoustic imaging~\cite{20Rajanna} to detect prostate cancer using K-means and SVM~\cite{23Zheng}. Besides, histopathology images are used~\cite{19Cruz, xu} to identify the existence of cancer using CNN. Literature~\cite{17Danaee} used stacked denoising autoencoder to extract features from RNA-seq data and then fed into SVM and shallow ANN to classify malignant or benign tumor of breasts~\cite{18Chen}. DeepCNA is another CNN-based approach for cancer type prediction based on CNVs and chromatin 3D structure~\cite{yuan2018cancer}. 

\hspace*{3.5mm}
Apart from these works, restricted methods have been proposed based on CNVs for cancer risk and type predictions~\cite{ding2014application, zhang2016classification, elsadek2018supervised}. Xiaofan D. et al~\cite{ding2014application} used recurrent CNVs from non-tumor blood cell DNAs of non-cancer subjects about hepatocellular carcinoma, gastric cancer, and colorectal cancer patients. They found to reveal the differences between cancer patients and controls concerning CN losses and CN gains. Although their study can make predictions on the cancer predisposition of an unseen test group of mixed DNAs with high confidence, it is limited to only Caucasian cohort and Korean cohorts. 

\begin{table*}[!ht]
    \caption{different cancer detection methods, data types, and performance }
    \label{table:stateofart}
    \begin{center}
    \scriptsize
    \vspace{-6mm}
    \begin{tabular}{l|l|l|l|l|l}
        \hline
        \textbf{Reference} & \textbf{Approach} & \textbf{Cancer types} & \textbf{\#Sample} & \textbf{Data type} & \textbf{Accuracy} \\\hline
            Karim et al.~\cite{karim2018a2ic} & DBN/LSTM & 14 primary types & 15,699 & TCGA CNVs & 73\% \\\hline % 2018
            Yuan et al.~\cite{yuan2018cancer} & CNN & 25 primary types & 14,703 & CNA \& 3D cromatin & 90\% \\\hline % 2018
            Sanaa et al.~\cite{elsadek2018supervised} & LR & 6 primary types & 3,480  & CNVs & 85\% \\\hline % 2018
        	Cruz et al.~\cite{19Cruz} & CNN & Breast cancer  & 605 & Slide images & 96\%  \\\hline  % 2017
            Danee et al.~\cite{17Danaee} & MLP & Breast cancer & 1210 & RNA-seq & 94\% \\\hline % 2016
            Ning et al.~\cite{zhang2016classification} & Dagging & 6 primary types & 3,480  & CNVs & 75\% \\\hline % 2016
        	Rajana et al.~\cite{20Rajanna} & Deep NN & Prostate cancer & 807 & Histology & 95\%\\\hline
            Chen et al.~\cite{18Chen} & Shallow NN & Colon cancer  & 590 & Gene expression & 84\% \\ \hline % 2015
            Ahmed et al.~\cite{abdel2016breast} & DBN & Breast cancer  & 569 & Wisconsin BRCA & 99\% \\ \hline % 2015
            Zheng et al.~\cite{23Zheng} & K-means/SVMst cancer & Phenotype & 569 & Wisconsin BRCA & 97.38\% \\ \hline % 2014
            Xiaofan et al.~\cite{ding2014application} & Naïve Bayes & Cancer risk & 640 & Human SNP & 93\% \\ \hline % 2014
        \end{tabular}
    \end{center}
\end{table*}

\hspace*{3.5mm}
Ning Z. et al.~\cite{zhang2016classification} used CNVs level of 23,082 genes for 2,916 instances from cBioPortal for Cancer Genomics to classify six different types of cancers, i.e., breasts, bladder urothelial, colon, glioblastoma, kidney, and head and neck squamous cell. They construct a dagging-based classifier in which the feature space was reduced into CNVs of 19 genes using minimum redundancy maximum relevance feature selection~(mRMR) and incremental feature selection~(IFS) methods~\cite{zhang2016classification}. Their approach managed to achieve an accuracy of 75\%, which indicates that only a few genes may play essential roles in differentiating cancer types. Sanaa et al.~\cite{elsadek2018supervised} extended their work in which 7 ML classifiers were trained giving random forest algorithm accuracy of 86\%. Other works used omics data to identify various cancer types e.g. literature~\cite{fakoor} used principal component analysis~(PCA) to extract features from high dimensional GE data, which are then fed into sparse and stacked autoencoders to classify acute myeloid leukemia, breast, and ovarian cancer patients. Whereas, literature~\cite{ibrahim} proposed a multilevel feature selection technique based on DBN and unsupervised active learning from miRNA expression data, which outperforms PCA-based methods for hepatocellular and breast carcinoma identification.

\hspace*{3.5mm}
For analyzing genomics data and decision making for cancer treatment, different ML and DL algorithms were trained using mixed data types, such as genomic data, bioimaging data, and clinical outcomes, as shown in \cref{table:stateofart}. These approaches are not only proven to be useful at improving cancer prognosis, diagnosis, and treatments, but also revealed the subtypes information of several cancer types~\cite{66Huang}. For example, RNA-seq data are used more widely to identify rare and common transcripts, isoforms, and non-coding RNAs in cancer. Single nucleotide polymorphism~(SNP) data are used to identify segmental variations across multiple cancer genomes, and array-based DNA methylation sequencing is used to provide epigenetic changes in the genome that are useful for early genetic changes of cancer (e.g., early-stage and metabolomic detection of ovarian cancer is now possible~\cite{82Tomczak,95Gaul}). 

\hspace*{3.5mm}
Unlike conventional cancer typing methods that work on analyzing morphological appearances, gene expression levels of the tumor are used to differentiate tumors that have similar histopathological appearances giving more accurate tumor typing results for the colorectal cancer diagnosis~\cite{paroder2006na+}. Different types of somatic mutations data such as point mutation, single nucleotide variation~(SNV), small insertion and deletion~(INDEL), copy number aberration~(CNA), translocation, and CNVs are also used. Literature~\cite{yuan2018cancer} has observed that these types of genomics data are not only associated with complex diseases but also with contribute to the growth of different types of cancers. In particular, literature~\cite{67Calcagno} studied CN changes by comparing healthy and cancer-affected patients, which showed that amplification and deletion of certain genes are more common in certain cancer patients than healthy people. It has been identified that CNVs are associated with the risk of pancreatic cancer~\cite{66Huang}. Imaging data such as histology and radiological images are used for understanding genetic and epigenetic causes in cancer analyses~\cite{yuan2018cancer,20Rajanna,23Zheng}. In particular, GISTIC, MutSig, and clustering algorithms are used to visualize genomic and transcription alterations in various cancers at an advanced level~\cite{wb}. X-ray and CRT images~\cite{25Cruz}, along with proteomic and genomic assays, are also used, which show great success in cancer prediction and prognosis~\cite{28Zhou}. These types of images are used to generate noninvasive, functional, and molecular imaging modality data called multispectral photoacoustic imaging~\cite{20Rajanna} in order to detect prostate cancer using K-means and SVM~\cite{23Zheng}. 

CNVs analysis based on different statistical methods are also used to identify significant CN associated with different types of cancers. For example, Fisher's exact~(FE) test is applied on patient and control groups to identify copy numbers for hereditary breast and ovarian cancer~\cite{58Kuusisto}. Although FE is mainly used for CNV analysis~\cite{fish}, ML-based approaches are trending to improve the accuracy of cancer susceptibility, recurrence, and survival prediction~\cite{16Kourou}. The main challenges are, however, accurate extraction of CNVs and dealing with dimensionality. ML algorithms such as Bayesian networks, SVM, and decision trees are applied effectively to extract the most significant CNVs features fro high dimensional data. In comparison with ML-based approaches, recent DL techniques have shown more accurate and promising results for cancer identification in some studies. In particular, CNN is widely applied~\cite{19Cruz} on whole slide images in order to detect cancer regions with a very high degree of precision, which is mainly because CNN can extract deep features from different cohorts simultaneously. 

\hspace*{3.5mm}
Literature~\cite{17Danaee} used a stacked denoising autoencoder to extract features from the RNA-seq data, which are then feed into SVM and shallow ANN to classify malignant or benign tumor of breasts~\cite{18Chen}. DeepCNA is another CNN-based approach proposed for cancer type prediction based on CNVs and chromatin 3D structure with CNN~\cite{yuan2018cancer}. Although DeepCNA is very efficient in cases where both CNA and 3D chromatin structures are supplied, the availability of such resources is not always possible, like in genomics-based cancer detection. Therefore, many researchers try to extract genomics data to be consumed by the DNN architectures. Apart from these works, restricted approaches have been proposed based on CNVs for cancer risk and type predictions~\cite{ding2014application, zhang2016classification, elsadek2018supervised}. Xiaofan D. et al~\cite{ding2014application} used recurrent CNVs from non-tumor blood cell DNAs of non-cancer subjects about hepatocellular carcinoma, gastric cancer, and colorectal cancer patients. They were found to reveal the differences between cancer patients and controls with respect to CN losses and CN gains. Although their study can make predictions on the cancer predisposition of an unseen test group of mixed DNAs with high confidence, it is limited to only Caucasian and Korean cohorts. Ning Z. et al.~\cite{zhang2016classification} used CNVs at a level of 23,082 genes for 2,916 instances from cBioPortal for Cancer Genomics to classify 6 different types of cancers, such as breasts, bladder urothelial, colon, glioblastoma, kidney, and head-and-neck squamous cell. They construct a dagging-based classifier in which the feature space was reduced into CNVs of 19 genes using mRMR and IFS methods. They managed to achieve an accuracy of 75\%. Their study indicates that only a few genes may play important roles in differentiating cancer types. Then, Sanaa et al.~\cite{elsadek2018supervised} used the same dataset and extended it by training 7 ML classifiers in which random forest algorithm shows 86\% accuracy. %The data used the CNV in variant types of cancers were downloaded from the 

\hspace*{3.5mm}
In a previous approach~\cite{karim2018a2ic}, we considered segmentation as an important feature because it represents number of CNVs at a DNA location, and the higher the segmentation mean, the higher the CN would be in that region. Followed by the calculation of the length of a CN and its value based on the difference between the start and end positions of a CNV to extract CNV features. We represented CN loss with negative segmentation means and amplifications of CN with positive segmentation means. CN with segmentation values between a certain range were considered as noise and discarded from rest of the calculation. However, a manual approach for CNV extraction like this often fails to extract non-trivial, high-quality recurrent CNV features in the case of simultaneous analysis of multiple samples~\cite{malekpour2018mseq}. Consequently, MSeq-CNV is used in one of our studes in \cref{chapter:uni_modality} for more efficient extraction of CNVs. 

\hspace*{3.5mm}
%\subsection{Related works on multimodality}
Literature~\cite{liang} proposed to cluster ovarian and breast cancer patients based on multiplatform genomics~(e.g. GE, DNA methylation, and miRNA expression) and clinical data. To deal with such multiplatform data, MAE is used in which latent features are extracted before clustering with the K-means.
Ngiam et al.~\cite{NgiamKKNLN11} proposed a multimodal architecture to handle multimodality of audio and video features based on three methods: multimodal fusion, cross-modality learning, and shared representation learning.
While each method uses multimodalities on the feature learning steps, multimodal fusion uses multimodalities in supervised learning and testing. Cross-modality learning used one type of data for both supervised learning and validating, while shared representation learning used one kind of data for supervised learning and testing. The original idea behind the cross-modality learning is to handle multimedia objects where not all data have all modalities. Liang et al.~\cite{liang} adopts a similar architecture for clustering multimodal cancer genomics GE, DNA methylation, and clinical data. 

\hspace*{3.5mm}
Although, approaches using both unimodal~\cite{abdel2016breast} and multimodal DBN~\cite{liang} show accuracy at different prediction tasks, one of the potential limitations using DBN-based approaches is that the limited capability at feature learning during pretraining~\cite{serban2016multi}, although it gets a decent set of feature representations for the inputs. Furthermore, DBN is incapable of learning quality features from very high dimensional datasets. Besides, pretraining losses often get out of bound, which results in overfitting issue. To overcome these limitations, researches have proposed multimodal autoencoder~(MAE)-based approaches~\cite{liu2016multimodal,serban2016multi,wang2018associativemulti}, which is a flexible, simple prior distribution which can be learned efficiently and potentially capture from extensive features of a target distribution. 
Consequently, MAE has shown tremendous success in natural language understanding tasks like document modeling and dialogue modeling~\cite{serban2016multi}, in computer vision like emotion recognition~\cite{liu2016multimodal}, and multimodal word representation~\cite{wang2018associativemulti} for natural language processing. 
Inspired by these successes, we construct a MAE network by extending the multimodal system presented in~\cite{wang2018associativemulti} by adding the capability of handling multiple modalities across four different types of genomics data. Then we added a fully connected layer to use the MAE architecture for the supervised learning task, i.e. breast cancer subtypes and survival rate predictions. However, our datasets are very rich, covering all the modalities for $93\%$ of patients. In our approach, we apply multimodal fusion approach by discarding the small part of patient data that don't have all modalities in our MAE network. 

\hspace*{3.5mm}
Lyu et al.~\cite{lyu2018deep} and Mostavi et al.~\cite{mostavi2019convolutional} embedded the RNA-Seq data from the PCA project into 2D images and trained a CNN to classify 33 tumor types, which outperforms the approach in~\cite{li2017comprehensive}. Besides, they provide a functional analysis on the genes with high intensities in the HM based on GradCAM and validated that these top genes are related to tumor-specific pathways. However, due to the stochastic nature of NN, the prediction and feature importance generated is slightly different across runs, i.e., not deterministic. This is also no exception for tree-based ensemble models such as gradient boosted trees~(GBT), which provides 3 options for measuring feature importance: i) \emph{weight}, which is the number of times a feature is used to split the data across all trees, ii) \emph{cover}, the number of times a feature is used to split the data across all trees weighted by the number of training data points go through those splits, and iii) \emph{gain}, which is the average training loss reduction gained when using a feature for splitting. Based on these measure, feature importance orderings~(i.e., the order in which features were added) are different since subsequent features will get a disproportionately high weight.

\section{Chapter summary}