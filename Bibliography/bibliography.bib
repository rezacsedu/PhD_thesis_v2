%containing a complete list of books and other publications that are either explicitly referred to in the text, or which are recommended for further reading on the topic

@book{cormen2009introduction,
  title={Introduction to algorithms},
  author={Cormen, Thomas H},
  year={2009},
  publisher={MIT press}
}
@article{diessner,
    title = "Do Patients with Luminal A Breast Cancer Profit from Adjuvant Systemic Therapy? A Retrospective Multicenter Study",
    author = "Joachim Diessner and Manfred Wischnewsky and Maria Blettner and others",
    journal = "PLOS One",
    volume = "11",
    year = "2016",
    number = {12},
    pages = "e0168730"
}
@article{xie2018adaptively,
  title={Adaptively capturing the heterogeneity of expression for cancer biomarker identification},
  author={Xie, Xin-Ping and Xie, Yu-Feng and Liu, Yi-Tong and Wang, Hong-Qiang},
  journal={BMC bioinformatics},
  volume={19},
  number={1},
  pages={401},
  year={2018},
  publisher={Springer}
}
@article{baker2015cancer,
  title={A cancer theory kerfuffle can lead to new lines of research},
  author={Baker, Stuart G},
  journal={Journal of the National Cancer Institute},
  volume={107},
  number={2},
  pages={dju405},
  year={2015},
  publisher={Oxford University Press US}
}
@article{o2010unit,
  title={Unit 5: How Do Cells Know When to Divide},
  author={O'CONNOR, Clare M and ADAMS, Jill U},
  journal={Essentials of Cell Biology. Cambridge, MA: NPG Education},
  year={2010}
}
@incollection{binder2016layer,
  title={Layer-wise relevance propagation for deep neural network architectures},
  author={Binder, Alexander and Bach, Sebastian and Montavon, Gregoire and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
  booktitle={Information Science and Applications (ICISA) 2016},
  pages={913--922},
  year={2016},
  publisher={Springer}
}
@inproceedings{ito2018effects,
  title={The Effects of Unimodal Representation Choices on Multimodal Learning},
  author={Ito, Fernando Tadao and de Medeiros Caseli, Helena and Moreira, Jander},
  booktitle={Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)},
  year={2018}
}
@article{ghazani2017assigning, 
  title={Assigning clinical meaning to somatic and germ-line whole-exome sequencing data in a prospective cancer precision medicine study},
  author={Ghazani, Arezou A and Oliver, Nelly M and Pierre, Joseph P St and Garofalo, Andrea and Rainville, Irene R and Hiller, Elaine and Treacy, Daniel J and Rojas-Rudilla, Vanesa and Wood, Sam and Bair, Elizabeth and others},
  journal={Genetics in Medicine},
  volume={19},
  number={7},
  pages={787--795},
  year={2017},
  publisher={Nature Publishing Group}
}
@article{zednik2019solving,
  title={Solving the black box problem: A normative framework for explainable artificial intelligence},
  author={Zednik, Carlos},
  journal={Philosophy \& Technology},
  pages={1--24},
  year={2019},
  publisher={Springer}
}
@article{hall2020responsible,
  title={Responsible Machine Learning},
  author={Hall, Patrick},
  year={2020}
}
@article{act2009fair,
  title={Fair Credit Reporting Act},
  author={Act, Fair Credit Reporting},
  journal={Flood Disaster Protection Act and Financial Institute},
  year={2009}
}
@article{hackathorn1981organizational,
  title={Organizational strategies for personal computing in decision support systems},
  author={Hackathorn, Richard D and Keen, Peter GW},
  journal={MIS quarterly},
  pages={21--27},
  year={1981},
  publisher={JSTOR}
}
@article{diakopoulos2015algorithmic,
  title={Algorithmic accountability: Journalistic investigation of computational power structures},
  author={Diakopoulos, Nicholas},
  journal={Digital journalism},
  volume={3},
  number={3},
  pages={398--415},
  year={2015},
  publisher={Taylor \& Francis}
}
@book{power2002decision,
  title={Decision support systems: concepts and resources for managers},
  author={Power, Daniel J},
  year={2002},
  publisher={Greenwood Publishing Group}
}
@article{haettenschwiler1999neues,
  title={Neues anwenderfreundliches konzept der entscheidungsunterst{\"u}tzung},
  author={Haettenschwiler, Plus},
  journal={Gutes entscheiden in wirtschaft, politik und gesellschaft. Zurich, vdf Hochschulverlag AG},
  pages={189--208},
  year={1999}
}
@article{azodi2020opening,
  title={Opening the Black Box: Interpretable machine learning for geneticists},
  author={Azodi, Christina B and Tang, Jiliang and Shiu, Shin-Han},
  journal={Trends in Genetics},
  year={2020},
  publisher={Elsevier}
}
@article{jha2017towards,
  title={Towards precision medicine: discovering novel gynecological cancer biomarkers and pathways using linked data},
  author={Jha, Alokkumar and Khan, Yasar and Mehdi, Muntazir and Karim, Md Rezaul and Mehmood, Qaiser and Zappa, Achille and Rebholz-Schuhmann, Dietrich and Sahay, Ratnesh},
  journal={Journal of biomedical semantics},
  volume={8},
  number={1},
  pages={40},
  year={2017},
  publisher={Springer}
}
@article{davenport2019potential,
  title={The potential for artificial intelligence in healthcare},
  author={Davenport, Thomas and Kalakota, Ravi},
  journal={Future healthcare journal},
  volume={6},
  number={2},
  pages={94},
  year={2019},
  publisher={Royal College of Physicians}
}
@article{alirezaie2017ontology,
  title={An ontology-based reasoning framework for querying satellite images for disaster monitoring},
  author={Alirezaie, Marjan and Kiselev, Andrey and L{\"a}ngkvist, Martin and Kl{\"u}gl, Franziska and Loutfi, Amy},
  journal={Sensors},
  volume={17},
  number={11},
  pages={2545},
  year={2017},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@techreport{acs,
  author       = {American Cancer Society}, 
  title        = {American Cancer Society: Cancer Facts and Figures 2017},
  year         = "2017",
  address      = "Atlanta, Ga"
}

@article{goldhirsch,
    title = "Strategies for subtypes--dealing with the diversity of breast cancer: highlights of the St Gallen International Expert Consensus on the Primary Therapy of Early Breast Cancer 2011",
    author = "A Goldhirsch and W C Wood and A S Coates and others",
    journal = "Annals of Oncology",
    volume = "22",
    year = "2011",
    number = {8},
    pages = "1736--1747"
}
%1
@Article{1Zarrei,
  author =       "Zarrei, M. and et al",
  title =        "A copy number variation map of the human genome",
  year =         "2015",
  journal =      "nature reviews genetics",
  volume =       "16(3)",
  pages =        "172-183"
}

@article{tomczak2015cancer,
  title={The Cancer Genome Atlas (TCGA): an immeasurable source of knowledge},
  author={Tomczak, Katarzyna and Czerwi{\'n}ska, Patrycja and Wiznerowicz, Maciej},
  journal={Contemporary oncology},
  volume={19},
  number={1A},
  pages={A68},
  year={2015},
  publisher={Termedia Publishing}
}


%2 http://genome.cshlp.org/content/16/8/949.full.html#ref-29
@Article{2Feuk,
  author =       "Feuk, L. and et al",
  title =        "Structural variation in the human genome",
  year =         "2006",
  journal =      "nature reviews genetics",
  volume =       "7(2)",
  pages =        "85-97"
}


%3Iafrate
@Article{3Iafrate,
  author =       "Iafrate, A.J. and et al.",
  title =        "Detection of large-scale variation in the human genome",
  year =         "2004",
  journal =      "nature genetics",
  volume =       "36(9)",
  pages =        "949-951"
}
Iafrate, A.J., Feuk, L., Rivera, M.N., Listewnik, M.L., Donahoe, P.K., Qi, Y., Scherer, S.W. and Lee, C., 2004. Detection of large-scale variation in the human genome. Nature genetics, 36(9), pp.949-951.


%4
@Article{4Sebat,
  author =       "Sebat, Jonathan and et al",
  title =        "Large-scale copy number polymorphism in the human genome",
  year =         "2004",
  journal =      "Science",
  volume =       "305(5683)",
  pages =        "525-528"
}
%  Sebat, Jonathan, et al. "Large-scale copy number polymorphism in %the human genome." Science 305.5683 (2004): 525-528


%7
@Article{7Stone,
  author =       "Stone, Jennifer L. and et al",
  title =        "Rare chromosomal deletions and duplications increase risk of schizophrenia",
  year =         "2008",
  journal =      "nature",
  volume =       "455(7210)",
  pages =        "237-241"
  }
%Stone, Jennifer L., et al. "Rare chromosomal deletions and %duplications increase risk of schizophrenia." Nature 455.7210 %(2008): 237-241.


%8
@Article{8Stefansson,
  author =       "Stefansson, Hreinn and et al",
  title =        "Large recurrent microdeletions associated with schizophrenia",
  year =         "2008",
  journal =      "nature",
  volume =       "455(7219)",
  pages =        "232-236"
}
%  Stefansson, Hreinn, et al. "Large recurrent microdeletions associated with %schizophrenia." nature 455.7210 (2008): 232-236.

@article{karimACCESS2019,
  title={Prognostically Relevant Subtypes and Survival Prediction for Breast Cancer Based on Multimodal Genomics Data},
  author={Karim, Md Rezaul and Wicaksono, Galih and Costa, Ivan G and Decker, Stefan and Beyan, Oya},
  journal={IEEE Access},
  volume={7},
  pages={133850--133864},
  year={2019},
  publisher={IEEE}
}

%9
@Article{9Walsh,
  author =       "Walsh, Tom and et al",
  title =        "Rare structural variants disrupt multiple genes in neurodevelopmental pathways in schizophrenia",
  year =         "2008",
  journal =      "science",
  volume =       "320(5875)",
  pages =        "539-543"
}
%  Walsh, Tom, et al. "Rare structural variants disrupt multiple genes in %neurodevelopmental pathways in schizophrenia." science 320.5875 (2008): 539-543.

@article{XAI_miller,
  title={Explanation in artificial intelligence: Insights from the social sciences},
  author={Miller, Tim},
  journal={Artificial Intelligence},
  year={2018},
  publisher={Elsevier}
}
@inproceedings{XAI_kim,
  title={Examples are not enough, learn to criticize! criticism for interpretability},
  author={Kim, Been and Khanna, Rajiv and Koyejo, Oluwasanmi O},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2280--2288},
  year={2016}
}

%10
@Article{10Cooper,
  author =       "Cooper, Gregory M. and et al",
  title =        "A copy number variation morbidity map of developmental delay",
  year =         "2011",
  journal =      "nature genetics",
  volume =       "43(9)",
  pages =        "838-846"
}
  %Cooper, Gregory M., et al. "A copy number variation morbidity map of developmental %delay." Nature genetics 43.9 (2011): 838-846.

%11
@Article{11Fromer,
  author =       "Fromer, Menachem and et al",
  title =        "Discovery and statistical genotyping of copy-number variation from whole-exome sequencing depth",
  year =         "2012",
  journal =      "The American Journal of Human Genetics",
  volume =       "91(4)",
  pages =        "597-607"
}
%Fromer, Menachem, et al. "Discovery and statistical genotyping of %copy-number variation from whole-exome sequencing depth." The %American Journal of Human Genetics 91.4 (2012): 597-607.


%12
@Article{12Lee,
  author =       "Lee, J. H., and J. T. Jeon",
  title =        "Methods to detect and analyze copy number variations at the genome-wide and locus-specific levels.",
  year =         "2008",
  journal =      "Cytogenetic and genome research",
  volume =       "123(1-4)",
  pages =        "333-342"
}
%Lee, J. H., and J. T. Jeon. "Methods to detect and analyze copy %number variations at the genome-wide and locus-specific levels." %Cytogenetic and genome research 123.1-4 (2008): 333-342.


%13
@Article{13cancerdef,
  author = "NIH, National Cancer Center",
  title =        "https://www.cancer.gov/about\-cancer/understanding/what\-is\-cancer",
  journal = "nih",
  year = "2011"
}
@article{Karim2020DeepCOVIDExplainer,
  title={DeepCOVIDExplainer: Explainable COVID-19 Predictions Based on Chest X-ray Images},
  author={Md. Rezaul Karim and Till Döhmen and Dietrich Rebholz-Schuhmann and Stefan Decker and Michael Cochez and Oya Beyan},
  journal={arXiv preprint  arXiv:2004.04582},
  year={2020}
}
@article{kahng2018gan,
  title={Gan lab: Understanding complex deep generative models using interactive visual experimentation},
  author={Kahng, Minsuk and Thorat, Nikhil and Chau, Duen Horng Polo and Vi{\'e}gas, Fernanda B and Wattenberg, Martin},
  journal={IEEE transactions on visualization and computer graphics},
  volume={25},
  number={1},
  pages={1--11},
  year={2018},
  publisher={IEEE}
}
@article{karimBIB2019,
    author = {Karim, Md Rezaul and Beyan, Oya and Zappa, Achille and Costa, Ivan G and Rebholz-Schuhmann, Dietrich and Cochez, Michael and Decker, Stefan},
    title = "{Deep learning-based clustering approaches for bioinformatics}",
    journal = {Briefings in Bioinformatics},
    year = {2020},
    month = {02},
    issn = {1477-4054},
    doi = {10.1093/bib/bbz170},
    url = {https://doi.org/10.1093/bib/bbz170},
    note = {bbz170}
}
@article{@article{futia2020integration,
  title={On the Integration of Knowledge Graphs into Deep Learning Models for a More Comprehensible AI—Three Challenges for Future Research},
  author={Futia, Giuseppe and Vetr{\`o}, Antonio},
  journal={Information},
  volume={11},
  number={2},
  pages={122},
  year={2020},
  publisher={Multidisciplinary Digital Publishing Institute}
}
@article{futia2020integration,
  title={On the Integration of Knowledge Graphs into Deep Learning Models for a More Comprehensible AI—Three Challenges for Future Research},
  author={Futia, Giuseppe and Vetr{\`o}, Antonio},
  journal={Information},
  volume={11},
  number={2},
  pages={122},
  year={2020},
  publisher={Multidisciplinary Digital Publishing Institute}
}
@book{GoFI,
  title={Artificial intelligence: The very idea},
  author={Haugeland, John},
  year={1989},
  publisher={MIT press}
}
@article{DORF,
  title={Data Science and symbolic AI: Synergies, challenges and opportunities},
  author={Hoehndorf, Robert and Queralt-Rosinach, N{\'u}ria and others},
  journal={Data Science},
  volume={1},
  number={1-2},
  pages={27--38},
  year={2017},
  publisher={IOS Press}
}
@article{seeliger2019semantic,
  title={Semantic Web Technologies for Explainable Machine Learning Models: A Literature Review},
  author={Seeliger, Arne and Pfaff, Matthias and Krcmar, Helmut},
  journal={PROFILES 2019},
  pages={30},
  year={2019}
}
@article{sarker2017explaining,
  title={Explaining trained neural networks with semantic web technologies: First steps},
  author={Sarker, Md Kamruzzaman and Xie, Ning and Doran, Derek and Raymer, Michael and Hitzler, Pascal},
  journal={arXiv preprint arXiv:1710.04324},
  year={2017}
}
@article{angelov2019towards,
  title={Towards Explainable Deep Neural Networks (xDNN)},
  author={Angelov, Plamen and Soares, Eduardo},
  journal={arXiv preprint arXiv:1912.02523},
  year={2019}
}
@article{wang2015explicit,
  title={Explicit knowledge-based reasoning for visual question answering},
  author={Wang, Peng and Wu, Qi and Shen, Chunhua and Hengel, Anton van den and Dick, Anthony},
  journal={arXiv preprint arXiv:1511.02570},
  year={2015}
}
@article{lehmann2015dbpedia,
  title={DBpedia--a large-scale, multilingual knowledge base extracted from Wikipedia},
  author={Lehmann, Jens and Isele, Robert and Jakob, Max and Jentzsch, Anja and Kontokostas, Dimitris and Mendes, Pablo N and Hellmann, Sebastian and Morsey, Mohamed and Van Kleef, Patrick and Auer, S{\"o}ren and others},
  journal={Semantic Web},
  volume={6},
  number={2},
  pages={167--195},
  year={2015},
  publisher={IOS Press}
}
@article{arya2019one,
  title={One explanation does not fit all: A toolkit and taxonomy of ai explainability techniques},
  author={Arya, Vijay and Bellamy, Rachel KE and Chen, Pin-Yu and Dhurandhar, Amit and Hind, Michael and Hoffman, Samuel C and Houde, Stephanie and Liao, Q Vera and Luss, Ronny and Mojsilovi{\'c}, Aleksandra and others},
  journal={arXiv preprint arXiv:1909.03012},
  year={2019}
}
@inproceedings{liao2018interpretable,
  title={Interpretable multimodal retrieval for fashion products},
  author={Liao, Lizi and He, Xiangnan and Zhao, Bo and Ngo, Chong-Wah and Chua, Tat-Seng},
  booktitle={Proceedings of the 26th ACM international conference on Multimedia},
  pages={1571--1579},
  year={2018}
}
@article{karim2018improving,
  title={Improving data workflow systems with cloud services and use of open data for bioinformatics research},
  author={Karim, Md Rezaul and Michel, Audrey and Zappa, Achille and Baranov, Pavel and Sahay, Ratnesh and Rebholz-Schuhmann, Dietrich},
  journal={Briefings in bioinformatics},
  volume={19},
  number={5},
  pages={1035--1050},
  year={2018},
  publisher={Oxford University Press}
}
@book{forrester2008engineering,
  title={Engineering design via surrogate modelling: a practical guide},
  author={Forrester, Alexander and Sobester, Andras and Keane, Andy},
  year={2008},
  publisher={John Wiley \& Sons}
}
@article{maslove2013discretization,
  title={Discretization of continuous features in clinical datasets},
  author={Maslove, David M and Podchiyska, Tanya and Lowe, Henry J},
  journal={Journal of the American Medical Informatics Association},
  volume={20},
  number={3},
  pages={544--553},
  year={2013},
  publisher={BMJ Publishing Group BMA House, Tavistock Square, London, WC1H 9JR}
}
@inproceedings{BayesianRule,
  title={Scalable Bayesian rule lists},
  author={Yang, Hongyu and Rudin, Cynthia and Seltzer, Margo},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={3921--3930},
  year={2017},
  organization={JMLR. org}
}
@article{ming2018rulematrix,
  title={Rulematrix: Visualizing and understanding classifiers with rules},
  author={Ming, Yao and Qu, Huamin and Bertini, Enrico},
  journal={IEEE transactions on visualization and computer graphics},
  volume={25},
  number={1},
  pages={342--352},
  year={2018},
  publisher={IEEE}
}
@article{song2017pixeldefend,
  title={Pixeldefend: Leveraging generative models to understand and defend against adversarial examples},
  author={Song, Yang and Kim, Taesup and Nowozin, Sebastian and Ermon, Stefano and Kushman, Nate},
  journal={arXiv preprint arXiv:1710.10766},
  year={2017}
}
@inproceedings{meng2017magnet,
  title={Magnet: a two-pronged defense against adversarial examples},
  author={Meng, Dongyu and Chen, Hao},
  booktitle={Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
  pages={135--147},
  year={2017}
}
@article{zhao2017generating,
  title={Generating natural adversarial examples},
  author={Zhao, Zhengli and Dua, Dheeru and Singh, Sameer},
  journal={arXiv preprint arXiv:1710.11342},
  year={2017}
}
@article{karimTCBB2020,
    author = {Karim, Md Rezaul and Beyan, Oya and Zappa, Achille and Costa, Ivan G and Rebholz-Schuhmann, Dietrich and Cochez, Michael and Decker, Stefan},
    title = "{Convolutional Embedded Networks for Population Scale Clustering and Bio-ancestry Inferencing}",
    journal = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
    year = {2020},
    month = {02},
    issn = {1477-4054},
    doi = {10.1093/bib/bbz170},
    url = {https://doi.org/10.1093/bib/bbz170},
    note = {bbz170}
}
  
@article{hoffman2018metrics,
  title={Metrics for explainable AI: Challenges and prospects},
  author={Hoffman, Robert R and Mueller, Shane T and Klein, Gary and Litman, Jordan},
  journal={arXiv preprint arXiv:1812.04608},
  year={2018}
}
  
@article{harder2019interpretable,
  title={Interpretable and Differentially Private Predictions},
  author={Harder, Frederik and Bauer, Matthias and Park, Mijung},
  journal={arXiv preprint arXiv:1906.02004},
  year={2019}
}
  
@Article{karimACCA2019,
    author = "Md. Rezaul Karim and Oya Beyan and Stefan Decker and Oya Beyan",
    title = "A snapshot neural ensemble method for cancer type prediction based on copy number variations", 
    year =         "2019",
    journal =      "Neural Computing and Applications",
    volume =       "67(1)"
  }
  @article{sparseAE,
  author    = {Andrea Asperti},
  title     = {Sparsity in Variational Autoencoders},
  journal   = {CoRR},
  volume    = {abs/1812.07238},
  year      = {2018},
  archivePrefix = {arXiv},
  eprint    = {1812.07238}
}

%14
@Article{14Siegel,
  author =       "Siegel, Rebecca L. and Kimberly D. Miller and Ahmedin Jemal",
  title =        "Cancer statistics, 2017",
  year =         "2017",
  journal =      "CA: a cancer journal for clinicians",
  volume =       "67(1)",
  pages =        "7-30"
}
%Siegel, Rebecca L., Kimberly D. Miller, and Ahmedin Jemal. "Cancer Statistics, 2017." CA: A Cancer Journal for Clinicians 67.1 (2017): 7-30.

%15
@Article{15Wu,
  author =       "Wu, Li and Xiaogang Qu",
  title =        "Cancer biomarker detection: recent achievements and challenges",
  year =         "2015",
  journal =      "Chemical Society Reviews",
  volume =       "44(10)",
  pages =        "2963-2997"
}
%Wu, Li, and Xiaogang Qu. "Cancer biomarker detection: recent %achievements and challenges." Chemical Society Reviews 44.10 (2015): %2963-2997.

@InProceedings{karim2018a2ic,
  author={Md. Rezaul Karim and Oya Beyan},
  title={Cancer Risk and Type Prediction Based on Copy Number Variations with {LSTM} and {Deep Belief Networks}},
  booktitle ={In proc. of 1st International Artificial Intelligence Conference (A2IC)},
  volume={1},
  address = {Barcelona, Spain},
  year={2018}
  }

%16
@Article{16Kourou,
  author =       "Kourou, Konstantina and et al",
  title =        "Machine learning applications in cancer prognosis and prediction",
  year =         "2015",
  journal =      "Computational and structural biotechnology journal",
  volume =       "13",
  pages =        "8-17"
}
%Kourou, Konstantina, et al. "Machine learning applications in cancer %prognosis and prediction." Computational and structural %biotechnology journal 13 (2015): 8-17.


%17
@Article{17Danaee,
  author =       "Danaee, Padideh and Reza Ghaeini and David A. Hendrix",
  title =        "A Deep Learning approach for cancer detection and relevent gene identification",
  year =         "2016",
  journal =      "Pacific Symposium on Biocomputing",
  volume =       "22",
  pages =        "NIH Public Access"
}
%Danaee, Padideh, Reza Ghaeini, and David A. Hendrix. "A DEEP LEARNING APPROACH FOR CANCER DETECTION AND RELEVANT GENE IDENTIFICATION." Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing. Vol. 22. NIH Public Access, 2016.


%18
@Article{18Chen,
  author =       "Chen, Huaming and et al",
  title =        "Supervised machine learning model for high dimensional gene data in colon cancer detection",
  year =         "2015",
  journal =      "Big Data (BigData Congress), 2015 IEEE International Congress on. IEEE",
  volume =       "",
  pages =        "",
}
Chen, Huaming, et al. "Supervised machine learning model for high dimensional gene data in colon cancer detection." Big Data (BigData Congress), 2015 IEEE International Congress on. IEEE, 2015.


%19
@Article{19Cruz,
  author =       "Cruz-Roa, Angel and et al",
  title =        "Accurate and reproducible invasive breast cancer detection in whole-slide images: A Deep Learning approach for quantifying tumor extent",
  year =         "2017",
  journal =      "Scientific Reports",
  volume =       "7",
  pages =        "46450",
}
Cruz-Roa, Angel, et al. "Accurate and reproducible invasive breast cancer detection in whole-slide images: A Deep Learning approach for quantifying tumor extent." Scientific Reports 7 (2017): 46450.


%20
@Article{20Rajanna,
  author =       "Rajanna, Arjun Raj and et al",
  title =        "Prostate cancer detection using photoacoustic imaging and deep learning",
  year =         "2016",
  journal =      "Electronic Imaging",
  volume =       "2016(15)",
  pages =        "1-6",
}
Rajanna, Arjun Raj, et al. "Prostate cancer detection using photoacoustic imaging and deep learning." Electronic Imaging 2016.15 (2016): 1-6.


%21
@Article{21Caorsi,
  author =       "Caorsi, Salvatore, and Claudio Lenzi",
  title =        "A Breast Cancer Detection Approach Based on Radar Data Processing using Artificial Neural Network",
  year =         "2016",
  journal =      "Research Journal of Advanced Engineering and Science",
  volume =       "1(4)",
  pages =        "213-222",
}
Caorsi, Salvatore, and Claudio Lenzi. "A Breast Cancer Detection Approach Based on Radar Data Processing using Artificial Neural Network." Research Journal of Advanced Engineering and Science 1.4 (2016): 213-222.


%22
@Article{22Ding,
  author =       "Ding, Xiaofan and et al",
  title =        "Application of machine learning to development of copy number variation-based prediction of cancer risk",
  year =         "2014",
  journal =      "Genomics insights",
  volume =       "7",
  pages =        "1",
}
Ding, Xiaofan, et al. "Application of machine learning to development of copy number variation-based prediction of cancer risk." Genomics insights 7 (2014): 1.

@article{huang2017snapshot,
  title={Snapshot ensembles: Train 1, get M for free},
  author={Huang, Gao and Li, Yixuan and Pleiss, Geoff and Liu, Zhuang and Hopcroft, John E and Weinberger, Kilian Q},
  journal={arXiv preprint arXiv:1704.00109},
  year={2017}
}

@article{loshchilov2016sgdr,
  title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1608.03983},
  year={2016}
}
@article{miller2018explanation,
  title={Explanation in artificial intelligence: Insights from the social sciences},
  author={Miller, Tim},
  journal={Artificial Intelligence},
  year={2018},
  publisher={Elsevier}
}
@inproceedings{cochez2017global,
  title={Global {RDF} vector space embeddings},
  author={Cochez, Michael and Ristoski, Petar and Ponzetto, Simone Paolo and Paulheim, Heiko},
  booktitle={International Semantic Web Conference},
  pages={190--207},
  year={2017},
  organization={Springer}
}
@inproceedings{ristoski2016rdf2vec,
  title={{RDF2Vec}: {RDF} graph embeddings for data mining},
  author={Ristoski, Petar and Paulheim, Heiko},
  booktitle={International Semantic Web Conference},
  pages={498--514},
  year={2016},
  organization={Springer}
}
@article{abdel2016breast,
  title={Breast cancer classification using deep belief networks},
  author={Abdel-Zaher, Ahmed M and Eldeib, Ayman M},
  journal={Expert Systems with Applications},
  volume={46},
  pages={139--144},
  year={2016},
  publisher={Elsevier}
}
%23
@Article{23Zheng,
  author =       {Zheng, Bichen and Sang Won, Yoon and Sarah, S. Lam},
  title =        {Breast cancer diagnosis based on feature extraction using a hybrid of {K-means} and support vector machine algorithms},
  year =         {2014},
  journal =      {Expert Systems with Applications},
  volume =       {41(4)},
  pages =        {1476-1482}
}

%24
@Article{24Podolsky,
  author =       "Podolsky, Maxim D. and et al",
  title =        "Evaluation of machine learning algorithm utilization for lung cancer classification based on gene expression levels",
  year =         "2016",
  journal =      "Asian Pacific Journal of Cancer Prevention",
  volume =       "17(2)",
  pages =        "835-838",
}
Podolsky, Maxim D., et al. "Evaluation of machine learning algorithm utilization for lung cancer classification based on gene expression levels." Asian Pacific Journal of Cancer Prevention 17.2 (2016): 835-838.



%25
@Article{25Cruz,
  author =       "Cruz, Joseph A., and David S. Wishart",
  title =        "Applications of machine learning in cancer prediction and prognosis",
  year =         "2006",
  journal =      "Cancer informatics",
  volume =       "2",
  pages =        "59",
}
Cruz, Joseph A., and David S. Wishart. "Applications of machine learning in cancer prediction and prognosis." Cancer informatics 2 (2006): 59.


%26
@Article{26Petricoin,
  author =       "Petricoin, Emanuel F., and Lance A. Liotta",
  title =        "{SELDI-TOF}-based serum proteomic pattern diagnostics for early detection of cancer",
  year =         "2004",
  journal =      "Current Opinion in Biotechnology",
  volume =       "15(1)",
  pages =        "24-30",
}
Petricoin, Emanuel F., and Lance A. Liotta. "SELDI-TOF-based serum proteomic pattern diagnostics for early detection of cancer." Current Opinion in Biotechnology 15.1 (2004): 24-30.


%27
@Article{27Bocchi,
  author =       "Bocchi, L. and et al",
  title =        "Detection of single and clustered microcalcifications in mammograms using fractals models and neural networks",
  year =         "2004",
  journal =      "Medical Engineering \& Physics",
  volume =       "26(4)",
  pages =        "303-312",
}
Bocchi, L., et al. "Detection of single and clustered microcalcifications in mammograms using fractals models and neural networks." Medical Engineering & Physics 26.4 (2004): 303-312.



%28
@Article{28Zhou,
  author =       "Zhou, Xiaobo and Kuang-Yu Liu and Stephen, TC Wong",
  title =        "Cancer classification and prediction using logistic regression with Bayesian gene selection",
  year =         "2004",
  journal =      "Journal of Biomedical Informatics",
  volume =       "37(4)",
  pages =        "249-259",
}
Zhou, Xiaobo, Kuang-Yu Liu, and Stephen TC Wong. "Cancer classification and prediction using logistic regression with Bayesian gene selection." Journal of Biomedical Informatics 37.4 (2004): 249-259.



%29
@Article{29Dettling,
  author =       "Dettling, Marcel",
  title =        "{BagBoosting} for tumor classification with gene expression data",
  year =         "2004",
  journal =      "Bioinformatics",
  volume =       "20(18)",
  pages =        "3583-3593",
}
Dettling, Marcel. "BagBoosting for tumor classification with gene expression data." Bioinformatics 20.18 (2004): 3583-3593.


%30
@Article{30Wang,
  author =       "Wang, Jia-Xiang and et al",
  title =        "Application of serum protein fingerprinting coupled with artificial neural network model in diagnosis of hepatocellular carcinoma",
  year =         "2005",
  journal =      "Chinese medical journal",
  volume =       "118(15)",
  pages =        "1278-1284",
}
Wang, Jia-Xiang, et al. "Application of serum protein fingerprinting coupled with artificial neural network model in diagnosis of hepatocellular carcinoma." Chinese medical journal 118.15 (2005): 1278-1284.




%31
@Article{31Park,
  author =       "Park, Richard W. and et al",
  title =        "Identification of rare germline copy number variations over-represented in five human cancer types",
  year =         "2015",
  journal =      "Molecular cancer",
  volume =       "14(1)",
  pages =        "25",
}
Park, Richard W., et al. "Identification of rare germline copy number variations over-represented in five human cancer types." Molecular cancer 14.1 (2015): 25.



%32
@Article{32da,
  author =       "da Silva, M. V. G. B. and et al",
  title =        "Descriptive analysis of copy number variation regions in a population of dairy Gyr cattle.",
  year =         "2014",
  journal =      "American Society of Animal Science",
  volume =       "",
  pages =        "",
}
da Silva, M. V. G. B., et al. "Descriptive analysis of copy number variation regions in a population of dairy Gyr cattle." Embrapa Informática Agropecuária-Artigo em anais de congresso (ALICE). In: WORLD CONGRESS OF GENETICS APPLIED TO LIVESTOCK PRODUCTION, 10., 2014, Vancouver. Proceedings... Champaign: American Society of Animal Science, 2014.



%33
@Article{33Redon,
  author =       "Redon, Richard and et al",
  title =        "Global variation in copy number in the human genome",
  year =         "2006",
  journal =      "nature",
  volume =       "444(7118)",
  pages =        "444-454",
}
Redon, Richard, et al. "Global variation in copy number in the human genome." nature 444.7118 (2006): 444-454.



%34
@Article{34Scherer,
  author =       "Scherer, Stephen W. and et al",
  title =        "Challenges and standards in integrating surveys of structural variation",
  year =         "2007",
  journal =      "Nature genetics",
  volume =       "39",
  pages =        "S7-S15",
}
Scherer, Stephen W., et al. "Challenges and standards in integrating surveys of structural variation." Nature genetics 39 (2007): S7-S15.


%35
@Article{35Liu,
  author =       "Liu, George E. and et al",
  title =        "Analysis of copy number variations among diverse cattle breeds.",
  year =         "2010",
  journal =      "Genome research",
  volume =       "20(5)",
  pages =        "693-703",
}
Liu, George E., et al. "Analysis of copy number variations among diverse cattle breeds." Genome research 20.5 (2010): 693-703.




%36
@Article{36She,
  author =       "She, Xinwei and et al",
  title =        "Mouse segmental duplication and copy number variation",
  year =         "2008",
  journal =      "Nature genetics",
  volume =       "40(7)",
  pages =        "909-914",
}
She, Xinwei, et al. "Mouse segmental duplication and copy number variation." Nature genetics 40.7 (2008): 909-914.



%37
@Article{37Yang,
  author =       "Yang, Tie-Lin and et al",
  title =        "Genome-wide copy-number-variation study identified a susceptibility gene, {UGT2B17}, for osteoporosis",
  year =         "2008",
  journal =      "The American Journal of Human Genetics",
  volume =       "83(6)",
  pages =        "663-674",
}
Yang, Tie-Lin, et al. "Genome-wide copy-number-variation study identified a susceptibility gene, UGT2B17, for osteoporosis." The American Journal of Human Genetics 83.6 (2008): 663-674.


%38
@Article{38Buckland,
  author =       "Buckland, Paul R.",
  title =        "Polymorphically duplicated genes: their relevance to phenotypic variation in humans",
  year =         "2003",
  journal =      "Annals of medicine",
  volume =       "35(5)",
  pages =        "308-315",
}
Buckland, Paul R. "Polymorphically duplicated genes: their relevance to phenotypic variation in humans." Annals of medicine 35.5 (2003): 308-315.




%39
@Article{39Nguyen,
  author =       "Nguyen, Duc-Quang, Caleb Webber, and Chris P. Ponting",
  title =        "Bias of selection on human copy-number variants",
  year =         "2006",
  journal =      "PLoS genetics",
  volume =       "2(2)",
  pages =        "e20"
}
Nguyen, Duc-Quang, Caleb Webber, and Chris P. Ponting. "Bias of selection on human copy-number variants." PLoS genetics 2.2 (2006): e20.

@article{karim2018recurrent,
  title={Recurrent Deep Embedding Networks for Genotype Clustering and Ethnicity Prediction},
  author={Karim, Md. Rezaul and Cochez, Michael and Decker, Stefan and Beyan, Oya},
  journal={arXiv preprint arXiv:1805.12218},
  year={2018}
}

@inproceedings{karim2019ecmlpkdd,
  title={Multimodal Deep Belief Networks for Prognostically Relevant Subtypes and Survival
Prediction for Breast Cancer (Under review)},
  author={Karim, Md. Rezaul and Galih, Wicaksono and Decker, Stefan and Beyan, Oya},
  booktitle={ECML-PKDD},
  year={2019}
}

@Article{40McCarroll,
  author =       "McCarroll, Steven A. and et al",
  title =        "Common deletion polymorphisms in the human genome",
  year =         "2006",
  journal =      "Nature genetics",
  volume =       "38(1)",
  pages =        "86-92",
}
McCarroll, Steven A., et al. "Common deletion polymorphisms in the human genome." Nature genetics 38.1 (2006): 86-92.

@article{fish,
  title={Association of Helicobacter pylori with gastric cancer and observations on the detection of this bacterium in gastric cancer cases.},
  author={Hu, PJ and Mitchell, HM and Li, YY and Zhou, MH and Hazell, SL},
  journal={American Journal of Gastroenterology},
  volume={89},
  number={10},
  year={1994}
}
@article{zeiler2012adadelta,
  title={ADADELTA: an adaptive learning rate method},
  author={Zeiler, Matthew D},
  journal={arXiv preprint arXiv:1212.5701},
  year={2012}
}

@article{paroder2006na+,
  title={Na+/monocarboxylate transport ({SMCT}) protein expression correlates with survival in colon cancer: molecular characterization of SMCT},
  author={Paroder, Viktoriya and Spencer, Shelly R and Paroder, Monika and Arango, Diego and Schwartz, Simo and Mariadason, John M and Augenlicht, Leonard H and Eskandari, Sepehr and Carrasco, Nancy},
  journal={Proceedings of the National Academy of Sciences},
  volume={103},
  number={19},
  pages={7270--7275},
  year={2006},
  publisher={National Acad Sciences}
}


@article{malekpour2018mseq,
  title={MSeq-CNV: accurate detection of Copy Number Variation from Sequencing of Multiple samples},
  author={Malekpour, Seyed Amir},
  journal={Scientific reports},
  volume={8},
  number={1},
  pages={4009},
  year={2018},
  publisher={Nature Publishing Group}
}


%41
@Article{41Friedman,
  author =       "Friedman, J. M. and et al",
  title =        "Oligonucleotide microarray analysis of genomic imbalance in children with mental retardation",
  year =         "2006",
  journal =      "The American Journal of Human Genetics",
  volume =       "79(3)",
  pages =        "500-513",
}
Friedman, J. M., et al. "Oligonucleotide microarray analysis of genomic imbalance in children with mental retardation." The American Journal of Human Genetics 79.3 (2006): 500-513.



%42
@Article{42Marshall,
  author =       "Marshall, Christian",
  title =        "Structural variation of chromosomes in autism spectrum disorder",
  year =         "2008",
  journal =      "The American Journal of Human Genetics",
  volume =       "82(2)",
  pages =        "477-488",
}
Marshall, Christian R., et al. "Structural variation of chromosomes in autism spectrum disorder." The American Journal of Human Genetics 82.2 (2008): 477-488.


%43
@Article{43Liu,
  author =       "Liu, Wennuan and et al",
  title =        "Association of a germ-line copy number variation at 2p24. 3 and risk for aggressive prostate cancer",
  year =         "2009",
  journal =      "Cancer research",
  volume =       "69(6)",
  pages =        "2176-2179",
}
Liu, Wennuan, et al. "Association of a germ-line copy number variation at 2p24. 3 and risk for aggressive prostate cancer." Cancer research 69.6 (2009): 2176-2179.


%44
@Article{44Thean,
  author =       "Thean, L. F. and et al",
  title =        "Genome wide scan identifies a copy number variable region at 3q26 that regulates {PPM1L} in APC mutation negative familial colorectal cancer patient",
  year =         "2010",
  journal =      "Genes, Chromosomes and Cancer",
  volume =       "49(2)",
  pages =        "99-106",
}
not good
Thean, L. F., et al. "Genome‐wide scan identifies a copy number variable region at 3q26 that regulates PPM1L in APC mutation‐negative familial colorectal cancer patients." Genes, Chromosomes and Cancer 49.2 (2010): 99-106.



%45
@Article{45Petrij,
  author =       "Petrij-Bosch, Anne and et al",
  title =        "{BRCA1} genomic deletions are major founder mutations in Dutch breast cancer patients",
  year =         "1997",
  journal =      "Nature genetics",
  volume =       "17(3)",
  pages =        "341-345",
}
Petrij-Bosch, Anne, et al. "BRCA1 genomic deletions are major founder mutations in Dutch breast cancer patients." Nature genetics 17.3 (1997): 341-345.



%46
@Article{46Montagna,
  author =       "Montagna, Marco and et al",
  title =        "Genomic rearrangements account for more than one-third of the {BRCA1} mutations in northern Italian breast/ovarian cancer families",
  year =         "2003",
  journal =      "Human molecular genetics",
  volume =       "12(9)",
  pages =        "1055-1061",
}
Montagna, Marco, et al. "Genomic rearrangements account for more than one-third of the BRCA1 mutations in northern Italian breast/ovarian cancer families." Human molecular genetics 12.9 (2003): 1055-1061.



%47
@Article{47Nørskov,
  author =       "Norskov, M. S. and et al",
  title =        "Copy number variation in glutathione-S-transferase {T1} and {M1} predicts incidence and 5-year survival from prostate and bladder cancer, and incidence of corpus uteri cancer in the general population",
  year =         "2011",
  journal =      "The pharmacogenomics journal",
  volume =       "11(4)",
  pages =        "292-299",
}
not good
Nørskov, M. S., et al. "Copy number variation in glutathione-S-transferase T1 and M1 predicts incidence and 5-year survival from prostate and bladder cancer, and incidence of corpus uteri cancer in the general population." The pharmacogenomics journal 11.4 (2011): 292-299.


%48
@Article{48Diskin,
  author =       "Diskin, Sharon J. and et al",
  title =        "Copy number variation at 1q21. 1 associated with neuroblastoma",
  year =         "2009",
  journal =      "Nature",
  volume =       "459(7249)",
  pages =        "987-991",
}
Diskin, Sharon J., et al. "Copy number variation at 1q21. 1 associated with neuroblastoma." Nature 459.7249 (2009): 987-991.



%49
@Article{49MacDonald,
  author =       "MacDonald, Jeffrey R. and et al",
  title =        "The Database of Genomic Variants: a curated collection of structural variation in the human genome",
  year =         "2013",
  journal =      "Nucleic acids research",
  volume =       "42(D1)",
  pages =        "D986-D992",
}
MacDonald, Jeffrey R., et al. "The Database of Genomic Variants: a curated collection of structural variation in the human genome." Nucleic acids research 42.D1 (2013): D986-D992.



%50
@Article{50Buchanan,
  author =       "Buchanan, Janet A. and Stephen W. Scherer",
  title =        "Contemplating effects of genomic structural variatio",
  year =         "2008",
  journal =      "Genetics in Medicine",
  volume =       "10(9)",
  pages =        "639-647",
}
not good
Buchanan, Janet A., and Stephen W. Scherer. "Contemplating effects of genomic structural variation." Genetics in Medicine 10.9 (2008): 639-647.



%51
@Article{51Craddock,
  author =       "Craddock, Nick and et al",
  title =        "Genome-wide association study of {CNVs} in 16,000 cases of eight common diseases and 3,000 shared controls",
  year =         "2010",
  journal =      "Nature",
  volume =       "464(7289)",
  pages =        "713-720",
}
Craddock, Nick, et al. "Genome-wide association study of CNVs in 16,000 cases of eight common diseases and 3,000 shared controls." Nature 464.7289 (2010): 713-720.



%52
@Article{52Cantsilieris,
  author =       "Cantsilieris, Stuart and Stefan J. White",
  title =        "Correlating multiallelic copy number polymorphisms with disease susceptibility",
  year =         "2013",
  journal =      "Human mutation",
  volume =       "34(1)",
  pages =        "1-13",
}
not good
Cantsilieris, Stuart, and Stefan J. White. "Correlating multiallelic copy number polymorphisms with disease susceptibility." Human mutation 34.1 (2013): 1-13.


%53
@Article{53Bowcock,
  author =       "Bowcock, Anne M",
  title =        "Invited review DNA copy number changes as diagnostic tools for lung cancer",
  year =         "2013",
  journal =      "thoraxjnl",
  volume =       "",
  pages =        "2013",
}
very bad
Bowcock, Anne M. "Invited review DNA copy number changes as diagnostic tools for lung cancer." Thorax (2013): thoraxjnl-2013.


%54
@Article{54Wang,
  author =       "Wang, Kai and et al",
  title =        "{PennCNV}: an integrated hidden Markov model designed for high-resolution copy number variation detection in whole-genome {SNP} genotyping data",
  year =         "2007",
  journal =      "Genome research",
  volume =       "17(11)",
  pages =        "1665-1674",
}
Wang, Kai, et al. "PennCNV: an integrated hidden Markov model designed for high-resolution copy number variation detection in whole-genome SNP genotyping data." Genome research 17.11 (2007): 1665-1674.



%55
@Article{55Pinto,
  author =       "Pinto, Dalila and et al",
  title =        "Copy-number variation in control population cohorts",
  year =         "2007",
  journal =      "Human molecular genetics",
  volume =       "16(R2)",
  pages =        "R168-R173",
}
Pinto, Dalila, et al. "Copy-number variation in control population cohorts." Human molecular genetics 16.R2 (2007): R168-R173.



%56
@Article{56Kim,
  author =       "Kim, Ji-Hong and et al",
  title =        "{CNVRuler}: a copy number variation-based case–control association analysis tool",
  year =         "2012",
  journal =      "Bioinformatics",
  volume =       "28(13)",
  pages =        "1790-1792",
}
very bad
Kim, Ji-Hong, et al. "CNVRuler: a copy number variation-based case–control association analysis tool." Bioinformatics 28.13 (2012): 1790-1792.


%57
@Article{57Yan,
  author =       "Yan, P. Yu and et al",
  title =        "Genomic copy number variations in the genomes of leukocytes predict prostate cancer clinical outcomes",
  year =         "2015",
  journal =      "PloS one",
  volume =       "10(8)",
  pages =        "e0135982",
}
very bad
Yan, P. Yu, et al. "Genomic copy number variations in the genomes of leukocytes predict prostate cancer clinical outcomes." PloS one 10.8 (2015): e0135982.



%58
@Article{58Kuusisto,
  author =       "Kuusisto, Kirsi M. and et al",
  title =        "Copy number variation analysis in familial {BRCA1}/2-negative Finnish breast and ovarian cancer",
  year =         "2013",
  journal =      "PloS one",
  volume =       "8(8)",
  pages =        "e71802",
}
very bad
Kuusisto, Kirsi M., et al. "Copy number variation analysis in familial BRCA1/2-negative Finnish breast and ovarian cancer." PloS one 8.8 (2013): e71802.



%59
@Article{59Hinton,
  author =       "Hinton, Geoffrey E. and Simon Osindero and Yee-Whye Teh",
  title =        "A fast learning algorithm for deep belief nets",
  year =         "2006",
  journal =      "Neural computation",
  volume =       "18(7)",
  pages =        "1527-1554",
}
Hinton, Geoffrey E., Simon Osindero, and Yee-Whye Teh. "A fast learning algorithm for deep belief nets." Neural computation 18.7 (2006): 1527-1554.


%60
@Article{60Fischer,
  author =       "Fischer, Asja, and Christian Igel",
  title =        "Training restricted Boltzmann machines: An introduction",
  year =         "2014",
  journal =      "Pattern Recognition",
  volume =       "47(1)",
  pages =        "25-39",
}
Fischer, Asja, and Christian Igel. "Training restricted Boltzmann machines: An introduction." Pattern Recognition 47.1 (2014): 25-39.


%61
@Article{61Hinton,
  author =       "Hinton, Geoffrey",
  title =        "A practical guide to training Restricted Boltzmann Machines ({RBM})",
  year =         "2010",
  journal =      "Momentum",
  volume =       "9(1)",
  pages =        "926",
}
Hinton, Geoffrey. "A practical guide to training restricted Boltzmann machines." Momentum 9.1 (2010): 926.


%62
@Article{62Hopfield,
  author =       "Hopfield, John J.",
  title =        "Neural networks and physical systems with emergent collective computational abilities.",
  year =         "1982",
  journal =      "Proceedings of the national academy of sciences",
  volume =       "79(8)",
  pages =        "2554-2558",
}
Hopfield, John J. "Neural networks and physical systems with emergent collective computational abilities." Proceedings of the national academy of sciences 79.8 (1982): 2554-2558.


%63
@Article{63Hinton,
  author =       "Hinton, Geoffrey E.",
  title =        "Training products of experts by minimizing contrastive divergence",
  year =         "2002",
  journal =      "Neural computation",
  volume =       "14(8)",
  pages =        "1771-1800",
}
Hinton, Geoffrey E. "Training products of experts by minimizing contrastive divergence." Neural computation 14.8 (2002): 1771-1800.


%64
@Article{64Charchar,
  author =       "Charchar, Fadi J. and et al",
  title =        "Whole Genome Survey of Copy Number Variation in the Spontaneously Hypertensive Rat",
  year =         "2010",
  journal =      "Hypertension",
  volume =       "55(5)",
  pages =        "1231-1238",
}
very bad
Charchar, Fadi J., et al. "Whole Genome Survey of Copy Number Variation in the Spontaneously Hypertensive Rat." Hypertension 55.5 (2010): 1231-1238.


%65
@Article{65Hinton,
  author =       "Hinton, Geoffrey E.",
  title =        "Deep Belief Networks, Scholarpedia, 4 (5): 5947",
  year =         "2009",
  journal =      "Available electronically at scholarpedia http://www. scholarpedia. org/article/Deep\_belief\_networks Hoppensteadt",
  volume =       "Hoppensteadt, FC",
  pages =        "129-35",
}
bad
Hinton, Geoffrey E. "Deep belief networks, Scholarpedia, 4 (5): 5947." Available electronically at http://www. scholarpedia. org/article/Deep_belief_networks Hoppensteadt, FC (2009): 129-35.
http://www. scholarpedia. org/article/Deep_belief_networks Hoppensteadt

%66
@Article{66Huang,
  author =       "Huang, Liming and et al",
  title =        "Copy number variation at 6q13 functions as a long-range regulator and is associated with pancreatic cancer risk",
  year =         "2011",
  journal =      "Carcinogenesis",
  volume =       "33(1)",
  pages =        "94-100",
}
Huang, Liming, et al. "Copy number variation at 6q13 functions as a long-range regulator and is associated with pancreatic cancer risk." Carcinogenesis 33.1 (2011): 94-100.


%67
@Article{67Calcagno,
  author =       "Calcagno, Danielle Queiroz and et al",
  title =        "{MYC, FBXW7 and TP53} copy number variation and expression in gastric cancer",
  year =         "2013",
  journal =      "BMC gastroenterology",
  volume =       "13(1)",
  pages =        "141",
}
Calcagno, Danielle Queiroz, et al. "MYC, FBXW7 and TP53 copy number variation and expression in gastric cancer." BMC gastroenterology 13.1 (2013): 141.


%68
@Article{68Hinton,
  author =       "Hinton, Geoffrey E. and et al",
  title =        "Improving neural networks by preventing co-adaptation of feature detectors",
  year =         "2012",
  journal =      "arXiv preprint arXiv",
  volume =       "1207(0580)",
  pages =        "",
}
Hinton, Geoffrey E., et al. "Improving neural networks by preventing co-adaptation of feature detectors." arXiv preprint arXiv:1207.0580 (2012).

%69
@Article{69Bengio,
  author =       "Bengio, Yoshua",
  title =        "Learning deep architectures for AI.",
  year =         "2009",
  journal =      "Foundations and trends in Machine Learning 2.1",
  volume =       "",
  pages =        "1-127",
}
Bengio, Yoshua. "Learning deep architectures for AI." Foundations and trends® in Machine Learning 2.1 (2009): 1-127.

%70
@Article{70Rezaul,
  author =       "Md. Rezaul Karim",
  title =        "Predictive Analytics with TensorFlow",
  year =         "2017",
  journal =      "Packt Publishing Ltd"
}

Md. Rezaul Karim, Predictive Analytics with TensorFlow, Packt Publishing Ltd., 2017

%71
@Article{71Torre,
  author =       "Torre, Lindsey A. and et al",
  title =        "Global cancer statistics, 2012",
  year =         "2015",
  journal =      "CA: a cancer journal for clinicians",
  volume =       "65(2)",
  pages =        "87-108",
}
Torre, Lindsey A., et al. "Global cancer statistics, 2012." CA: a cancer journal for clinicians 65.2 (2015): 87-108.

%72
@Article{72Breiman,
  author =       "Breiman, Leo",
  title =        "Random forests",
  year =         "2001",
  journal =      "Machine learning",
  volume =       "45(1)",
  pages =        "5-32",
}
Breiman, Leo. "Random forests." Machine learning 45.1 (2001): 5-32.

%73
@Article{73Breiman,
  author =       "Breiman, Leo",
  title =        "Bagging predictors",
  year =         "1996",
  journal =      "Machine learning",
  volume =       "24(2)",
  pages =        "123-140",
}
Breiman, Leo. "Bagging predictors." Machine learning 24.2 (1996): 123-140.

%74
@Article{74Dehzangi,
  author =       "Dehzangi, Abdollah, Somnuk Phon-Amnuaisuk, and Omid Dehzangi",
  title =        "Using Random Forest for Protein Fold Prediction Problem: An Empirical Study",
  year =         "2010",
  journal =      "J. Inf. Sci. Eng",
  volume =       "26(6)",
  pages =        "1941-1956",
}
Dehzangi, Abdollah, Somnuk Phon-Amnuaisuk, and Omid Dehzangi. "Using Random Forest for Protein Fold Prediction Problem: An Empirical Study." J. Inf. Sci. Eng. 26.6 (2010): 1941-1956.


%75
@Article{75Schapire,
  author =       "Schapire, Robert E",
  title =        "The strength of weak learnability",
  year =         "1990",
  journal =      "Machine learning",
  volume =       "5(2)",
  pages =        "197-227",
}
Schapire, Robert E. "The strength of weak learnability." Machine learning 5.2 (1990): 197-227.

%76
@Article{76Livingston,
  author =       "Livingston, Frederick",
  title =        "Implementation of Breiman random forest machine learning algorithm",
  year =         "2005",
  journal =      "Machine Learning Journal Paper",
  volume =       "ECE591Q",
  pages =        "",
}
Livingston, Frederick. "Implementation of Breiman’s random forest machine learning algorithm." ECE591Q Machine Learning Journal Paper (2005).

%77
@Article{77Breiman,
  author =       "Breiman, Leo and et al",
  title =        "Classification and regression trees",
  year =         "1984",
  journal =      "CRC press",
  volume =       "",
  pages =        "",
}
Breiman, Leo, et al. Classification and regression trees. CRC press, 1984.

%78
@Article{78Mingers,
  author =       "Mingers, John",
  title =        "An empirical comparison of selection measures for decision-tree induction",
  year =         "1989",
  journal =      "Machine learning",
  volume =       "3(4)",
  pages =        "319-342",
}
Mingers, John. "An empirical comparison of selection measures for decision-tree induction." Machine learning 3.4 (1989): 319-342.

%79
@Article{79Chan,
  author =       "Chan, Jonathan Cheung-Wai, and Desiré Paelinckx",
  title =        "Evaluation of Random Forest and Adaboost tree-based ensemble classification and spectral band selection for ecotope mapping using airborne hyperspectral imagery",
  year =         "2008",
  journal =      "Remote Sensing of Environment",
  volume =       "112(6)",
  pages =        "2999-3011",
}

Chan, Jonathan Cheung-Wai, and Desiré Paelinckx. "Evaluation of Random Forest and Adaboost tree-based ensemble classification and spectral band selection for ecotope mapping using airborne hyperspectral imagery." Remote Sensing of Environment 112.6 (2008): 2999-3011.

%80
@Article{80Pal,
  author =       "Pal, Mahesh, and Paul M. Mather",
  title =        "An assessment of the effectiveness of decision tree methods for land cover classification",
  year =         "2003",
  journal =      "Remote sensing of environment",
  volume =       "86(4)",
  pages =        "554-565",
}
Pal, Mahesh, and Paul M. Mather. "An assessment of the effectiveness of decision tree methods for land cover classification." Remote sensing of environment 86.4 (2003): 554-565.

%81
@Article{81Menze,
  author =       "Menze, Bjoern H. and et al",
  title =        "A comparison of random forest and its Gini importance with standard chemometric methods for the feature selection and classification of spectral data",
  year =         "2009",
  journal =      "BMC bioinformatics",
  volume =       "10(1)",
  pages =        "213",
}
Menze, Bjoern H., et al. "A comparison of random forest and its Gini importance with standard chemometric methods for the feature selection and classification of spectral data." BMC bioinformatics 10.1 (2009): 213.


%82
@Article{82Tomczak,
  author =   {Tomczak, Katarzyna and Patrycja, Czerwińska and Maciej Wiznerowicz},
  title =        {The Cancer Genome Atlas ({TCGA}): an immeasurable source of knowledge},
  year =         {2015},
  journal =      {Contemporary oncology},
  volume =       {19(1A)},
  pages =        {A68}
}

@misc{stat,
  title={Editorial for Cancer Virtual Issue},
  author={Blass, Benjamin E},
  year={2017},
  publisher={ACS Publications}
}

@article{wang2009rna,
  title={RNA-Seq: a revolutionary tool for transcriptomics},
  author={Wang, Zhong and Gerstein, Mark and Snyder, Michael},
  journal={Nature reviews genetics},
  volume={10},
  number={1},
  pages={57},
  year={2009},
  publisher={Nature Publishing Group}
}

@article{bartel2009micrornas,
  title={MicroRNAs: target recognition and regulatory functions},
  author={Bartel, David P},
  journal={cell},
  volume={136},
  number={2},
  pages={215--233},
  year={2009},
  publisher={Elsevier}
}
@article{yuan2018cancer,
  title={Cancer type prediction based on copy number aberration and chromatin 3D structure with convolutional neural networks},
  author={Yuan, Yuchen and Shi, Yi and Su, Xianbin and Zou, Xin and Luo, Qing and Feng, David Dagan and Cai, Weidong and Han, Ze-Guang},
  journal={BMC genomics},
  volume={19},
  number={6},
  pages={97},
  year={2018},
  publisher={BioMed Central}
}

@article{dna,
  title={Principles and challenges of genome-wide DNA methylation analysis},
  author={Laird, Peter W},
  journal={Nature Reviews Genetics},
  volume={11},
  number={3},
  pages={191},
  year={2010},
  publisher={Nature Publishing Group}
}
@article{dna2,
  title={A rapid method for determining sequences in DNA by primed synthesis with DNA polymerase},
  author={Sanger, Fred and Coulson, Alan R},
  journal={Journal of molecular biology},
  volume={94},
  number={3},
  pages={441--448},
  year={1975},
  publisher={Elsevier}
}

@article{CNV2,
  title={Integrated detection and population-genetic analysis of SNPs and copy number variation},
  author={McCarroll, Steven A and Kuruvilla, and Kirby, Andrew},
  journal={Nature genetics},
  volume={40},
  number={10},
  pages={1166},
  year={2008},
  publisher={Nature Publishing Group}
}

%83
@Article{83Leung,
  author =       "Leung, Michael KK and et al",
  title =        "Deep learning of the tissue-regulated splicing code",
  year =         "2014",
  journal =      "Bioinformatics",
  volume =       "30(12)",
  pages =        "i121-i129",
}
Leung, Michael KK, et al. "Deep learning of the tissue-regulated splicing code." Bioinformatics 30.12 (2014): i121-i129.


%84
@Article{84Lee,
  author =       "Lee, Taehoon, and Sungroh Yoon",
  title =        "Boosted categorical Restricted Boltzmann Machine for computational prediction of splice junctions",
  year =         "2015",
  journal =      "International Conference on Machine Learning",
  volume =       "",
  pages =        "",
}
Lee, Taehoon, and Sungroh Yoon. "Boosted categorical restricted Boltzmann machine for computational prediction of splice junctions." International Conference on Machine Learning. 2015.

%85
@Article{85Chen,
  author =       "Chen, Yifei and et al",
  title =        "Gene expression inference with deep learning",
  year =         "2016",
  journal =      "Bioinformatics",
  volume =       "32(12)",
  pages =        "1832-1839",
}
Chen, Yifei, et al. "Gene expression inference with deep learning." Bioinformatics 32.12 (2016): 1832-1839.

%86
@Article{86Leung,
  author =       "Leung, Michael KK and et al",
  title =        "Machine learning in genomic medicine: a review of computational problems and data sets",
  year =         "2016",
  journal =      "Proceedings of the IEEE",
  volume =       "104(1)",
  pages =        "176-197",
}
Leung, Michael KK, et al. "Machine learning in genomic medicine: a review of computational problems and data sets." Proceedings of the IEEE 104.1 (2016): 176-197.


%87
@Article{87Yim,
  author =       "Yim, Seon-Hee and et al",
  title =        "Clinical implications of copy number variations in autoimmune disorders",
  year =         "2015",
  journal =      "The Korean journal of internal medicine",
  volume =       "30(3)",
  pages =        "294",
}
Yim, Seon-Hee, et al. "Clinical implications of copy number variations in autoimmune disorders." The Korean journal of internal medicine 30.3 (2015): 294.


%88
@Article{88Lowe,
  author =       "Lowe, Craig B., et al",
  title =        "Detecting differential copy number variation between groups of samples",
  year =         "2017",
  journal =      "Genome research",
  volume =       "",
  pages =        "",
}
Lowe, Craig B., et al. "Detecting differential copy number variation between groups of samples." Genome research (2017).

%89
@Article{89Xie,
  author =       "Xie, Chao, and Martti T. Tammi",
  title =        "{CNV}-seq, a new method to detect copy number variation using high-throughput sequencing",
  year =         "2009",
  journal =      "BMC bioinformatics",
  volume =       "10(1)",
  pages =        "80",
}
Xie, Chao, and Martti T. Tammi. "CNV-seq, a new method to detect copy number variation using high-throughput sequencing." BMC bioinformatics 10.1 (2009): 80.

%90
@Article{90Rodriguez,
  author =       "Rodriguez-Galiano, Victor Francisco and et al",
  title =        "An assessment of the effectiveness of a random forest classifier for land-cover classification",
  year =         "2012",
  journal =      "{ISPRS} Journal of Photogrammetry and Remote Sensing",
  volume =       "67",
  pages =        "93-104",
}
Rodriguez-Galiano, Victor Francisco, et al. "An assessment of the effectiveness of a random forest classifier for land-cover classification." ISPRS Journal of Photogrammetry and Remote Sensing 67 (2012): 93-104.

%91
@Article{91Caruana,
  author =       "Caruana, Rich and et al",
  title =        "An empirical evaluation of supervised learning in high dimensions",
  year =         "2008",
  journal =      "Proceedings of the 25th international conference on Machine learning",
  volume =       "{ACM}",
  pages =        "",
}
Caruana, Rich, Nikos Karampatziakis, and Ainur Yessenalina. "An empirical evaluation of supervised learning in high dimensions." Proceedings of the 25th international conference on Machine learning. ACM, 2008.

%92
@Article{92aruana,
  author =       "Caruana, Rich and et al",
  title =        "An empirical comparison of supervised learning algorithms",
  year =         "2006",
  journal =      "Proceedings of the 23rd international conference on Machine learning",
  volume =       "{ACM}",
  pages =        "",
}
Caruana, Rich, and Alexandru Niculescu-Mizil. "An empirical comparison of supervised learning algorithms." Proceedings of the 23rd international conference on Machine learning. ACM, 2006.

%93
@Article{93Bahadure,
  author =       "Bahadure, Nilesh Bhaskarrao and et al",
  title =        "Image analysis for MRI based brain tumor detection and feature extraction using biologically inspired BWT and SVM",
  year =         "2017",
  journal =      "International journal of biomedical imaging",
  volume =       "",
  pages =        "",
}
Bahadure, Nilesh Bhaskarrao, Arun Kumar Ray, and Har Pal Thethi. "Image analysis for MRI based brain tumor detection and feature extraction using biologically inspired BWT and SVM." International journal of biomedical imaging 2017 (2017).

%94
@Article{94Padmanabhan,
  author =       "Padmanabhan, Sharanya, and Raji Sundararajan",
  title =        "Enhanced accuracy of breast cancer detection in digital mammograms using wavelet analysis",
  year =         "2012",
  journal =      "Machine Vision and Image Processing ({MVIP}), 2012 International Conference on",
  volume =       "{IEEE}",
  pages =        "",
}
Padmanabhan, Sharanya, and Raji Sundararajan. "Enhanced accuracy of breast cancer detection in digital mammograms using wavelet analysis." Machine Vision and Image Processing (MVIP), 2012 International Conference on. IEEE, 2012.

%95
@Article{95Gaul,
  author =       "Gaul, David A. and et al",
  title =        "Highly-accurate metabolomic detection of early-stage ovarian cancer",
  year =         "2015",
  journal =      "Scientific reports",
  volume =       "5",
  pages =        "16351",
}
@article{mmsurvey,
  title={Multimodal machine learning: A survey and taxonomy},
  author={Baltru{\v{s}}aitis, Tadas and Ahuja, Chaitanya and Morency, Louis-Philippe},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={2},
  pages={423--443},
  year={2018},
  publisher={IEEE}
}
@article{wb,
  title={The Cancer Genome Workbench: identifying and visualizing complex genetic alterations in tumors},
  author={Zhang, J and Finney, R and Edmonson, M and Schaefer, C and Rowe, W and Yan, C and Clifford, R and Greenblum, S and Wu, G and Zhang, H and others},
  journal={NCI Nature Pathway Interaction Database},
  year={2010}
}
@article{atrey2010multimodal,
  title={Multimodal fusion for multimedia analysis: a survey},
  author={Atrey, Pradeep K and Hossain, M Anwar and El Saddik, Abdulmotaleb and Kankanhalli, Mohan S},
  journal={Multimedia systems},
  volume={16},
  number={6},
  pages={345--379},
  year={2010},
  publisher={Springer}
}
@inproceedings{thiam2020multimodal,
  title={Multimodal Deep Denoising Convolutional Autoencoders for Pain Intensity Classification based on Physiological Signals.},
  author={Thiam, Patrick and Kestler, Hans A and Schwenker, Friedhelm},
  booktitle={ICPRAM},
  pages={289--296},
  year={2020}
}
@article{clevert2015fast,
  title={Fast and accurate deep network learning by exponential linear units (elus)},
  author={Clevert, Djork-Arn{\'e} and Unterthiner, Thomas and Hochreiter, Sepp},
  journal={arXiv preprint arXiv:1511.07289},
  year={2015}
}
@article{mmdcae,
  title={Multimodal Deep Denoising Convolutional Autoencoders for Pain Intensity Classification based on Physiological Signals},
  author={Patrick, Thiam and Hans, A. K. and Friedhelm, S.},
  journal={The International Conference on Pattern Recognition Applications and Methods},
  year={2020}
}
@article{BO,
  title={Bayesian optimization},
  author={Martin Krasser},
  url={http://krasserm.github.io/2018/03/21/bayesian-optimization/},
  year={2028}
}
@misc{diakopoulos2017algorithmic,
  title={Algorithmic transparency in the news media. Digital Journalism 5, 7 (2017), 809--828},
  author={Diakopoulos, Nicholas and Koliska, Michael},
  year={2017}
}
@inproceedings{ying2019gnnexplainer,
  title={Gnnexplainer: Generating explanations for graph neural networks},
  author={Ying, Zhitao and Bourgeois, Dylan and You, Jiaxuan and Zitnik, Marinka and Leskovec, Jure},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9240--9251},
  year={2019}
}
@article{das2020opportunities,
  title={Opportunities and Challenges in Explainable Artificial Intelligence (XAI): A Survey},
  author={Das, Arun and Rad, Paul},
  journal={arXiv preprint arXiv:2006.11371},
  year={2020}
}
@book{garoufallou2016metadata,
  title={Metadata and Semantics Research: 10th International Conference, MTSR 2016, G{\"o}ttingen, Germany, November 22-25, 2016, Proceedings},
  author={Garoufallou, Emmanouel and Coll, Imma Subirats and Stellato, Armando and Greenberg, Jane},
  volume={672},
  year={2016},
  publisher={Springer}
}
@article{oltramari2020neuro,
  title={Neuro-symbolic Architectures for Context Understanding},
  author={Oltramari, Alessandro and Francis, Jonathan and Henson, Cory and Ma, Kaixin and Wickramarachchi, Ruwan},
  journal={arXiv preprint arXiv:2003.04707},
  year={2020}
}
@article{alshahrani2017neuro,
  title={Neuro-symbolic representation learning on biological knowledge graphs},
  author={Alshahrani, Mona and Khan, Mohammad Asif and Maddouri, Omar and Kinjo, Akira R and Queralt-Rosinach, N{\'u}ria and Hoehndorf, Robert},
  journal={Bioinformatics},
  volume={33},
  number={17},
  pages={2723--2730},
  year={2017},
  publisher={Oxford University Press}
}
@article{berk2017convex,
  title={A convex framework for fair regression},
  author={Berk, Richard and Heidari, Hoda and Jabbari, Shahin and Joseph, Matthew and Kearns, Michael and Morgenstern, Jamie and Neel, Seth and Roth, Aaron},
  journal={arXiv preprint arXiv:1706.02409},
  year={2017}
}
@article{fairness_survey,
  title={A survey on bias and fairness in machine learning},
  author={Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
  journal={arXiv preprint arXiv:1908.09635},
  year={2019}
}
@inproceedings{verma2018fairness,
  title={Fairness definitions explained},
  author={Verma, Sahil and Rubin, Julia},
  booktitle={2018 IEEE/ACM International Workshop on Software Fairness (FairWare)},
  pages={1--7},
  year={2018},
  organization={IEEE}
}
@article{biasList,
  title={Social data: Biases, methodological pitfalls, and ethical boundaries},
  author={Olteanu, Alexandra and Castillo, Carlos and Diaz, Fernando and Kiciman, Emre},
  journal={Frontiers in Big Data},
  volume={2},
  pages={13},
  year={2019},
  publisher={Frontiers}
}
@article{POSTF,
  title={Double agents: genes with both oncogenic and tumor-suppressor functions},
  author={Shen, Libing and Shi, Qili and Wang, Wenyuan},
  journal={Oncogenesis},
  volume={7},
  number={3},
  pages={1--14},
  year={2018},
  publisher={Nature Publishing Group}
}
@article{SAI,
  title={Symbolic Reasoning (Symbolic AI) and Machine Learning},
  author={Path Mind, Inc.},
  url={https://pathmind.com/wiki/symbolic-reasoning/},
  year={2020}
}
@article{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}
%96
@article{96Karim,
  title={A Deep Learning Approach to Genomics Data for Population Scale Clustering and Ethnicity Prediction},
  author={Karim, Md Rezaul and Zappa, Achille and Sahay, Ratnesh and Rebholz-Schuhmann, Dietrich},
  booktitle={Proceedings of 1st international {ESWC}'2017 workshop Semantic Web solutions for large-scale biomedical data analytics ({SeWeBMeDA}'17)},
  pages={1--15},
  publisher={ESWC},
  year={2017}
}

%97
@Article{97Quinlan,
  author =       "Quinlan, J. Ross",
  title =        "C4.5: programs for machine learning",
  year =         "1993",
  journal =      "Elsevier",
  volume =       "",
  pages =        "",
}
Quinlan, J. Ross. C4. 5: programs for machine learning. Elsevier, 1993.

%98
@Article{98roccurve,
  author =       "",
  title =        "http://algolytics.com/how-to-assess-quality-and-correctness-of-classification-models-part-4-roc-curve/",
  year =         "",
  journal =      "",
  volume =       "",
  pages =        "",
}

%
@Article{11111111111,
  author =       "and et al",
  title =        "",
  year =         "20",
  journal =      "",
  volume =       "()",
  pages =        "",
}

@article{dai,
    title = "Breast cancer intrinsic subtype classification, clinical use and future trends",
    author = "Xiaofeng Dai and Ting Li and Zhonghu Bai",
    journal = "American Journal of Cancer Research",
    volume = "5",
    year = "2015",
    number = {10},
    pages = "2929--2943"
}

@article{sorlie,
    title = "Repeated observation of breast tumor subtypes in independent gene expression data sets",
    author = "Therese Sorlie and Robert Tibshirani and Joel Parker and others",
    journal = "Proceedings of the National Academy of Sciences of the United States of America",
    volume = "100",
    year = "2003",
    number = {14},
    pages = "8418--8423"
}

@inproceedings{arel,
	author    = {Itamar Arel and Derek Rose and Robert Coop},
	title     = {DeSTIN: A Scalable Deep Learning Architecture with Application to High-Dimensional Robust Pattern Recognition},
	booktitle = {AAAI Workshop on Biologically Inspired Cognitive Architectures},
	year      = {2009},
	pages = "1150--1157"
}
 
@book{karim,
    title = {Predictive Analytics with TensorFlow},
    author = {Md Rezaul Karim},
    isbn = {9781788398923},
    year = {2017},
    publisher = {Packt Publishing Ltd.}
}
@inproceedings{wang2020score,
  title={Score-CAM: Score-Weighted Visual Explanations for Convolutional Neural Networks},
  author={Wang, Haofan and Wang, Zifan and Du, Mengnan and Yang, Fan and Zhang, Zijian and Ding, Sirui and Mardziel, Piotr and Hu, Xia},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  pages={24--25},
  year={2020}
}
@book{karimIoT2019,
    title = {Hands-on Deep Learning for IoT},
    author = {Md. Abdur Razzaque and Md Rezaul Karim},
    isbn = {9781789616132},
    year = {2019},
    publisher = {Packt Publishing Ltd.}
}

@book{karimScalaML2019,
    title = {Scala Machine Learning Quick Start Guide},
    author = {Md Rezaul Karim},
    isbn = {9781789345070},
    year = {2019},
    publisher = {Packt Publishing Ltd.}
}


@inproceedings{wang2018associativemulti,
  title={Associative Multichannel Autoencoder for Multimodal Word Representation},
  author={Wang, Shaonan and Zhang, Jiajun and Zong, Chengqing},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={115--124},
  year={2018}
}
@article{Hinton:2009,
AUTHOR = {Hinton, G. E.},
TITLE   = {{D}eep belief networks},
YEAR    = {2009},
JOURNAL = {Scholarpedia},
VOLUME  = {4},
NUMBER  = {5},
PAGES   = {5947},
DOI     = {10.4249/scholarpedia.5947},
NOTE    = {revision \#91189}
}
@article{liu2016multimodal,
  title={Multimodal video classification with stacked contractive autoencoders},
  author={Liu, Yanan and Feng, Xiaoqing and Zhou, Zhiguang},
  journal={Signal Processing},
  volume={120},
  pages={761--766},
  year={2016},
  publisher={Elsevier}
}
@book{karim2017predictive,
  title={Predictive Analytics with TensorFlow: Implement deep learning principles to predict valuable insights using TensorFlow},
  author={Karim, Md Rezaul},
  year={2017},
  publisher={Packt Publishing Ltd}
}
@article{serban2016multi,
  title={Multimodal video classification with stacked contractive autoencoders},
  author={Liu, Yanan and Feng, Xiaoqing and Zhou, Zhiguang},
  journal={Signal Processing},
  volume={120},
  pages={761--766},
  year={2016},
  publisher={Elsevier}
}
@book{karimDLTF2018,
    title = {Deep Learning with TensorFlow - Second Edition},
    author = {Giancarlo Zaccone and Md Rezaul Karim },
    isbn = {9781788831109},
    year = {2018},
    publisher = {Packt Publishing Ltd.}
}

@book{hastie,
    title = {The Elements of Statistical Learning},
    author = {Trevor Hastie and Robert Tibshirani and Jerome Friedman},
    isbn = {0-387-95284-5},
    year = {2008},
    publisher = {Springer}
}

@article{chial,
    title = "DNA Sequencing Technologies Key to the Human Genome Project",
    author = "Heidi Chial",
    journal = "Nature Education",
    volume = "1",
    year = "2008",
    number = {1},
    pages = "219"
}

@article{turchenko,
    title = {A Deep Convolutional Auto-Encoder with Pooling-Unpooling Layers in Caffe},
    author = {Volodymyr Turchenko and Eric Chalmers and Artur Luczak},
    year = {2017},
    journal = {arXiv:1701.04949}
}

@article{graves,
    title = {Multi-Dimensional Recurrent Neural Networks},
    author = {Alex Graves and Santiago Fernandez and Jurgen Schmidhuber},
    year = {2007},
    journal = {arXiv:0705.2011}
}

@article{tomasetti,
    title = "Stem cell divisions, somatic mutations, cancer etiology, and cancer prevention",
    author = "Cristian Tomasetti and Lu Li and Bert Vogelstein",
    journal = "Science",
    volume = "355",
    year = "2017",
    number = {6331},
    pages = "1330--1334"
}

@techreport{reinsel,
  author       = {David Reinsel and John Gantz and John Rydning}, 
  title        = {Data Age 2025: The Evolution of Data to Life-Critical},
  institution  = {International Data Corporation},
  year         = 2017,
  month        = 4,
}

@article{forbes,
    title = "COSMIC: mining complete cancer genomes in the Catalogue of Somatic Mutations in Cancer",
    author = "Simon A Forbes and Nidhi Bindal and Sally Bamford and Charlotte Cole and Chai Yin Kok and David Beare and Mingming Jia and Rebecca Shepherd and Kenric Leung and Andrew Menzies and Jon W Teague and Peter J Campbell and Michael R Stratton and P Andrew Futreal",
    journal = "Nucleic Acids Res.",
    volume = "39",
    year = "2011",
}

@inproceedings{salcedo-bernala,
  author    = {A Salcedo-Bernala and M P Villamil-Giraldoa and A D Moreno-Barbosa},
  title     = {Clinical Data Analysis: An opportunity to compare machine learning methods},
  booktitle = {Conference on ENTERprise Information Systems / International Conference on Project
MANagement / Conference on Health and Social Care Information Systems and Technologies,
CENTERIS},
  organization = {International Society for Optics and Photonics},
  year      = {2015}
}

@article{orphanidou,
    title = {Machine Learning Models for Multidimensional Clinical Data},
    author = {Christina Orphanidou and David Wong},
    journal = {Handbook of Large-Scale Distributed Computing in Smart Healthcare},
    volume = {13},
    number = {94},
    year = {2014},
    pages = {177--216}
}

@article{foster,
    title = "Machine learning, medical diagnosis, and biomedical engineering research",
    author = "Kenneth R Foster and Robert Koprowski and Joseph D Skufca",
    journal = "BioMedical Engineering OnLine",
    volume = "13",
    number = {94},
    year = "2014",
    pages = "1--9"
}

@article{libbrecht,
    title = "Machine learning in genetics and genomics",
    author = "Maxwell W Libbrecht and William Stafford Noble",
    journal = "Nature Reviews",
    volume = "16",
    number = {6},
    year = "2015",
    pages = "321--332"
}

@article{nussinov,
    title = "Advancements and Challenges in Computational Biology",
    author = "Ruth Nussinov",
    journal = "PLOS Computational Biology",
    volume = "11",
    number = {1},
    year = "2015"
}

@article{alipanahi,
    title = "Predicting the sequence specificities of DNA-and RNA-binding proteins by deep learning",
    author = "Babak Alipanahi and Andrew Delong and Matthew T Weirauch and Brendan J Frey",
    journal = "Nature biotechnology",
    volume = "33",
    number = {8},
    year = "2015",
    pages = "831--839"
}

@article{an,
    title = "A Deep Learning Method for Classification of EEG Data Based on Motor Imagery",
    author = "Xiu An and Deping Kuang and Xiaojiao Guo and Yilu Zhao and Lianghua He",
    journal = "Intelligent Computing in Bioinformatics",
    year = "2014",
    pages = "203--210",
}

@article{asgari,
    title = "Continuous Distributed Representation of Biological Sequences for Deep Proteomics and Genomics",
    author = "Ehsaneddin Asgari and Mohammad R. K. Mofrad",
    journal = "PLoS ONE",
    year = "2015"
}

@misc{backpropagation,
  title = {How the backpropagation algorithm works},
  howpublished = {\url{http://neuralnetworksanddeeplearning.com/chap2.html}},
  note = {Accessed: 2017-02-28}
}

@unpublished{bahrampour,
  author    = {Soheil Bahrampour and Naveen Ramakrishnan and Lukas Schott and Mohak Shah},
  title     = {Comparative Study of Deep Learning Software Frameworks},
  note      = {arXiv preprint arXiv:1511.06435 2015},
  year	    = {2015}
}

@article{baldi99,
    title = "Exploiting the past and the future in protein secondary structure prediction",
    author = "Pierre Baldi and Soren Brunak and Paolo Frasconi and Giovanni Soda and Gianluca Pollastri",
    journal = "Bioinformatics",
    volume = "15",
    number = {11},
    year = "1999",
    pages = "937--946"
}

@inproceedings{baldi00,
  author    = {Pierre Baldi and Gianluca Pollastri and Claus A. F. Andersen and Soren Brunak},
  title     = {Matching protein beta-sheet partners by feedforward and recurrent neural networks},
  organization = {Proceedings of the 2000 Conference on Intelligent Systems for Molecular Biology},
  pages     = {25--36},
  year      = {2000}
}

@inproceedings{bar,
  author    = {Yaniv Bar and Idit Diamant and Lior Wolf and Hayit Greenspan},
  title     = {Deep learning with non-medical training used for chest pathology identification},
  booktitle = {SPIE Medical Imaging},
  organization = {International Society for Optics and Photonics},
  year      = {2015}
}

@misc{cancernet,
  title = {The Genetics of Cancer},
  howpublished = {\url{http://www.cancer.net/navigating-cancer-care/cancer-basics/genetics/genetics-cancer}},
  note = {Accessed: 2017-02-28}
}

@inproceedings{cecotti08,
  author    = {Hubert Cecotti and Axel Graeser},
  title     = {Convolutional neural network with embedded Fourier transform for EEG classification},
  booktitle = {19th International Conference on Pattern Recognition, 2008. ICPR 2008.},
  organization = {IEEE},
  pages     = {1--4},
  year      = {2008}
}

@article{cecotti11,
    title = "Convolutional neural networks for P300 detection with application to braincomputer interfaces",
    author = "Hubert Cecotti and Axel Graeser",
    journal = "IEEE Transactions on Pattern Analysis and Machine Intelligence",
    volume = "33",
    number = {3},
    pages = "433--445",
    year = "2011",
}

@article{chenC,
    title = "Deep Learning in Label-free Cell Classification",
    author = "Claire Lifan Chen and Ata Mahjoubfar and Li-Chia Tai and Ian K. Blaby and Allen Huang and Kayvan Reza Niazi and Bahram Jalali",
    journal = "Scientific reports",
    volume = "6",
    year = "2016",
}

@article{chenY,
    title = "Gene expression inference with deep learning",
    author = "Yifei Chen and Yi Li and Rajiv Narayan and Aravind Subramanian and Xiaohui Xie",
    journal = "Bioinformatics",
    volume = "32",
    number = {12},
    year = "2016",
    pages = "1832--1839",
}

@unpublished{cho,
  author    = {Junghwan Cho and Kyewook Lee and Ellie Shin and Garry Choy and Synho Do}, 
  title     = {Medical Image Deep Learning with Hospital PACS Dataset},
  note      = {arXiv preprint arXiv:1511.06348},
  year	    = {2015}
}

@inproceedings{ciresan12,
  author    = {Dan C. Ciresan and Alessandro Giusti and Luca M. Gambardella and Jurgen Schmidhuber},
  title     = {Deep neural networks segment neuronal membranes in electron microscopy images},
  booktitle = {Advances in neural information processing systems},
  pages     = "2843--2851",
  year      = {2012}
}

@article{ciresan13,
    title = "Mitosis detection in breast cancer histology images with deep neural networks",
    author = "Dan C. Ciresan and Alessandro Giusti and Luca M. Gambardella and Jurgen Schmidhuber",
    journal = "Medical Image Computing and Computer-Assisted Intervention--MICCAI 2013",
    year = "2013",
    pages = "411--418",
}

@article{cruz-roa,
    title = "A deep learning architecture for image representation, visual interpretability and automated basal-cell carcinoma cancer detection",
    author = "Angel Alfonso Cruz-Roa and John Edison Arevalo Ovalle and Anant Madabhushi and Fabio Augusto González Osorio",
    journal = "Medical Image Computing and Computer-Assisted Intervention--MICCAI 2013",
    year = "2013",
    pages = "403--410",
}

@article{davidson,
    title = "EEG-based lapse detection with high temporal resolution",
    author = "Paul R. Davidson and Richard D. Jones and Malik T. R. Peiris",
    journal = "IEEE Transactions on Biomedical Engineering",
    volume = "54",
    number = "5", 
    year = "2007",
    pages = "832--839",
}

@misc{deepmindhealth,
  title = {DeepMind Health},
  howpublished = {\url{https://deeplearning4j.org/}},
  note = {Accessed: 2017-03-02}
}

@inproceedings{denas,
  author    = {Olgert Denas and James Taylor},
  title     = {Deep modeling of gene expression regulation in an Erythropoiesis model},
  booktitle = {International Conference on Machine
Learning workshop on Representation Learning},
  year      = {2013}
}

@misc{dl4j,
  title = {Deeplearning4j: Open-source distributed deep learning for the JVM},
  howpublished = {\url{https://dcc.icgc.org/}},
  note = {Accessed: 2017-02-28}
}

@inproceedings{fakoor,
  author    = {Rasool Fakoor and Faisal Ladhak and Azade Nazi and Manfred Huber},
  title     = {Using deep learning to enhance cancer diagnosis and classification},
  booktitle = {Proc. of the Intl. Conf. on Machine Learning},
  year      = {2013}
}

@book{fletcher,
  author    = {Roger Fletcher}, 
  title     = {Practical methods of optimization},
  publisher = {John Wiley and Sons},
  year      = 1987,
  edition   = 2,
  isbn      = {978-0-471-91547-8}
}

@article{freudenburg,
  author    = {Zachary V. Freudenburg and Nicolas F. Ramsey and Mark Wronkiewicz and William D. Smart and Robert Pless and Eric C. Leuthardt},
  title     = {Real-time naive learning of neural correlates in ECoG Electrophysiology},
  journal = {International Journal of Machine Learning and Computing},
  volume    = "1",
  number    = {3},
  year      = {2011},
  pages     = "269--278",
}

@manual{gdc,
  title        = {GDC API Users Guide},
  organization = {NCI Genomic Data Commons (GDC)},
  month        = 6,
  year         = 2017
}

@article{gerven,
    title = "Neural decoding with hierarchical generative models",
    author = "Marcel A. J. van Gerven and Floris P. de Lange and Tom Heskes",
    journal = "Neural Computation",
    volume = "22",
    number = {12},
    year = "2010",
    pages = "3127--3142",
}

@article{graves,
    title = "Offline handwriting recognition with multidimensional recurrent neural networks",
    author = "Alex Graves and Jurgen Schmidhuber",
    journal = "Advances in neural information processing systems",
    year = "2009",
    pages = "545--552",
}

@article{griffiths-jones1,
    title = "miRBase: tools for microRNA genomics",
    author = "Sam Griffiths-Jones and Harpreet Kaur Saini and Stijn van Dongen and Anton J. Enright",
    journal = "Nucleic Acids Res",
    volume = "36",
    number = {1},
    year = "2008",
    pages = "154--158",
}

@article{griffiths-jones2,
    title = "miRBase: microRNA sequences, targets and gene nomenclature",
    author = "Sam Griffiths-Jones and Russell J. Grocock and Stijn van Dongen and Alex Bateman and Anton J. Enright",
    journal = "Nucleic Acids Res",
    volume = "34",
    number = {1},
    year = "2006",
    pages = "140--144",
}

@article{griffiths-jones3,
    title = "The microRNA Registry",
    author = "Sam Griffiths-Jones",
    journal = "Nucleic Acids Res",
    volume = "32",
    number = {1},
    year = "2004",
    pages = "109--111",
}

@misc{hackernoon,
  title = {Log Analytics With Deep Learning And Machine Learning},
  howpublished = {\url{https://hackernoon.com/log-analytics-with-deep-learning-and-machine-learning-20a1891ff70e}},
  note = {Accessed: 2017-06-28}
}

@article{hadsell,
    title = "Learning long-range vision for autonomous off-road driving",
    author = "Marcel A. J. van Gerven and Floris P. de Lange and Tom Heskes",
    journal = "Journal of Field Robotics",
    volume = "26",
    number = {2},
    year = "2009",
    pages = "120--144",
}

@unpublished{havaei,
  author    = {Mohammad Havaei and Axel Davy and David Warde-Farley and Antoine Biard and Aaron Courville and Yoshua Bengio and Chris Pal and Pierre-Marc Jodoin and Hugo Larochelle}, 
  title     = {Brain Tumor Segmentation with Deep Neural Networks},
  note      = {arXiv preprint arXiv:1505.03540},
  year	    = {2015}
}

@techreport{heffernan,
  author       = {Rhys Heffernan and Kuldip Paliwal and James Lyons and Abdollah Dehzangi and Alok Sharma and Jihua Wang and Abdul Sattar and Yuedong Yang and Yaoqi Zhou}, 
  title        = {Improving prediction of secondary structure, local backbone angles, and solvent accessible surface area of proteins by iterative deep learning},
  institution  = {Nature},
  year         = 2015
}

@article{helmstaedter,
    title = "Connectomic reconstruction of the inner plexiform layer in the mouse retina",
    author = "Moritz Helmstaedter and Kevin L. Briggman and Srinivas C. Turaga and Viren Jain and H. Sebastian Seung and Winfried Denk",
    journal = "Nature",
    volume = "500",
    number = {7461},
    year = "2013",
    pages = "168--174"
}

@article{hinton,
    title = "Reducing the Dimensionality of Data with Neural Networks",
    author = "G. E. Hinton and R. R. Salakhutdinov",
    journal = "Science",
    volume = "313",
    number = {5786},
    year = "2006",
    pages = "504--507"
}

@techreport{hinton2,
  author       = {Geoffrey Hinton}, 
  title        = {A Practical Guide to Training Restricted Boltzmann Machines},
  institution  = {Department of Computer Science, University of Toronto},
  year         = 2010,
  month        = 8,
}

@phdthesis{hochreiter91,
  author       = {S. Hochreiter}, 
  title        = {Untersuchungen zu dynamischen neuronalen Netzen},
  school       = {Technische Univ. Munich},
  year         = 1991,
  address      = {Munich},
}

@article{hochreiter07,
    title = "Fast model-based protein homology detection without alignment",
    author = "Sepp Hochreiter and Martin Heusel and Klaus Obermayer",
    journal = "Bioinformatics",
    volume = "23",
    number = {14},
    year = "2007",
    pages = "1728--1736"
}

@article{hua,
    title = "Computer-aided classification of lung nodules on computed tomography images via deep learning technique",
    author = "Kai-Lung Hua and Che-Hao Hsu and Shintami Chusnul Hidayati and Wen-Huang Cheng and Yu-Jen Chen",
    journal = "OncoTargets and therapy",
    volume = "8",
    number = {12},
    year = "2015",
    pages = "2015--2022",
}

@inproceedings{huanhuan,
  author    = {Meng Huanhuan and Zhang Yue},
  title     = {Classification of Electrocardiogram Signals with Deep Belief Networks},
  booktitle = {2014 IEEE 17th International Conference on Computational Science and Engineering (CSE)},
  organization = {IEEE},
  pages     = {7--12},
  year      = {2014}
}

@inproceedings{ibrahim,
  author    = {Rania Ibrahim and Noha A. Yousri and Mohamed A. Ismail and Nagwa M. El-Makky},
  title     = {Multi-Level Gene/MiRNA Feature Selection using Deep Belief Nets and Active Learning},
  booktitle = {2014 36th Annual International Conference Eng. Med. Biol. Soc. (EMBC)},
  organization = {IEEE},
  pages     = {3957--3960},
  year      = {2014}
}

@misc{ibm,
  title = {Manipal Hospitals announces national launch of IBM Watson for Oncology},
  howpublished = {\url{https://www-03.ibm.com/press/in/en/pressrelease/50290.wss}},
  note = {Accessed: 2017-03-01}
}

@misc{icgc,
  title = {{ICGC} Data Portal},
  howpublished = {\url{https://dcc.icgc.org/}},
  note = {Accessed: 2017-02-28}
}

@book{ivakhnenko,
  author = "Alexey Ivakhnenko",
  title = "Cybernetic Predicting Devices",
  year = 1965,
  publisher = "Naukova Dumka",
}

@inproceedings{jia,
  author    = {Xiaowei Jia and  Kang Li and  Xiaoyi Li and  Aidong Zhang},
  title     = {A Novel Semi-Supervised Deep Learning Framework for Affective State Recognition on EEG Signals},
  booktitle = {2014 IEEE International
Conference on Bioinformatics and Bioengineering (BIBE)},
  organization = {IEEE},
  pages     = {30--37},
  year      = {2014}
}

@article{jirayucharoensak,
    title = "EEG-based emotion recognition using deep learning network with principal component based covariate shift adaptation",
    author = "Suwicha Jirayucharoensak and Setha Pan-Ngum and Pasin Israsena",
    journal = "The Scientific World Journal",
    year = "2014",
}

@unpublished{kelley,
  author       = {David R. Kelley and Jasper Snoek and John L. Rinn}, 
  title        = {Basset: Learning the regulatory code of the accessible genome with deep convolutional neural networks},
  note         = {bioRxiv 2015:028399},
  year         = 2017
}

@article{DBLP:journals/corr/KingmaB14,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  title     = {Adam: {A} Method for Stochastic Optimization},
  journal   = {CoRR},
  volume    = {abs/1412.6980},
  year      = {2014},
  url       = {http://arxiv.org/abs/1412.6980},
  timestamp = {Wed, 07 Jun 2017 14:40:52 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/KingmaB14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@unpublished{koyamada,
  author    = {Sotetsu Koyamada and Yumi Shikauchi and Ken Nakae and Masanori Koyama and Shin Ishii}, 
  title     = {Deep learning of fMRI big data: a novel approach to subject-transfer decoding},
  note      = {arXiv preprint arXiv:1502.00093},
  year	    = {2015}
}

@article{kozomara1,
    title = "miRBase: annotating high confidence microRNAs using deep sequencing data",
    author = "Ana Kozomara and Sam Griffiths-Jones",
    journal = "Nucleic Acids Res",
    volume = "42",
    number = {1},
    year = "2014",
    pages = "68--73",
}

@article{kozomara2,
    title = "miRBase: integrating microRNA annotation and deep-sequencing data",
    author = "Ana Kozomara and Sam Griffiths-Jones",
    journal = "Nucleic Acids Res",
    volume = "39",
    number = {1},
    year = "2011",
    pages = "152--157",
}

@unpublished{lanchantin,
  author       = {Jack Lanchantin and Ritambhara Singh and Zeming Lin and Yanjun Qi}, 
  title        = {Deep motif: Visualizing genomic sequence classifications},
  note         = {arXiv preprint arXiv:1605.01133},
  year         = 2016
}

@article{langkvist,
    title = "Sleep stage classification using unsupervised feature learning",
    author = "Martin Langkvist and Lars Karlsson and Amy Loutfi",
    journal = "Advances in Artificial Neural Systems",
    year = "2012",
}

@article{lecun,
    title = "Deep learning",
    author = "Yann LeCun and Yoshua Bengio and Geoffrey Hinton",
    journal = "Nature",
    volume = "521",
    month = May, 
    year = "2015",
    pages = "436--654",
}

@article{lecun2,
    title = "Gene expression inference with deep learning",
    author = "Yifei Chen and Yi Li and Rajiv Narayan and Aravind Subramanian and Xiaohui Xie",
    journal = "Bioinformatics",
    volume = "32",
    number = {12},
    year = "2016",
    pages = "1832--1839",
}

@unpublished{leeB15,
  author       = {Byunghan Lee and Taehoon Lee and Byunggook Na and Sungroh Yoon}, 
  title        = {DNA-Level Splice Junction Prediction using Deep Recurrent Neural Networks},
  note         = {arXiv preprint arXiv:1512.05135},
  year         = 2015
}

@unpublished{leeB16,
  author       = {Byunghan Lee and Junghwan Baek and Seunghyun Park and Sungroh Yoon}, 
  title        = {deepTarget: End-to-end Learning Framework for microRNA Target Prediction using Deep Recurrent Neural Networks},
  note         = {arXiv preprint arXiv:1603.09123},
  year         = 2016
}

@inproceedings{leeS15,
  author    = {Sungmin Lee and Minsuk Choi and Hyun-soo Choi and Moon Seok Park and Sungroh Yoon},
  title     = {FingerNet: Deep learning-based robust finger joint detection from radiographs},
  booktitle = {Biomedical Circuits and Systems Conference (BioCAS)},
  organization = {IEEE},
  pages     = {1--4},
  year      = {2015}
}

@inproceedings{leeT15,
  author    = {Taehoon Lee and Sungroh Yoon},
  title     = {Boosted Categorical Restricted Boltzmann Machine for Computational Prediction of Splice Junctions},
  booktitle = {International Conference on Machine Learning},
  organization = {International Conference on Machine Learning},
  pages     = {2483--2492},
  year      = {2015}
}

@article{lena12a,
    title = "Deep architectures for protein contact map prediction",
    author = "Pietro Di Lena and Ken Nagata and Pierre Baldi",
    journal = "Bioinformatics",
    volume = "28",
    number = {19},
    year = "2012",
    pages = "2449--2457",
}

@article{lena12b,
    title = "Deep spatio-temporal architectures and learning for proteinstructure prediction",
    author = "Pietro Di Lena and Ken Nagata and Pierre Baldi",
    journal = "Advances in neural information processing systems",
    year = "2012",
    pages = "512--520",
}

@article{leung,
    title = "Deep learning of the tissue-regulated splicing code",
    author = "Michael K. K. Leung and Hui Yuan Xiong and Leo J. Lee and Brendan J. Frey",
    journal = "Bioinformatics",
    volume = "30",
    number = {12},
    year = "2014",
    pages = "i121--i129",
}

@inproceedings{liK13,
  author    = {Kang Li and Xiaoyi Li and Yuan Zhang and Aidong Zhang},
  title     = {Affective state recognition from EEG with deep belief networks},
  booktitle = {2013 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
  organization = {IEEE},
  pages     = {305--310},
  year      = {2013}
}

@inproceedings{liQ14,
  author = {Qing Li and Weidong Cai and Xiaogang Wang and Yun Zhou and David Dagan Feng and Mei Chen},
  title = {Medical image classification with convolutional neural network},
  booktitle = {13th International Conference on Control Automation Robotics and Vision},
  organization = {IEEE},
  pages = {844--848},
  year = {2014}
}

@article{liQ16,
    title = "A Cross-Modality Learning Approach for Vessel Segmentation in Retinal Images",
    author = "Qiaoliang Li and Bowei Feng and LinPei Xie and Ping Liang and Huisheng Zhang and Tianfu Wang",
    journal = "IEEE Transactions on Medical Imaging",
    volume = "35",
    number = {1},
    year = "2015",
    pages = "109--118",
}

@unpublished{liY16,
  author    = {Yifeng Li and Wenqiang Shi and Wyeth W. Wasserman},
  title     = {Genome-Wide Prediction of cis-Regulatory Regions Using Supervised Deep Learning Methods},
  note      = {bioRxiv 2016:041616},
  year	    = {2016},
}

@article{liu,
    title = "De novo identification of replication-timing domains in the human genome by deep learning",
    author = "Feng Liu and Chao Ren and Hao Li and Pingkun Zhou and Xiaochen Bo and Wenjie Shu",
    journal = "Bioinformatics",
    volume = "32",
    number = {5},
    year = "2016",
    pages = "641--649",
}

@inproceedings{liang,
  author    = {M. Liang and Z. Li and T. Chen},
  title     = {Integrative Data Analysis of Multiplatform Cancer Data with a Multimodal Deep Learning Approach},
  booktitle = {Molecular Pharmaceutics},
  organization = {IEEE Transaction Computational Biology and Bioinformatics},
  pages     = {928--937},
  year      = {2015},
  volume    = {12}
}

@article{lyons,
    title = "Predicting backbone Ca angles and dihedrals from protein sequences by stacked sparse auto-encoder deep neural network",
    author = "James Lyons and Abdollah Dehzangi and Rhys Heffernan and Alok Sharma and Kuldip Paliwal and Abdul Sattar and Yaoqi Zhou and Yuedong Yang",
    journal = "Journal of computational chemistry",
    volume = "35",
    number = {28},
    year = "2014",
    pages = "2040--2052",
}

@inproceedings{mamoshina,
  author    = {P. Mamoshina and A. Vieira and E. Putin and A. Zhavoronkov},
  title     = {Applications of Deep Learning in Biomedicine},
  booktitle = {Molecular Pharmaceutics},
  organization = {American Chemical Society},
  pages     = {1445--1454},
  year      = {2016},
  volume    = {13}
}

@article{masci,
    title = "Stacked Convolutional Auto-Encoders for Hierarchical Feature Extraction",
    author = "Jonathan Masci and Ueli Meier and Dan Ciresan and Jurgen Schmidhuber",
    journal = "Artificial Neural Networks and Machine Learning-ICANN 2011",
    year = "2011",
    pages = "52--59",
}

@misc{microway,
  title = {Deep Learning Frameworks: A Survey of TensorFlow, Torch, Theano, Caffe, Neon, and the IBM Machine Learning Stack},
  howpublished = {\url{https://www.microway.com/hpc-tech-tips/deep-learning-frameworks-survey-tensorflow-torch-theano-caffe-neon-ibm-machine-learning-stack/}},
  note = {Accessed: 2017-03-02}
}


@unpublished{min,
  author    = {Seonwoo Min and Byunghan Lee and Sungroh Yoon}, 
  title     = {Deep Learning in Bioinformatics},
  note      = {arXiv preprint arXiv:1603.06430},
  year	    = {2016},
}

@article{mirowski,
    title = "Classification of patterns of EEG synchronization for seizure prediction",
    author = "Piotr Mirowski and Deepak Madhavan and Yann LeCun and Ruben Kuzniecky",
    journal = "Clinical neurophysiology",
    volume = "120",
    number = "11", 
    year = "2009",
    pages = "1927--1940",
}

@article{mootha,
    title = "PGC-1{\textalpha}-responsive genes involved in oxidative phosphorylation are coordinately downregulated in human diabetes",
    author = {Vamsi K Mootha and Cecilia M Lindgren and Karl-Fredrik Eriksson and Aravind Subramanian and Smita Sihag and Joseph Lehar and Pere Puigserver and Emma Carlsson and Martin Ridderstr{\aa}le and Esa Laurila and Nicholas Houstis and Mark J Daly and Nick Patterson and Jill P Mesirov and Todd R Golub and Pablo Tamayo and Bruce Spiegelman and Eric S Lander and Joel N Hirschhorn and David Altshuler and Leif C Groop},
    journal = "Nature Genetics",
    year = "2003",
    volume = "34",
    pages = "267--273",
}

@misc{ncbi1,
  title = {Platform GPL8490},
  howpublished = {\url{https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GPL8490}},
  note = {Accessed: 2017-06-10}
}

@misc{ncbi2,
  title = {Platform GPL16304},
  howpublished = {\url{https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GPL16304}},
  note = {Accessed: 2017-06-10}
}

@misc{nci2,
  title = {Common Cancer},
  howpublished = {\url{https://www.cancer.gov/types/common-cancers}},
  note = {Accessed: 2017-02-28}
}

@inproceedings{nguyen,
  author    = {Son P. Nguyen and Yi Shang and Dong Xu},
  title     = {DL-PRO: A novel deep learning method for protein model quality assessment},
  booktitle = {2014 International Joint Conference on Neural Networks (IJCNN)},
  organization = {IEEE},
  pages     = {2071--2078},
  year      = {2014}
}

@inproceedings{NgiamKKNLN11,
  added-at = {2011-12-16T00:00:00.000+0100},
  author = {Ngiam, Jiquan and Khosla, Aditya and Kim, Mingyu and Nam, Juhan and Lee, Honglak and Ng, Andrew Y.},
  booktitle = {ICML},
  pages = {689-696},
  publisher = {Omnipress},
  title = {Multimodal Deep Learning.},
  year = 2011 
}

@misc{nhgi,
  title = {What Is Cancer?},
  howpublished = {\url{https://www.cancer.gov/about-cancer/understanding/what-is-cancer}},
  note = {Accessed: 2017-02-27}
}

@article{ning,
    title = "Toward automatic phenotyping of developing embryos from videos",
    author = "Feng Ning and Damien Delhomme and Yann LeCun and Fabio Piano and Léon Bottou and Paolo Emilio Barbano",
    journal = "IEEE Transactions on Image Processing",
    volume = "14",
    number = {9},
    year = "2005",
    pages = "1360--1371",
}

@unpublished{park,
  author       = {Seunghyun Park and Seonwoo Min and Hyun-soo Choi and Sungroh Yoon}, 
  title        = {deepMiRGene: Deep Neural Network based Precursor microRNA Prediction},
  note         = {arXiv preprint arXiv:1605.00017},
  year         = 2016
}

@article{petrosian,
    title = "Recurrent neural network based prediction of epileptic seizures in intra- and extracranial EEG",
    author = "Arthur Petrosian and Danil Prokhorov and Richard Homan and Richard Dasheiff and Donald Wunsch",
    journal = "Neurocomputing",
    volume = "30",
    number = "1", 
    year = "2000",
    pages = "201--218",
}

@article{plis,
    title = "Deep learning for neuroimaging: a validation study",
    author = "Sergey M. Plis and Devon R. Hjelm and Ruslan Salakhutdinov and Elena A. Allen and Henry J. Bockholt and Jeffrey D. Long and Hans J. Johnson and Jane S. Paulsen and Jessica A. Turner and
Vince D. Calhoun",
    journal = "Frontiers in neuroscience",
    volume = "8",
    year = "2014"
}

@article{prasoon,
    title = "Deep feature learning for knee cartilage segmentation using a triplanar convolutional neural network",
    author = "Adhish Prasoon and Kersten Petersen and Christian Igel and François Lauze and Erik Dam and Mads Nielsen",
    journal = "Medical Image Computing and Computer-Assisted Intervention-MICCAI 2013",
    year = "2013",
    pages = "246--253",
}

@article{roth14,
    title = "A new 2.5D representation for lymph node detection using random sets of deep convolutional neural network observations",
    author = "Holger R. Roth and Le Lu and Ari Seff and Kevin M. Cherry and Joanne Hoffman and Shijun Wang and Jiamin Liu and Evrim Turkbey and Ronald M. Summers",
    journal = "Medical Image Computing and Computer-Assisted Intervention-MICCAI 2014",
    year = "2014",
    pages = "520--527",
}

@article{roth15a,
  author  = {Holger R. Roth  and  Le Lu and  Jiamin Liu and  Jianhua Yao and  Ari Seff and  Kevin Cherry and Lauren Kim and  Ronald M. Summers}, 
  title   = {Improving Computer-Aided Detection Using Convolutional Neural Networks and Random View Aggregation},
  journal = {IEEE Transactions on Medical Imaging},
  year    = 2015,
  number  = 5,
  pages   = {1170--1182},
  month   = 9,
  volume  = 35
}

@article{roth15b,
  author  = {Holger R. Roth and Jianhua Yao and Le Lu and James Stieger and Joseph E. Burns and Ronald M. Summers}, 
  title   = {Detection of Sclerotic Spine Metastases via Random Aggregation of Deep Convolutional Neural Network Classifications},
  journal = {Recent Advances in Computational Methods and Clinical Applications for Spine Imaging},
  year    = 2015,
  pages   = {3--12}
}

@article{roth15c,
    title = "Deeporgan: Multi-level deep convolutional networks for automated pancreas segmentation",
    author = "Holger R. Roth and Le Lu and Amal Farag and Hoo-Chang Shin and Jiamin Liu and Evrim B. Turkbey and Ronald M. Summers",
    journal = "Medical Image Computing and Computer-Assisted Intervention-MICCAI 2015",
    year = "2015",
    pages = "556--564",
}

@unpublished{roth15d,
  author    = {Holger R. Roth and Christopher T. Lee and Hoo-Chang Shin and Ari Seff and Lauren Kim and Jianhua Yao and Le Lu and Ronald M. Summers}, 
  title     = {Anatomy-specific classification of medical images using deep convolutional nets},
  note      = {arXiv preprint arXiv:1504.04003},
  year	    = {2015}
}

@inproceedings{soleymani,
  author    = {Mohammad Soleymani and Sadjad Asghari-Esfeden and Maja Pantic and Yun Fu},
  title     = {Continuous emotion detection using EEG signals and facial expressions},
  booktitle = {2014 IEEE International Conference on Multimedia and Expo (ICME)},
  organization = {IEEE},
  pages     = {1--6},
  year      = {2014}
}

@unpublished{sonderby14,
  author    = {Soren Kaae Sonderby and Ole Winther}, 
  title     = {Protein Secondary Structure Prediction with Long Short Term Memory Networks},
  note      = {arXiv preprint arXiv:1412.7828},
  year	    = {2014}
}

@unpublished{sonderby15,
  author    = {Soren Kaae Sonderby and Casper Kaae Sonderby and Henrik Nielsen and Ole Winther}, 
  title     = {Convolutional LSTM Networks for Subcellular Localization of Proteins},
  note      = {arXiv preprint arXiv:1503.01919},
  year	    = {2015},
}

@article{spencer,
    title = "A Deep Learning Network Approach to ab initio Protein Secondary Structure Prediction",
    author = "Matt Spencer and Jesse Eickholt and Jianlin Cheng",
    journal = "IEEE/ACM Trans Comput Biol Bioinform",
    volume = "12",
    number = {1},
    year = "2015",
    pages = "103--112",
}

@inproceedings{stober14a,
  author    = {Sebastian Stober and Daniel J. Cameron and Jessica A. Grahn},
  title     = {Classifying EEG recordings of rhythm perception},
  booktitle = {15th International Society for Music Information Retrieval Conference (ISMIR'14)},
  pages     = {649--654},
  year      = {2014}
}

@inproceedings{stober14b,
  author    = {Sebastian Stober and Daniel J. Cameron and Jessica A. Grahn},
  title     = {Using Convolutional Neural Networks to Recognize Rhythm Stimuli from Electroencephalography Recordings},
  booktitle = {Advances in neural information processing systems},
  pages     = {1449--1457},
  year      = {2014}
}

@unpublished{stober15,
  author    = {Sebastian Stober and Avital Sternin and Adrian M. Owen and Jessica A. Grahn}, 
  title     = {Deep Feature Learning for EEG Recordings},
  note      = {arXiv preprint arXiv:1511.04306},
  year	    = {2015},
}

@unpublished{stollenga,
  author    = {Marijn F. Stollenga and Wonmin Byeon and Marcus Liwicki and Juergen Schmidhuber}, 
  title     = {Parallel Multi-Dimensional LSTM, With Application to Fast Biomedical Volumetric Image Segmentation},
  note      = {arXiv preprint arXiv:1506.07452},
  year	    = {2015},
}

@phdthesis{straeter,
  author       = {Terry Anthony Straeter}, 
  title        = {On the Extension of the Davidon-Broyden Class of Rank One, Quasi-Newton Minimization Methods to an Infinite Dimensional Hilbert Space with Applications to Optimal Control Problems},
  school       = {North Carolina State University},
  year         = 1971,
  address      = {Raleigh, NC 27695, USA}
}

@article{subramanian,
    title = "Gene set enrichment analysis: A knowledge-based approach for interpreting genome-wide expression profiles",
    author = {Aravind Subramanian and Pablo Tamayo and Vamsi K. Mootha and Sayan Mukherjee and Benjamin L. Ebert and Michael A. Gillette and Amanda Paulovich and Scott L. Pomeroy and Todd R. Golub and Eric S. Lander and Jill P. Mesirov},
    journal = "Proceedings of the National Academy of Sciences of the United States of America (PNAS)",
    year = "2005",
    volume = "102",
    number = {43},
    pages = "15545--15550",
}

@article{suk,
    title = "Deep learning-based feature representation for AD/MCI classification",
    author = "Heung-Il Suk and Dinggang Shen",
    journal = "Medical Image Computing and Computer-Assisted Intervention-MICCAI 2013",
    year = "2013",
    pages = "583--590",
}

@misc{tcga,
  title = {{Genomic Data Commons (GDC)} Data Portal}, 
  howpublished = {\url{https://gdc-portal.nci.nih.gov/}},
  note = {Accessed: 2017-09-28}
} 

@article{turaga,
    title = "Convolutional networks can learn to generate affinity graphs for image segmentation",
    author = "Srinivas C. Turaga and Joseph F. Murray and Viren Jain and Fabian Roth and Moritz Helmstaedter and Kevin Briggman and Winfried Denk and H. Sebastian Seung",
    journal = "Neural Computation",
    volume = "22",
    number = {2},
    year = "2010",
    pages = "511--538",
}

@inproceedings{turner,
  author    = {JT Turner and Adam Page and Tinoosh Mohsenin and Tim Oates},
  title     = {Deep belief networks used on high resolution multichannel electroencephalography data for seizure detection},
  booktitle = {2014 AAAI Spring Symposium Series},
  year      = {2014}
}

@techreport{ushhs,
  author       = {National Center for Health Statistics}, 
  title        = {Health, United States, 2015},
  institution  = {U.S. Department of Health and Human Services},
  year         = 2016,
  month        = 5,
}

@misc{vcloud,
  title = {Every Day Big Data Statistics - 2,5 Quintillion Bytes of Data Created Daily},
  howpublished = {\url{http://www.vcloudnews.com/every-day-big-data-statistics-2-5-quintillion-bytes-of-data-created-daily/}},
  note = {Accessed: 2017-02-24}
}

@INPROCEEDINGS{VincentPLarochelleH2008,
    author = {Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre-Antoine},
     title = {Extracting and Composing Robust Features with Denoising Autoencoders},
      year = {2008},
     pages = {1096--1103},
  crossref = {ICML08}
}

@inproceedings{wang,
  author    = {Zuoguan Wang and Siwei Lyu and Gerwin Schalk and Qiang Ji},
  title     = {Deep feature learning using target priors with applications in ECoG signal decoding for BCI},
  booktitle = {Proceedings of the Twenty-Third international joint conference on Artificial Intelligence},
  organization = {AAAI Press},
  pages     = {1785--1791},
  year      = {2013}
}

@misc{watsonmanipal,
  title = {Watson for Oncology},
  howpublished = {\url{https://watsononcology.manipalhospitals.com/}},
  note = {Accessed: 2017-03-01}
}

@article{wulsin,
    title = "Modeling electroencephalography waveforms with semisupervised deep belief nets: fast classification and anomaly measurement",
    author = "D. F. Wulsin and J. R. Gupta and R. Mani and J. A. Blanco and B. Litt",
    journal = "Journal of neural engineering",
    volume = "8",
    number = {3},
    year = "2011",
}

@article{xu,
    title = "Stacked Sparse Autoencoder (SSAE) for Nuclei Detection on Breast Cancer Histopathology images",
    author = "Jun Xu and  Lei Xiang and  Qingshan Liu and  Hannah Gilmore and  Jianzhong Wu and  Jinghai Tang and  Anant Madabhushi",
    journal = "IEEE Transactions on Medical Imaging",
    volume = "35",
    number = {1},
    year = "2016",
    pages = "119--130",
}
%1
@Article{1Zarrei,
  author =       "Zarrei, M. and et al",
  title =        "A copy number variation map of the human genome",
  year =         "2015",
  journal =      "nature reviews genetics",
  volume =       "16(3)",
  pages =        "172-183",
}



%2 http://genome.cshlp.org/content/16/8/949.full.html#ref-29
@Article{2Feuk,
  author =       "Feuk, L. and et al",
  title =        "Structural variation in the human genome",
  year =         "2006",
  journal =      "nature reviews genetics",
  volume =       "7(2)",
  pages =        "85-97",
}


%3Iafrate
@Article{3Iafrate,
  author =       "Iafrate, A.J. and et al.",
  title =        "Detection of large-scale variation in the human genome",
  year =         "2004",
  journal =      "nature genetics",
  volume =       "36(9)",
  pages =        "949-951"
}
Iafrate, A.J., Feuk, L., Rivera, M.N., Listewnik, M.L., Donahoe, P.K., Qi, Y., Scherer, S.W. and Lee, C., 2004. Detection of large-scale variation in the human genome. Nature genetics, 36(9), pp.949-951.


%4
@Article{4Sebat,
  author =       "Sebat, Jonathan and et al",
  title =        "Large-scale copy number polymorphism in the human genome",
  year =         "2004",
  journal =      "Science",
  volume =       "305(5683)",
  pages =        "525-528",
}
%  Sebat, Jonathan, et al. "Large-scale copy number polymorphism in %the human genome." Science 305.5683 (2004): 525-528


%7
@Article{7Stone,
  author =       "Stone, Jennifer L. and et al",
  title =        "Rare chromosomal deletions and duplications increase risk of schizophrenia",
  year =         "2008",
  journal =      "nature",
  volume =       "455(7210)",
  pages =        "237-241",
  }
%Stone, Jennifer L., et al. "Rare chromosomal deletions and %duplications increase risk of schizophrenia." Nature 455.7210 %(2008): 237-241.


%8
@Article{8Stefansson,
  author =       "Stefansson, Hreinn and et al",
  title =        "Large recurrent microdeletions associated with schizophrenia",
  year =         "2008",
  journal =      "nature",
  volume =       "455(7219)",
  pages =        "232-236",
}
%  Stefansson, Hreinn, et al. "Large recurrent microdeletions associated with %schizophrenia." nature 455.7210 (2008): 232-236.


%9
@Article{9Walsh,
  author =       "Walsh, Tom and et al",
  title =        "Rare structural variants disrupt multiple genes in neurodevelopmental pathways in schizophrenia",
  year =         "2008",
  journal =      "science",
  volume =       "320(5875)",
  pages =        "539-543",
}
%  Walsh, Tom, et al. "Rare structural variants disrupt multiple genes in %neurodevelopmental pathways in schizophrenia." science 320.5875 (2008): 539-543.


%10
@Article{10Cooper,
  author =       "Cooper, Gregory M. and et al",
  title =        "A copy number variation morbidity map of developmental delay",
  year =         "2011",
  journal =      "nature genetics",
  volume =       "43(9)",
  pages =        "838-846",
}
  %Cooper, Gregory M., et al. "A copy number variation morbidity map of developmental %delay." Nature genetics 43.9 (2011): 838-846.

%11
@Article{11Fromer,
  author =       "Fromer, Menachem and et al",
  title =        "Discovery and statistical genotyping of copy-number variation from whole-exome sequencing depth",
  year =         "2012",
  journal =      "The American Journal of Human Genetics",
  volume =       "91(4)",
  pages =        "597-607",
}
%Fromer, Menachem, et al. "Discovery and statistical genotyping of %copy-number variation from whole-exome sequencing depth." The %American Journal of Human Genetics 91.4 (2012): 597-607.


%12
@Article{12Lee,
  author =       "Lee, J. H., and J. T. Jeon",
  title =        "Methods to detect and analyze copy number variations at the genome-wide and locus-specific levels.",
  year =         "2008",
  journal =      "Cytogenetic and genome research",
  volume =       "123(1-4)",
  pages =        "333-342",
}
%Lee, J. H., and J. T. Jeon. "Methods to detect and analyze copy %number variations at the genome-wide and locus-specific levels." %Cytogenetic and genome research 123.1-4 (2008): 333-342.

%21
@Article{21Caorsi,
  author =       "Caorsi, Salvatore, and Claudio Lenzi",
  title =        "A Breast Cancer Detection Approach Based on Radar Data Processing using Artificial Neural Network",
  year =         "2016",
  journal =      "Research Journal of Advanced Engineering and Science",
  volume =       "1(4)",
  pages =        "213-222"
}
%Caorsi, Salvatore, and Claudio Lenzi. "A Breast Cancer Detection Approach Based on Radar Data Processing using Artificial Neural Network." Research Journal of Advanced Engineering and Science 1.4 (2016): 213-222.

@article{ding2014application,
  title={Application of machine learning to development of copy number variation-based prediction of cancer risk},
  author={Ding, Xiaofan and Tsang, Shui-Ying and Ng, Siu-Kin and Xue, Hong},
  journal={Genomics insights},
  volume={7},
  pages={GEI--S15002},
  year={2014},
  publisher={SAGE Publications Sage UK: London, England}
}
@inproceedings{Conv_LSTM1,
  title={Convolutional LSTM network: A machine learning approach for precipitation nowcasting},
  author={Xingjian, SHI and Chen, Zhourong and Wang, Hao and Yeung, Dit-Yan and Wong, Wai-Kin and Woo, Wang-chun},
  booktitle={Advances in neural information processing systems},
  pages={802--810},
  year={2015}
}
@article{ostrovnaya2010classification,
  title={A classification model for distinguishing copy number variants from cancer-related alterations},
  author={Ostrovnaya, Irina and Nanjangud, Gouri and Olshen, Adam B},
  journal={BMC bioinformatics},
  volume={11},
  number={1},
  pages={297},
  year={2010},
  publisher={BioMed Central}
}
@article{zhang2016classification,
  title={Classification of cancers based on copy number variation landscapes},
  author={Zhang, Ning and Wang, Meng and Zhang, Peiwei and Huang, Tao},
  journal={Biochimica et Biophysica Acta (BBA)-General Subjects},
  volume={1860},
  number={11},
  pages={2750--2755},
  year={2016},
  publisher={Elsevier}
}
@inproceedings{elsadek2018supervised,
  title={Supervised Classification of Cancers Based on Copy Number Variation},
  author={Elsadek, Sanaa Fekry Abed and Makhlouf, Mohamed Abd Allah and Aldeen, Mohamed Amal},
  booktitle={International Conference on Advanced Intelligent Systems and Informatics},
  pages={198--207},
  year={2018},
  organization={Springer}
}

Zheng, Bichen, Sang Won Yoon, and Sarah S. Lam. "Breast cancer diagnosis based on feature extraction using a hybrid of K-means and support vector machine algorithms." Expert Systems with Applications 41.4 (2014): 1476-1482.

@article{zuo2019identification,
  title={Identification of a 6-gene signature predicting prognosis for colorectal cancer},
  author={Zuo, Shuguang and Dai, Gongpeng and Ren, Xuequn},
  journal={Cancer cell international},
  volume={19},
  number={1},
  pages={6},
  year={2019},
  publisher={BioMed Central}
}

@article{lawrence2014discovery,
  title={Discovery and saturation analysis of cancer genes across 21 tumour types},
  author={Lawrence, Michael S and Stojanov, Petar and Mermel, Craig H and Robinson, James T and Garraway, Levi A and Golub, Todd R and Meyerson, Matthew and Gabriel, Stacey B and Lander, Eric S and Getz, Gad},
  journal={Nature},
  volume={505},
  number={7484},
  pages={495},
  year={2014},
  publisher={Nature Publishing Group}
}
%25
%26
@Article{26Petricoin,
  author =       "Petricoin, Emanuel F., and Lance A. Liotta",
  title =        "{SELDI-TOF}-based serum proteomic pattern diagnostics for early detection of cancer",
  year =         "2004",
  journal =      "Current Opinion in Biotechnology",
  volume =       "15(1)",
  pages =        "24-30"
}
%Petricoin, Emanuel F., and Lance A. Liotta. "SELDI-TOF-based serum proteomic pattern diagnostics for early detection of cancer." Current Opinion in Biotechnology 15.1 (2004): 24-30.


%27
@Article{27Bocchi,
  author =       "Bocchi, L. and et al",
  title =        "Detection of single and clustered microcalcifications in mammograms using fractals models and neural networks",
  year =         "2004",
  journal =      "Medical Engineering \& Physics",
  volume =       "26(4)",
  pages =        "303-312"
}
%Bocchi, L., et al. "Detection of single and clustered microcalcifications in mammograms using fractals models and neural networks." Medical Engineering & Physics 26.4 (2004): 303-312.

%29
@Article{29Dettling,
  author =       "Dettling, Marcel",
  title =        "{BagBoosting} for tumor classification with gene expression data",
  year =         "2004",
  journal =      "Bioinformatics",
  volume =       "20(18)",
  pages =        "3583-3593"
}
%Dettling, Marcel. "BagBoosting for tumor classification with gene expression data." Bioinformatics 20.18 (2004): 3583-3593.


%30
@Article{30Wang,
  author =       "Wang, Jia-Xiang and et al",
  title =        "Application of serum protein fingerprinting coupled with artificial neural network model in diagnosis of hepatocellular carcinoma",
  year =         "2005",
  journal =      "Chinese medical journal",
  volume =       "118(15)",
  pages =        "1278-1284"
}
%Wang, Jia-Xiang, et al. "Application of serum protein fingerprinting coupled with artificial neural network model in diagnosis of hepatocellular carcinoma." Chinese medical journal 118.15 (2005): 1278-1284.

%32
@Article{32da,
  author =       "da Silva, M. V. G. B. and et al",
  title =        "Descriptive analysis of copy number variation regions in a population of dairy Gyr cattle.",
  year =         "2014",
  journal =      "American Society of Animal Science",
  volume =       "1",
  pages =        "1-20"
}
%da Silva, M. V. G. B., et al. "Descriptive analysis of copy number variation regions in a population of dairy Gyr cattle." Embrapa Informática Agropecuária-Artigo em anais de congresso (ALICE). In: WORLD CONGRESS OF GENETICS APPLIED TO LIVESTOCK PRODUCTION, 10., 2014, Vancouver. Proceedings... Champaign: American Society of Animal Science, 2014.

%33
@Article{33Redon,
  author =       "Redon, Richard and et al",
  title =        "Global variation in copy number in the human genome",
  year =         "2006",
  journal =      "nature",
  volume =       "444(7118)",
  pages =        "444-454"
}
%Redon, Richard, et al. "Global variation in copy number in the human genome." nature 444.7118 (2006): 444-454.



%34
@Article{34Scherer,
  author =       "Scherer, Stephen W. and et al",
  title =        "Challenges and standards in integrating surveys of structural variation",
  year =         "2007",
  journal =      "Nature genetics",
  volume =       "39",
  pages =        "S7-S15"
}
%Scherer, Stephen W., et al. "Challenges and standards in integrating surveys of structural variation." Nature genetics 39 (2007): S7-S15.


%35
@Article{35Liu,
  author =       "Liu, George E. and et al",
  title =        "Analysis of copy number variations among diverse cattle breeds.",
  year =         "2010",
  journal =      "Genome research",
  volume =       "20(5)",
  pages =        "693-703"
}
%Liu, George E., et al. "Analysis of copy number variations among diverse cattle breeds." Genome research 20.5 (2010): 693-703.
%36
@Article{36She,
  author =       "She, Xinwei and et al",
  title =        "Mouse segmental duplication and copy number variation",
  year =         "2008",
  journal =      "Nature genetics",
  volume =       "40(7)",
  pages =        "909-914"
}
%She, Xinwei, et al. "Mouse segmental duplication and copy number variation." Nature genetics 40.7 (2008): 909-914.

@inproceedings{vardropout,
  title={Variational dropout and the local reparameterization trick},
  author={Kingma, Durk P and Salimans, Tim and Welling, Max},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2575--2583},
  year={2015}
}
@inproceedings{ae1,
  title={Extracting and composing robust features with denoising autoencoders},
  author={Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre-Antoine},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={1096--1103},
  year={2008},
  organization={ACM}
}
@article{ae2,
  title={A fast learning algorithm for deep belief nets},
  author={Hinton, Geoffrey E and Osindero, Simon and Teh, Yee-Whye},
  journal={Neural computation},
  volume={18},
  number={7},
  pages={1527--1554},
  year={2006},
  publisher={MIT Press}
}
@article{cnv11,
  title={DNA copy number changes define spatial patterns of heterogeneity in colorectal cancer},
  author={Mamlouk, Soulafa and Childs, Liam Harold and Aust, Daniela and Heim, Daniel and Melching, Friederike and Oliveira, Cristiano and Wolf, Thomas and Durek, Pawel and Schumacher, Dirk and Bl{\"a}ker, Hendrik and others},
  journal={Nature communications},
  volume={8},
  pages={14093},
  year={2017},
  publisher={Nature Publishing Group}
}
@article{cnv12,
  title={Germline copy number variations are associated with breast cancer risk and prognosis},
  author={Kumaran, Mahalakshmi and Cass, Carol E and Graham, Kathryn and Mackey, John R and Hubaux, Roland and Lam, Wan and Yasui, Yutaka and Damaraju, Sambasivarao},
  journal={Scientific reports},
  volume={7},
  number={1},
  pages={14621},
  year={2017},
  publisher={Nature Publishing Group}
}
@article{zhang2006development,
  title={Development of bioinformatics resources for display and analysis of copy number and other structural variants in the human genome},
  author={Zhang, J and Feuk, L and Duggan, GE and Khaja, R and Scherer, SW},
  journal={Cytogenetic and genome research},
  volume={115},
  number={3-4},
  pages={205--214},
  year={2006},
  publisher={Karger Publishers}
}
@article{diskin2009copy,
  title={Copy number variation at 1q21. 1 associated with neuroblastoma},
  author={Diskin, Sharon J and Hou, Cuiping and Glessner, Joseph T and Attiyeh, Edward F and Laudenslager, Marci and Bosse, Kristopher and Cole, Kristina and Moss{\'e}, Ya{\"e}l P and Wood, Andrew and Lynch, Jill E and others},
  journal={Nature},
  volume={459},
  number={7249},
  pages={987},
  year={2009},
  publisher={Nature Publishing Group}
}
@article{nie2018theoretical,
  title={A theoretical explanation for perplexing behaviors of backpropagation-based visualizations},
  author={Nie, Weili and Zhang, Yang and Patel, Ankit},
  journal={arXiv preprint arXiv:1805.07039},
  year={2018}
}

@article{iafrate2004detection,
  title={Detection of large-scale variation in the human genome},
  author={Iafrate, A John and Feuk, Lars and Rivera, Miguel N and Listewnik, Marc L and Donahoe, Patricia K and Qi, Ying and Scherer, Stephen W and Lee, Charles},
  journal={Nature genetics},
  volume={36},
  number={9},
  pages={949},
  year={2004},
  publisher={Nature Publishing Group}
}

@article{cnv13,
  title={Genome-wide analysis of the role of copy-number variation in pancreatic cancer risk},
  author={Willis, Jason and Mukherjee, Semanti and Orlow, Irene and Viale, Agnes and Offit, Kenneth and Kurtz, Robert C and Olson, Sara and Klein, Robert},
  journal={Frontiers in genetics},
  volume={5},
  pages={29},
  year={2014},
  publisher={Frontiers}
}

@inproceedings{ggcam,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={618--626},
  year={2017}
}

@inproceedings{xavier,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={249--256},
  year={2010}
}

@inproceedings{ae3,
  title={Deeppainter: Painter classification using deep convolutional autoencoders},
  author={David, Omid E and Netanyahu, Nathan S},
  booktitle={International conference on artificial neural networks},
  pages={20--28},
  year={2016},
  organization={Springer}
}
%41
@Article{41Friedman,
  author =       "Friedman, J. M. and et al",
  title =        "Oligonucleotide microarray analysis of genomic imbalance in children with mental retardation",
  year =         "2006",
  journal =      "The American Journal of Human Genetics",
  volume =       "79(3)",
  pages =        "500-513"
}
%Friedman, J. M., et al. "Oligonucleotide microarray analysis of genomic imbalance in children with mental retardation." The American Journal of Human Genetics 79.3 (2006): 500-513.

@article{kourou2015machine,
  title={Machine learning applications in cancer prognosis and prediction},
  author={Kourou, Konstantina and Exarchos, Themis P and Exarchos, Konstantinos P and Karamouzis, Michalis V and Fotiadis, Dimitrios I},
  journal={Computational and structural biotechnology journal},
  volume={13},
  pages={8--17},
  year={2015},
  publisher={Elsevier}
}
@incollection{NIPS2017_7062,
title = {A Unified Approach to Interpreting Model Predictions},
author = {Lundberg, Scott M and Lee, Su-In},
booktitle = {Advances in Neural Information Processing Systems},
pages = {4765--4774},
year = {2017},
publisher = {Curran Associates, Inc.}
}

%42
@Article{42Marshall,
  author =       "Marshall, Christian",
  title =        "Structural variation of chromosomes in autism spectrum disorder",
  year =         "2008",
  journal =      "The American Journal of Human Genetics",
  volume =       "82(2)",
  pages =        "477-488"
}
%Marshall, Christian R., et al. "Structural variation of chromosomes in autism spectrum disorder." The American Journal of Human Genetics 82.2 (2008): 477-488.

@article{kaminski2019right,
  title={The right to explanation, explained},
  author={Kaminski, Margot E},
  journal={Berkeley Tech. LJ},
  volume={34},
  pages={189},
  year={2019},
  publisher={HeinOnline}
}

%47
@Article{47Nørskov,
  author =       "Norskov, M. S. and et al",
  title =        "Copy number variation in glutathione-S-transferase {T1} and {M1} predicts incidence and 5-year survival from prostate and bladder cancer, and incidence of corpus uteri cancer in the general population",
  year =         "2011",
  journal =      "The pharmacogenomics journal",
  volume =       "11(4)",
  pages =        "292-299"
}
%not good
%Nørskov, M. S., et al. "Copy number variation in glutathione-S-transferase T1 and M1 predicts incidence and 5-year survival from prostate and bladder cancer, and incidence of corpus uteri cancer in the general population." The pharmacogenomics journal 11.4 (2011): 292-299.
%49
@Article{49MacDonald,
  author =       "MacDonald, Jeffrey R. and et al",
  title =        "The Database of Genomic Variants: a curated collection of structural variation in the human genome",
  year =         "2013",
  journal =      "Nucleic acids research",
  volume =       "42(D1)",
  pages =        "D986-D992"
}
%MacDonald, Jeffrey R., et al. "The Database of Genomic Variants: a curated collection of structural variation in the human genome." Nucleic acids research 42.D1 (2013): D986-D992.



%50
@Article{50Buchanan,
  author =       "Buchanan, Janet A. and Stephen W. Scherer",
  title =        "Contemplating effects of genomic structural variatio",
  year =         "2008",
  journal =      "Genetics in Medicine",
  volume =       "10(9)",
  pages =        "639-647"
}
%not good
%Buchanan, Janet A., and Stephen W. Scherer. "Contemplating effects of genomic structural variation." Genetics in Medicine 10.9 (2008): 639-647.



%51
@Article{51Craddock,
  author =       "Craddock, Nick and et al",
  title =        "Genome-wide association study of {CNVs} in 16,000 cases of eight common diseases and 3,000 shared controls",
  year =         "2010",
  journal =      "Nature",
  volume =       "464(7289)",
  pages =        "713-720"
}
%Craddock, Nick, et al. "Genome-wide association study of CNVs in 16,000 cases of eight common diseases and 3,000 shared controls." Nature 464.7289 (2010): 713-720.



%52
@Article{52Cantsilieris,
  author =       "Cantsilieris, Stuart and Stefan J. White",
  title =        "Correlating multiallelic copy number polymorphisms with disease susceptibility",
  year =         "2013",
  journal =      "Human mutation",
  volume =       "34(1)",
  pages =        "1-13"
}
%not good
%Cantsilieris, Stuart, and Stefan J. White. "Correlating multiallelic copy number polymorphisms with disease susceptibility." Human mutation 34.1 (2013): 1-13.


%53
@Article{53Bowcock,
  author =       "Bowcock, Anne M",
  title =        "Invited review DNA copy number changes as diagnostic tools for lung cancer",
  year =         "2013",
  journal =      "thoraxjnl",
  volume =       "",
  pages =        "2013"
}
%very bad
%Bowcock, Anne M. "Invited review DNA copy number changes as diagnostic tools for lung cancer." Thorax (2013): thoraxjnl-2013.


%54
@Article{54Wang,
  author =       "Wang, Kai and et al",
  title =        "{PennCNV}: an integrated hidden Markov model designed for high-resolution copy number variation detection in whole-genome {SNP} genotyping data",
  year =         "2007",
  journal =      "Genome research",
  volume =       "17(11)",
  pages =        "1665-1674"
}
%Wang, Kai, et al. "PennCNV: an integrated hidden Markov model designed for high-resolution copy number variation detection in whole-genome SNP genotyping data." Genome research 17.11 (2007): 1665-1674.



%55
@Article{55Pinto,
  author =       "Pinto, Dalila and et al",
  title =        "Copy-number variation in control population cohorts",
  year =         "2007",
  journal =      "Human molecular genetics",
  volume =       "16(R2)",
  pages =        "R168-R173"
}
%Pinto, Dalila, et al. "Copy-number variation in control population cohorts." Human molecular genetics 16.R2 (2007): R168-R173.



%56
@Article{56Kim,
  author =       "Kim, Ji-Hong and et al",
  title =        "{CNVRuler}: a copy number variation-based case–control association analysis tool",
  year =         "2012",
  journal =      "Bioinformatics",
  volume =       "28(13)",
  pages =        "1790-1792"
}
%very bad
%Kim, Ji-Hong, et al. "CNVRuler: a copy number variation-based case–control association analysis tool." Bioinformatics 28.13 (2012): 1790-1792.


%57
@Article{57Yan,
  author =       "Yan, P. Yu and et al",
  title =        "Genomic copy number variations in the genomes of leukocytes predict prostate cancer clinical outcomes",
  year =         "2015",
  journal =      "PloS one",
  volume =       "10(8)",
  pages =        "e0135982"
}
%very bad
%Yan, P. Yu, et al. "Genomic copy number variations in the genomes of leukocytes predict prostate cancer clinical outcomes." PloS one 10.8 (2015): e0135982.
%59
@Article{59Hinton,
  author =       "Hinton, Geoffrey E. and Simon Osindero and Yee-Whye Teh",
  title =        "A fast learning algorithm for deep belief nets",
  year =         "2006",
  journal =      "Neural computation",
  volume =       "18(7)",
  pages =        "1527-1554"
}
%Hinton, Geoffrey E., Simon Osindero, and Yee-Whye Teh. "A fast learning algorithm for deep belief nets." Neural computation 18.7 (2006): 1527-1554.


%60
@Article{60Fischer,
  author =       "Fischer, Asja, and Christian Igel",
  title =        "Training restricted Boltzmann machines: An introduction",
  year =         "2014",
  journal =      "Pattern Recognition",
  volume =       "47(1)",
  pages =        "25-39"
}
%Fischer, Asja, and Christian Igel. "Training restricted Boltzmann machines: An introduction." Pattern Recognition 47.1 (2014): 25-39.


%61
@Article{61Hinton,
  author =       "Hinton, Geoffrey",
  title =        "A practical guide to training Restricted Boltzmann Machines ({RBM})",
  year =         "2010",
  journal =      "Momentum",
  volume =       "9(1)",
  pages =        "926"
}
%Hinton, Geoffrey. "A practical guide to training restricted Boltzmann machines." Momentum 9.1 (2010): 926.


%62
@Article{62Hopfield,
  author =       "Hopfield, John J.",
  title =        "Neural networks and physical systems with emergent collective computational abilities.",
  year =         "1982",
  journal =      "Proceedings of the national academy of sciences",
  volume =       "79(8)",
  pages =        "2554-2558"
}
%Hopfield, John J. "Neural networks and physical systems with emergent collective computational abilities." Proceedings of the national academy of sciences 79.8 (1982): 2554-2558.


%63
@Article{63Hinton,
  author =       "Hinton, Geoffrey E.",
  title =        "Training products of experts by minimizing contrastive divergence",
  year =         "2002",
  journal =      "Neural computation",
  volume =       "14(8)",
  pages =        "1771-1800"
}
%Hinton, Geoffrey E. "Training products of experts by minimizing contrastive divergence." Neural computation 14.8 (2002): 1771-1800.


%64
@Article{64Charchar,
  author =       "Charchar, Fadi J. and et al",
  title =        "Whole Genome Survey of Copy Number Variation in the Spontaneously Hypertensive Rat",
  year =         "2010",
  journal =      "Hypertension",
  volume =       "55(5)",
  pages =        "1231-1238"
}
%very bad
%Charchar, Fadi J., et al. "Whole Genome Survey of Copy Number Variation in the Spontaneously Hypertensive Rat." Hypertension 55.5 (2010): 1231-1238.


%65
@Article{65Hinton,
  author =       "Hinton, Geoffrey E.",
  title =        "Deep Belief Networks, Scholarpedia, 4 (5): 5947",
  year =         "2009",
  journal =      "Available electronically at scholarpedia http://www. scholarpedia. org/article/Deep\_belief\_networks Hoppensteadt",
  volume =       "Hoppensteadt, FC",
  pages =        "129-35"
}
%bad
%Hinton, Geoffrey E. "Deep belief networks, Scholarpedia, 4 (5): 5947." Available electronically at http://www. scholarpedia. org/article/Deep_belief_networks Hoppensteadt, FC (2009): 129-35.
http://www. scholarpedia. org/article/Deep_belief_networks Hoppensteadt

%68
@Article{68Hinton,
  author =       "Hinton, Geoffrey E. and et al",
  title =        "Improving neural networks by preventing co-adaptation of feature detectors",
  year =         "2012",
  journal =      "arXiv preprint arXiv",
  volume =       "1207(0580)",
  pages =        "10"
}
%Hinton, Geoffrey E., et al. "Improving neural networks by preventing co-adaptation of feature detectors." arXiv preprint arXiv:1207.0580 (2012).

%69
@Article{69Bengio,
  author =       "Bengio, Yoshua",
  title =        "Learning deep architectures for AI.",
  year =         "2009",
  journal =      "Foundations and trends in Machine Learning 2.1",
  volume =       "2",
  pages =        "1-127"
}
%Bengio, Yoshua. "Learning deep architectures for AI." Foundations and trends® in Machine Learning 2.1 (2009): 1-127.

%70
@Article{70Rezaul,
  author =       "Md. Rezaul Karim",
  title =        "Predictive Analytics with TensorFlow",
  year =         "2017",
  journal =      "Packt Publishing Ltd"
}

%Md. Rezaul Karim, Predictive Analytics with TensorFlow, Packt Publishing Ltd., 2017


%72
@Article{72Breiman,
  author =       "Breiman, Leo",
  title =        "Random forests",
  year =         "2001",
  journal =      "Machine learning",
  volume =       "45(1)",
  pages =        "5-32"
}
%Breiman, Leo. "Random forests." Machine learning 45.1 (2001): 5-32.

%73
@Article{73Breiman,
  author =       "Breiman, Leo",
  title =        "Bagging predictors",
  year =         "1996",
  journal =      "Machine learning",
  volume =       "24(2)",
  pages =        "123-140"
}
%Breiman, Leo. "Bagging predictors." Machine learning 24.2 (1996): 123-140.

%74
@Article{74Dehzangi,
  author =       "Dehzangi, Abdollah, Somnuk Phon-Amnuaisuk, and Omid Dehzangi",
  title =        "Using Random Forest for Protein Fold Prediction Problem: An Empirical Study",
  year =         "2010",
  journal =      "J. Inf. Sci. Eng",
  volume =       "26(6)",
  pages =        "1941-1956"
}
%Dehzangi, Abdollah, Somnuk Phon-Amnuaisuk, and Omid Dehzangi. "Using Random Forest for Protein Fold Prediction Problem: An Empirical Study." J. Inf. Sci. Eng. 26.6 (2010): 1941-1956.


%75
@Article{75Schapire,
  author =       "Schapire, Robert E",
  title =        "The strength of weak learnability",
  year =         "1990",
  journal =      "Machine learning",
  volume =       "5(2)",
  pages =        "197-227"
}
%Schapire, Robert E. "The strength of weak learnability." Machine learning 5.2 (1990): 197-227.

%76
@Article{76Livingston,
  author =       "Livingston, Frederick",
  title =        "Implementation of Breiman random forest machine learning algorithm",
  year =         "2005",
  journal =      "Machine Learning Journal Paper",
  volume =       "ECE591Q",
  pages =        "12-45"
}
%Livingston, Frederick. "Implementation of Breiman’s random forest machine learning algorithm." ECE591Q Machine Learning Journal Paper (2005).

%77
@Article{77Breiman,
  author =       "Breiman, Leo and et al",
  title =        "Classification and regression trees",
  year =         "1984",
  journal =      "CRC press",
  volume =       "",
  pages =        "5-15"
}
%Breiman, Leo, et al. Classification and regression trees. CRC press, 1984.

%78
@Article{78Mingers,
  author =       "Mingers, John",
  title =        "An empirical comparison of selection measures for decision-tree induction",
  year =         "1989",
  journal =      "Machine learning",
  volume =       "3(4)",
  pages =        "319-342"
}
%Mingers, John. "An empirical comparison of selection measures for decision-tree induction." Machine learning 3.4 (1989): 319-342.

%79
@Article{79Chan,
  author =       "Chan, Jonathan Cheung-Wai, and Desiré Paelinckx",
  title =        "Evaluation of Random Forest and Adaboost tree-based ensemble classification and spectral band selection for ecotope mapping using airborne hyperspectral imagery",
  year =         "2008",
  journal =      "Remote Sensing of Environment",
  volume =       "112(6)",
  pages =        "2999-3011"
}

%Chan, Jonathan Cheung-Wai, and Desiré Paelinckx. "Evaluation of Random Forest and Adaboost tree-based ensemble classification and spectral band selection for ecotope mapping using airborne hyperspectral imagery." Remote Sensing of Environment 112.6 (2008): 2999-3011.

%80
@Article{80Pal,
  author =       "Pal, Mahesh, and Paul M. Mather",
  title =        "An assessment of the effectiveness of decision tree methods for land cover classification",
  year =         "2003",
  journal =      "Remote sensing of environment",
  volume =       "86(4)",
  pages =        "554-565"
}
%Pal, Mahesh, and Paul M. Mather. "An assessment of the effectiveness of decision tree methods for land cover classification." Remote sensing of environment 86.4 (2003): 554-565.

%81
@Article{81Menze,
  author =       "Menze, Bjoern H. and et al",
  title =        "A comparison of random forest and its Gini importance with standard chemometric methods for the feature selection and classification of spectral data",
  year =         "2009",
  journal =      "BMC bioinformatics",
  volume =       "10(1)",
  pages =        "213"
}
%Menze, Bjoern H., et al. "A comparison of random forest and its Gini importance with standard chemometric methods for the feature selection and classification of spectral data." BMC bioinformatics 10.1 (2009): 213.


@article{wang2009rna,
  title={RNA-Seq: a revolutionary tool for transcriptomics},
  author={Wang, Zhong and Gerstein, Mark and Snyder, Michael},
  journal={Nature reviews genetics},
  volume={10},
  number={1},
  pages={57},
  year={2009},
  publisher={Nature Publishing Group}
}

@article{bartel2009micrornas,
  title={MicroRNAs: target recognition and regulatory functions},
  author={Bartel, David P},
  journal={cell},
  volume={136},
  number={2},
  pages={215--233},
  year={2009},
  publisher={Elsevier}
}


@article{dna,
  title={Principles and challenges of genome-wide DNA methylation analysis},
  author={Laird, Peter W},
  journal={Nature Reviews Genetics},
  volume={11},
  number={3},
  pages={191},
  year={2010},
  publisher={Nature Publishing Group}
}
@article{dna2,
  title={A rapid method for determining sequences in DNA by primed synthesis with DNA polymerase},
  author={Sanger, Fred and Coulson, Alan R},
  journal={Journal of molecular biology},
  volume={94},
  number={3},
  pages={441--448},
  year={1975},
  publisher={Elsevier}
}


%83
@Article{83Leung,
  author =       "Leung, Michael KK and et al",
  title =        "Deep learning of the tissue-regulated splicing code",
  year =         "2014",
  journal =      "Bioinformatics",
  volume =       "30(12)",
  pages =        "i121-i129"
}
%Leung, Michael KK, et al. "Deep learning of the tissue-regulated splicing code." Bioinformatics 30.12 (2014): i121-i129.


%84
@Article{84Lee,
  author =       "Lee, Taehoon, and Sungroh Yoon",
  title =        "Boosted categorical Restricted Boltzmann Machine for computational prediction of splice junctions",
  year =         "2015",
  journal =      "International Conference on Machine Learning",
  volume =       "",
  pages =        ""
}
%Lee, Taehoon, and Sungroh Yoon. "Boosted categorical restricted Boltzmann machine for computational prediction of splice junctions." International Conference on Machine Learning. 2015.

%85
@Article{85Chen,
  author =       "Chen, Yifei and et al",
  title =        "Gene expression inference with deep learning",
  year =         "2016",
  journal =      "Bioinformatics",
  volume =       "32(12)",
  pages =        "1832-1839"
}
%Chen, Yifei, et al. "Gene expression inference with deep learning." Bioinformatics 32.12 (2016): 1832-1839.

%86
@Article{86Leung,
  author =       "Leung, Michael KK and et al",
  title =        "Machine learning in genomic medicine: a review of computational problems and data sets",
  year =         "2016",
  journal =      "Proceedings of the IEEE",
  volume =       "104(1)",
  pages =        "176-197"
}
%Leung, Michael KK, et al. "Machine learning in genomic medicine: a review of computational problems and data sets." Proceedings of the IEEE 104.1 (2016): 176-197.


%87
@Article{87Yim,
  author =       "Yim, Seon-Hee and et al",
  title =        "Clinical implications of copy number variations in autoimmune disorders",
  year =         "2015",
  journal =      "The Korean journal of internal medicine",
  volume =       "30(3)",
  pages =        "294"
}
%Yim, Seon-Hee, et al. "Clinical implications of copy number variations in autoimmune disorders." The Korean journal of internal medicine 30.3 (2015): 294.


%88
@Article{88Lowe,
  author =       "Lowe, Craig B., et al",
  title =        "Detecting differential copy number variation between groups of samples",
  year =         "2017",
  journal =      "Genome research",
  volume =       "",
  pages =        ""
}
%Lowe, Craig B., et al. "Detecting differential copy number variation between groups of samples." Genome research (2017).

%89
@Article{89Xie,
  author =       "Xie, Chao, and Martti T. Tammi",
  title =        "{CNV}-seq, a new method to detect copy number variation using high-throughput sequencing",
  year =         "2009",
  journal =      "BMC bioinformatics",
  volume =       "10(1)",
  pages =        "80"
}
%Xie, Chao, and Martti T. Tammi. "CNV-seq, a new method to detect copy number variation using high-throughput sequencing." BMC bioinformatics 10.1 (2009): 80.

%90
@Article{90Rodriguez,
  author =       "Rodriguez-Galiano, Victor Francisco and et al",
  title =        "An assessment of the effectiveness of a random forest classifier for land-cover classification",
  year =         "2012",
  journal =      "{ISPRS} Journal of Photogrammetry and Remote Sensing",
  volume =       "67",
  pages =        "93-104"
}
%Rodriguez-Galiano, Victor Francisco, et al. "An assessment of the effectiveness of a random forest classifier for land-cover classification." ISPRS Journal of Photogrammetry and Remote Sensing 67 (2012): 93-104.

%94
@Article{94Padmanabhan,
  author =       "Padmanabhan, Sharanya, and Raji Sundararajan",
  title =        "Enhanced accuracy of breast cancer detection in digital mammograms using wavelet analysis",
  year =         "2012",
  journal =      "Machine Vision and Image Processing ({MVIP}), 2012 International Conference on",
  volume =       "{IEEE}",
  pages =        ""
}
%Padmanabhan, Sharanya, and Raji Sundararajan. "Enhanced accuracy of breast cancer detection in digital mammograms using wavelet analysis." Machine Vision and Image Processing (MVIP), 2012 International Conference on. IEEE, 2012.

%96
@article{96Karim,
  title={A Deep Learning Approach to Genomics Data for Population Scale Clustering and Ethnicity Prediction},
  author={Karim, Md Rezaul and Zappa, Achille and Sahay, Ratnesh and Rebholz-Schuhmann, Dietrich},
  booktitle={Proceedings of 1st international {ESWC}'2017 workshop Semantic Web solutions for large-scale biomedical data analytics ({SeWeBMeDA}'17)},
  pages={1--15},
  publisher={ESWC},
  year={2017}
}
%
@Article{11111111111,
  author =       "and et al",
  title =        "",
  year =         "20",
  journal =      "",
  volume =       "()",
  pages =        "",
}
@article{yates,
    title = "Ensembl 2016.",
    author = "Andrew Yates and Wasiu Akanni and M. Ridwan Amode and Daniel Barrell and Konstantinos Billis and others",
    journal = "Nucleic Acids Res.",
    volume = "44",
    year = "2016"
}

@article{ypsilantis,
    title = "Predicting Response to Neoadjuvant Chemotherapy with PET Imaging Using Convolutional Neural Networks",
    author = "Petros-Pavlos Ypsilantis and Musib Siddique and Hyon-Mok Sohn and Andrew Davies and Gary Cook and Vicky Goh and Giovanni Montana",
    journal = "PLoS ONE",
    year = "2015"
}

@article{zengH,
  author  = {Haoyang Zeng and Matthew D. Edwards and Ge Liu and David K. Gifford}, 
  title   = {Convolutional neural network architectures for predicting DNA-protein binding},
  journal = {Bioinformatics},
  year    = 2016,
  volume  = 32,
  number  = 12,
  pages   = {i121--i127}
}

@article{zengT,
  author  = {Tao Zeng and Rongjian Li and Ravi Mukkamala and Jieping Ye and Shuiwang Ji}, 
  title   = {Deep convolutional neural networks for annotating gene expression patterns in the mouse brain},
  journal = {BMC Bioinformaticss},
  year    = 2015,
  volume  = 16,
  number  = 1,
  pages   = {1--10}
}

@article{zhang,
    title = "A deep learning framework for modeling structural features of RNA-binding protein targets",
    author = "Sai Zhang and Jingtian Zhou and Hailin Hu and Haipeng Gong and Ligong Chen and Chao Cheng
and Jianyang Zeng",
    journal = "Nucleic Acids Research",
    volume = "44",
    number = "4",
    year = "2016",
}

@inproceedings{zhao,
  author    = {Yilu Zhao and Lianghua He},
  title     = {Deep Learning in the EEG Diagnosis of Alzheimer's Disease},
  booktitle = {Computer Vision-ACCV 2014 Workshops},
  pages     = {340--353},
  year      = {2014}
}

@inproceedings{zheng,
  author    = {Wei-Long Zheng and Hao-Tian Guo and Bao-Liang Lu},
  title     = {Revealing critical channels and frequency bands for emotion recognition from EEG with deep belief network},
  booktitle = {2015 7th International IEEE/EMBS Conference on Neural Engineering (NER)},
  organization = {IEEE},
  pages     = {154--157},
  year      = {2015}
}

@article{zhou,
    title = "Predicting effects of noncoding variants with deep learning-based sequence model",
    author = "Jian Zhou and Olga G Troyanskaya",
    journal = "Nature methods",
    volume = "12",
    number = "10",
    year = "2015",
  pages   = {931--934}
}

%1
@Article{1Zarrei,
  author =       "Zarrei, M. and et al",
  title =        "A copy number variation map of the human genome",
  year =         "2015",
  journal =      "nature reviews genetics",
  volume =       "16(3)",
  pages =        "172-183"
}



%2 http://genome.cshlp.org/content/16/8/949.full.html#ref-29
@Article{2Feuk,
  author =       "Feuk, L. and et al",
  title =        "Structural variation in the human genome",
  year =         "2006",
  journal =      "nature reviews genetics",
  volume =       "7(2)",
  pages =        "85-97"
}


%3Iafrate
@Article{3Iafrate,
  author =       "Iafrate, A.J. and et al.",
  title =        "Detection of large-scale variation in the human genome",
  year =         "2004",
  journal =      "nature genetics",
  volume =       "36(9)",
  pages =        "949-951"
}
Iafrate, A.J., Feuk, L., Rivera, M.N., Listewnik, M.L., Donahoe, P.K., Qi, Y., Scherer, S.W. and Lee, C., 2004. Detection of large-scale variation in the human genome. Nature genetics, 36(9), pp.949-951.


%4
@Article{4Sebat,
  author =       "Sebat, Jonathan and et al",
  title =        "Large-scale copy number polymorphism in the human genome",
  year =         "2004",
  journal =      "Science",
  volume =       "305(5683)",
  pages =        "525-528"
}
%  Sebat, Jonathan, et al. "Large-scale copy number polymorphism in %the human genome." Science 305.5683 (2004): 525-528


%7
@Article{7Stone,
  author =       "Stone, Jennifer L. and et al",
  title =        "Rare chromosomal deletions and duplications increase risk of schizophrenia",
  year =         "2008",
  journal =      "nature",
  volume =       "455(7210)",
  pages =        "237-241"
  }
%Stone, Jennifer L., et al. "Rare chromosomal deletions and %duplications increase risk of schizophrenia." Nature 455.7210 %(2008): 237-241.


%8
@Article{8Stefansson,
  author =       "Stefansson, Hreinn and et al",
  title =        "Large recurrent microdeletions associated with schizophrenia",
  year =         "2008",
  journal =      "nature",
  volume =       "455(7219)",
  pages =        "232-236"
}
%  Stefansson, Hreinn, et al. "Large recurrent microdeletions associated with %schizophrenia." nature 455.7210 (2008): 232-236.


%9
@Article{9Walsh,
  author =       "Walsh, Tom and et al",
  title =        "Rare structural variants disrupt multiple genes in neurodevelopmental pathways in schizophrenia",
  year =         "2008",
  journal =      "science",
  volume =       "320(5875)",
  pages =        "539-543"
}
%  Walsh, Tom, et al. "Rare structural variants disrupt multiple genes in %neurodevelopmental pathways in schizophrenia." science 320.5875 (2008): 539-543.


%10
@Article{10Cooper,
  author =       "Cooper, Gregory M. and et al",
  title =        "A copy number variation morbidity map of developmental delay",
  year =         "2011",
  journal =      "nature genetics",
  volume =       "43(9)",
  pages =        "838-846"
}
  %Cooper, Gregory M., et al. "A copy number variation morbidity map of developmental %delay." Nature genetics 43.9 (2011): 838-846.

%11
@Article{11Fromer,
  author =       "Fromer, Menachem and et al",
  title =        "Discovery and statistical genotyping of copy-number variation from whole-exome sequencing depth",
  year =         "2012",
  journal =      "The American Journal of Human Genetics",
  volume =       "91(4)",
  pages =        "597-607"
}
%Fromer, Menachem, et al. "Discovery and statistical genotyping of %copy-number variation from whole-exome sequencing depth." The %American Journal of Human Genetics 91.4 (2012): 597-607.


%12
@Article{12Lee,
  author =       "Lee, J. H., and J. T. Jeon",
  title =        "Methods to detect and analyze copy number variations at the genome-wide and locus-specific levels.",
  year =         "2008",
  journal =      "Cytogenetic and genome research",
  volume =       "123(1-4)",
  pages =        "333-342"
}
@article{liu2017tumor,
  title={Tumor gene expression data classification via sample expansion-based deep learning},
  author={Liu, Jian and Wang, Xuesong and Cheng, Yuhu and Zhang, Lin},
  journal={Oncotarget},
  volume={8},
  number={65},
  pages={109646},
  year={2017},
  publisher={Impact Journals, LLC}
}

@inproceedings{zeebaree2018gene,
  title={Gene Selection \& Classification of Microarray Data Using Convolutional Neural Network},
  author={Zeebaree, Diyar Qader and Haron, Habibollah and Abdulazeez, Adnan Mohsin},
  booktitle={Intl. Conf. on Advanced Science \& Eng.},
  pages={145--150},
  year={2018},
  organization={IEEE}
}
@article{yue2018deep,
  title={Deep learning for genomics: A concise overview},
  author={Yue, Tianwei and Wang, Haohan},
  journal={arXiv preprint arXiv:1802.00810},
  year={2018}
}
@article{asgari2015continuous,
  title={Continuous distributed representation of biological sequences for deep proteomics and genomics},
  author={Asgari, Ehsaneddin and Mofrad, Mohammad RK},
  journal={PloS one},
  volume={10},
  number={11},
  year={2015},
  publisher={Public Library of Science}
}
@inproceedings{CapsNet,
  title={Dynamic routing between capsules},
  author={Sabour, Sara and Frosst, Nicholas and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={3856--3866},
  year={2017}
}

@inproceedings{GAN,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2672--2680},
  year={2014}
}
@article{CNN_GAN,
  title={Unsupervised representation learning with deep convolutional generative adversarial networks},
  author={Radford, Alec and Metz, Luke and Chintala, Soumith},
  journal={arXiv preprint arXiv:1511.06434},
  year={2015}
}
@article{zagoruyko2016wide,
  title={Wide residual networks},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1605.07146},
  year={2016}
}
%14
@Article{14Siegel,
  author =       "Siegel, Rebecca L. and Kimberly D. Miller and Ahmedin Jemal",
  title =        "Cancer statistics, 2017",
  year =         "2017",
  journal =      "CA: a cancer journal for clinicians",
  volume =       "67(1)",
  pages =        "7-30"
}
%Siegel, Rebecca L., Kimberly D. Miller, and Ahmedin Jemal. "Cancer Statistics, 2017." CA: A Cancer Journal for Clinicians 67.1 (2017): 7-30.

@inproceedings{lyu2018deep,
  title={Deep learning based tumor type classification using gene expression},
  author={Lyu, Boyu and Haque, Anamul},
  booktitle={Pro. of ACM Intl. Conf. on Bioinformatics, Computational Biology, \& Health Informatics},
  pages={89--96},
  year={2018},
  organization={ACM}
}
@article{li2017comprehensive,
  title={A comprehensive genomic pan-cancer classification using The Cancer Genome Atlas gene expression data},
  author={Li, Yuanyuan and Kang, Kai and Krahn, Juno and Li, Leping},
  journal={BMC genomics},
  volume={18},
  number={1},
  pages={508},
  year={2017},
  publisher={BioMed Central}
}

@article{mostavi2019convolutional,
  title={Convolutional neural network for cancer type prediction using gene expression},
  author={Mostavi, Milad and Chiu, Yuchiao and Chen, Yidong},
  journal={arXiv:1906.07794},
  year={2019}
}
@article{way2018machine,
  title={Machine learning detects pan-cancer ras pathway activation in the cancer genome atlas},
  author={Way, Gregory P and Sanchez-Vega, Francisco and La, Konnor and Armenia, Joshua and Chatila, Walid K and Luna, Augustin and Sander, Chris and Cherniack, Andrew D and Mina, Marco and Ciriello, Giovanni and others},
  journal={Cell reports},
  volume={23},
  number={1},
  pages={172--180},
  year={2018},
  publisher={Elsevier}
}
@article{malta2018machine,
  title={Machine learning identifies stemness features associated with oncogenic dedifferentiation},
  author={Malta, Tathiane M and Sokolov, Artem and Gentles, Andrew J and Burzykowski, Tomasz and Poisson, Laila and Weinstein, John N and Kami{\'n}ska, Bo{\.z}ena and Huelsken, Joerg and Omberg, Larsson and Gevaert, Olivier and others},
  journal={Cell},
  volume={173},
  number={2},
  pages={338--354},
  year={2018},
  publisher={Elsevier}
}

@article{hoadley2018cell,
  title={Cell-of-origin patterns dominate the molecular classification of 10,000 tumors from 33 types of cancer},
  author={Hoadley, Katherine A and Yau, Christina and Hinoue, Toshinori and Wolf, Denise M and Lazar, Alexander J and Drill, Esther and Shen, Ronglai and Taylor, Alison M and Cherniack, Andrew D and Thorsson, V{\'e}steinn and others},
  journal={Cell},
  volume={173},
  number={2},
  pages={291--304},
  year={2018},
  publisher={Elsevier}
}
%21
@Article{21Caorsi,
  author =       "Caorsi, Salvatore, and Claudio Lenzi",
  title =        "A Breast Cancer Detection Approach Based on Radar Data Processing using Artificial Neural Network",
  year =         "2016",
  journal =      "Research Journal of Advanced Engineering and Science",
  volume =       "1(4)",
  pages =        "213-222"
}
%Caorsi, Salvatore, and Claudio Lenzi. "A Breast Cancer Detection Approach Based on Radar Data Processing using Artificial Neural Network." Research Journal of Advanced Engineering and Science 1.4 (2016): 213-222.

%26
@Article{26Petricoin,
  author =       "Petricoin, Emanuel F., and Lance A. Liotta",
  title =        "{SELDI-TOF}-based serum proteomic pattern diagnostics for early detection of cancer",
  year =         "2004",
  journal =      "Current Opinion in Biotechnology",
  volume =       "15(1)",
  pages =        "24-30"
}
%Petricoin, Emanuel F., and Lance A. Liotta. "SELDI-TOF-based serum proteomic pattern diagnostics for early detection of cancer." Current Opinion in Biotechnology 15.1 (2004): 24-30.


%27
@Article{27Bocchi,
  author =       "Bocchi, L. and et al",
  title =        "Detection of single and clustered microcalcifications in mammograms using fractals models and neural networks",
  year =         "2004",
  journal =      "Medical Engineering \& Physics",
  volume =       "26(4)",
  pages =        "303-312"
}
%Bocchi, L., et al. "Detection of single and clustered microcalcifications in mammograms using fractals models and neural networks." Medical Engineering & Physics 26.4 (2004): 303-312.
%29
@Article{29Dettling,
  author =       "Dettling, Marcel",
  title =        "{BagBoosting} for tumor classification with gene expression data",
  year =         "2004",
  journal =      "Bioinformatics",
  volume =       "20(18)",
  pages =        "3583-3593"
}
%Dettling, Marcel. "BagBoosting for tumor classification with gene expression data." Bioinformatics 20.18 (2004): 3583-3593.


%30
@Article{30Wang,
  author =       "Wang, Jia-Xiang and et al",
  title =        "Application of serum protein fingerprinting coupled with artificial neural network model in diagnosis of hepatocellular carcinoma",
  year =         "2005",
  journal =      "Chinese medical journal",
  volume =       "118(15)",
  pages =        "1278-1284"
}
%Wang, Jia-Xiang, et al. "Application of serum protein fingerprinting coupled with artificial neural network model in diagnosis of hepatocellular carcinoma." Chinese medical journal 118.15 (2005): 1278-1284.

%32
@Article{32da,
  author =       "da Silva, M. V. G. B. and et al",
  title =        "Descriptive analysis of copy number variation regions in a population of dairy Gyr cattle.",
  year =         "2014",
  journal =      "American Society of Animal Science",
  volume =       "",
  pages =        ""
}
%da Silva, M. V. G. B., et al. "Descriptive analysis of copy number variation regions in a population of dairy Gyr cattle." Embrapa Informática Agropecuária-Artigo em anais de congresso (ALICE). In: WORLD CONGRESS OF GENETICS APPLIED TO LIVESTOCK PRODUCTION, 10., 2014, Vancouver. Proceedings... Champaign: American Society of Animal Science, 2014.

%33
@Article{33Redon,
  author =       "Redon, Richard and et al",
  title =        "Global variation in copy number in the human genome",
  year =         "2006",
  journal =      "nature",
  volume =       "444(7118)",
  pages =        "444-454"
  }
Redon, Richard, et al. "Global variation in copy number in the human genome." nature 444.7118 (2006): 444-454.

%34
@Article{34Scherer,
  author =       "Scherer, Stephen W. and et al",
  title =        "Challenges and standards in integrating surveys of structural variation",
  year =         "2007",
  journal =      "Nature genetics",
  volume =       "39",
  pages =        "S7-S15"
}
Scherer, Stephen W., et al. "Challenges and standards in integrating surveys of structural variation." Nature genetics 39 (2007): S7-S15.


%35
@Article{35Liu,
  author =       "Liu, George E. and et al",
  title =        "Analysis of copy number variations among diverse cattle breeds.",
  year =         "2010",
  journal =      "Genome research",
  volume =       "20(5)",
  pages =        "693-703"
}
Liu, George E., et al. "Analysis of copy number variations among diverse cattle breeds." Genome research 20.5 (2010): 693-703.

%36
@Article{36She,
  author =       "She, Xinwei and et al",
  title =        "Mouse segmental duplication and copy number variation",
  year =         "2008",
  journal =      "Nature genetics",
  volume =       "40(7)",
  pages =        "909-914"
}
She, Xinwei, et al. "Mouse segmental duplication and copy number variation." Nature genetics 40.7 (2008): 909-914.
@article{LRP1,
  title={On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation},
  author={Bach, Sebastian and Binder, Alexander and Montavon, Gr{\'e}goire and Klauschen, Frederick and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
  journal={PloS one},
  volume={10},
  number={7},
  year={2015},
  publisher={Public Library of Science}
}

@article{DTD,
  title={Explaining nonlinear classification decisions with deep taylor decomposition},
  author={Montavon, Gr{\'e}goire and Lapuschkin, Sebastian and Binder, Alexander and Samek, Wojciech and M{\"u}ller, Klaus-Robert},
  journal={Pattern Recognition},
  volume={65},
  pages={211--222},
  year={2017},
  publisher={Elsevier}
}
@article{klambauer2017self,
  title={Self-normalizing neural networks},
  author={Klambauer, G{\"u}nter and Unterthiner, Thomas and Mayr, Andreas and Hochreiter, Sepp},
  journal={Advances in neural information processing systems},
  volume={30},
  pages={971--980},
  year={2017}
}
@article{jacovi2020towards,
  title={Towards Faithfully Interpretable NLP Systems: How should we define and evaluate faithfulness?},
  author={Jacovi, Alon and Goldberg, Yoav},
  journal={arXiv preprint arXiv:2004.03685},
  year={2020}
}
@article{vskrlj2020feature,
  title={Feature importance estimation with self-attention networks},
  author={{\v{S}}krlj, Bla{\v{z}} and D{\v{z}}eroski, Sa{\v{s}}o and Lavra{\v{c}}, Nada and Petkovi{\v{c}}, Matej},
  journal={arXiv preprint arXiv:2002.04464},
  year={2020}
}
@article{holzinger2020measuring,
  title={Measuring the quality of explanations: the system causability scale (SCS)},
  author={Holzinger, Andreas and Carrington, Andr{\'e} and M{\"u}ller, Heimo},
  journal={KI-K{\"u}nstliche Intelligenz},
  pages={1--6},
  year={2020},
  publisher={Springer}
}
@article{holzinger2019causability,
  title={Causability and explainability of artificial intelligence in medicine},
  author={Holzinger, Andreas and Langs, Georg and Denk, Helmut and Zatloukal, Kurt and M{\"u}ller, Heimo},
  journal={Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
  volume={9},
  number={4},
  pages={e1312},
  year={2019},
  publisher={Wiley Online Library}
  }
@inproceedings{zaidan2007using,
  title={Using “annotator rationales” to improve machine learning for text categorization},
  author={Zaidan, Omar and Eisner, Jason and Piatko, Christine},
  booktitle={Human language technologies 2007: The conference of the North American chapter of the association for computational linguistics; proceedings of the main conference},
  pages={260--267},
  year={2007}
}
@article{herrewijnenmachine,
  title={Machine-annotated Rationales: Faithfully Explaining Text Classification},
  author={Herrewijnen, Elize and Nguyen, Dong and Mense, Jelte and Bex, Floris}
}
@article{deyoung2019eraser,
  title={Eraser: A benchmark to evaluate rationalized nlp models},
  author={DeYoung, Jay and Jain, Sarthak and Rajani, Nazneen Fatema and Lehman, Eric and Xiong, Caiming and Socher, Richard and Wallace, Byron C},
  journal={arXiv preprint arXiv:1911.03429},
  year={2019}
}
@article{han2000mining,
  title={Mining frequent patterns without candidate generation},
  author={Han, Jiawei and Pei, Jian and Yin, Yiwen},
  journal={ACM sigmod record},
  volume={29},
  number={2},
  pages={1--12},
  year={2000},
  publisher={ACM New York, NY, USA}
}
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  pages={5998--6008},
  year={2017}
}
@article{duchi2011adaptive,
  title={Adaptive subgradient methods for online learning and stochastic optimization.},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of machine learning research},
  volume={12},
  number={7},
  year={2011}
}
@article{LRP2,
  title={Explaining Convolutional Neural Networks using Softmax Gradient Layer-wise Relevance Propagation},
  author={Iwana, Brian Kenji and Kuroki, Ryohei and Uchida, Seiichi},
  journal={arXiv preprint arXiv:1908.04351},
  year={2019}
}
@article{gene_clustering,
author = {Thalamuthu, Anbupalam and Mukhopadhyay, Indranil and Zheng, Xiaojing  et al.},
title = {Evaluation and comparison of gene clustering methods in microarray analysis},
journal = {Bioinformatics},
volume = {22},
number = {19},
pages = {2405-2412},
year = {2006},
publisher={Oxford Academic}
}
@article{hubert1985comparing,
  title={Comparing partitions},
  author={Hubert, Lawrence and Arabie, Phipps},
  journal={Journal of classification},
  volume={2},
  number={1},
  pages={193--218},
  year={1985},
  publisher={Springer}
}
@article{strehl2002cluster,
  title={Cluster ensembles---a knowledge reuse framework for combining multiple partitions},
  author={Strehl, Alexander and Ghosh, Joydeep},
  journal={Journal of machine learning research},
  volume={3},
  number={Dec},
  pages={583--617},
  year={2002},
  publisher={MIT Press}
}
@article{renganathan2017text,
  title={Text Mining in Biomedical Domain with Emphasis on Document Clustering},
  author={Renganathan, Vinaitheerthan},
  journal={Healthcare informatics research},
  volume={23},
  number={3},
  pages={141--146},
  year={2017},
  publisher={Springer}
}
@inproceedings{grasser2018aspect,
  title={Aspect-based sentiment analysis of drug reviews applying cross-domain and cross-data learning},
  author={Gr{\"a}{\ss}er, Felix and Kallumadi, Surya and Malberg, Hagen  et al.},
  booktitle={Proceedings of the 2018 International Conference on Digital Health},
  pages={121--125},
  year={2018},
  organization={ACM}
}
@article{aresta2019bach,
  title={Bach: Grand challenge on breast cancer histology images},
  author={Aresta, Guilherme and Ara{\'u}jo, Teresa and Kwok, Scotty  et al.},
  journal={Medical image analysis},
  year={2019},
  volume={56},
  publisher={Elsevier}
}

@inproceedings{rosenberg2007v,
  title={V-measure: A conditional entropy-based external cluster evaluation measure},
  author={Rosenberg, Andrew and Hirschberg, Julia},
  booktitle={Proceedings of the 2007 joint conference on empirical methods in natural language processing and computational natural language learning (EMNLP-CoNLL)},
  pages={410--420},
  address={Prague, Czech Republic},
  year={2007},
  organization={ACL SIGDAT and ACL SIGNLL}
}
@article{RCC,
  title={Robust continuous clustering},
  author={Shah, Sohil Atul and Koltun, Vladlen},
  journal={Proceedings of the National Academy of Sciences},
  volume={114},
  number={37},
  pages={9814--9819},
  year={2017},
  publisher={National Acad Sciences}
}
@inproceedings{ghasedi2017deep,
  title={Deep clustering via joint convolutional autoencoder embedding and relative entropy minimization},
  author={Ghasedi Dizaji, Kamran and Herandi, Amirhossein and Deng, Cheng  et al.},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={5736--5745},
  year={2017},
  organization={IEEE}
}
@inproceedings{choi2016retain,
  title={Retain: An interpretable predictive model for healthcare using reverse time attention mechanism},
  author={Choi, Edward and Stewart, Walter},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3504--3512},
  address={Barcelona, Spain},
  year={2016},
  organization={Neural Information Processing Systems Foundation}
}
@article{mcdaid2011normalized,
  title={Normalized mutual information to evaluate overlapping community finding algorithms},
  author={McDaid, Aaron F and Greene, Derek and Hurley, Neil},
  journal={arXiv preprint arXiv:1110.2515},
  year={2011}
}
@inproceedings{chen2016infogan,
  title={Infogan: Interpretable representation learning by information maximizing generative adversarial nets},
  author={Chen, Xi and Duan, Yan and Houthooft, Rein  et al.},
  booktitle={Advances in neural information processing systems},
  pages={2172--2180},
  address={Barcelona, Spain},
  year={2016},
  organization={Neural Information Processing Systems Foundation}
}
@article{kuhn1955hungarian,
  title={The Hungarian method for the assignment problem},
  author={Kuhn, Harold W},
  journal={Naval research logistics quarterly},
  volume={2},
  number={1-2},
  pages={83--97},
  year={1955},
  publisher={Wiley Online Library}
}

@article{NMMC,
  title={Deep learning with nonparametric clustering},
  author={Chen, Gang},
  journal={arXiv preprint arXiv:1501.03084},
  year={2015}
}
@article{masood2015clustering,
  title={Clustering techniques in bioinformatics},
  author={Masood, Muhammad Ali and Khan, MNA},
  journal={IJ Modern Education and Computer Science},
  volume={1},
  pages={38--46},
  year={2015}
}
@inproceedings{jaques2017multimodal,
  title={Multimodal autoencoder: A deep learning approach to filling in missing sensor data and enabling better mood prediction},
  author={Jaques, Natasha and Taylor, Sara and Sano, Akane  et al.},
  booktitle={2017 Seventh International Conference on Affective Computing and Intelligent Interaction (ACII)},
  pages={202--208},
  address={San Antonio, Texas, USA},
  year={2017},
  organization={IEEE}
}
@article{eisen1998cluster,
  title={Cluster analysis and display of genome-wide expression patterns},
  author={Eisen, Michael B and Spellman, Paul T and Brown, Patrick O  et al.},
  journal={Proceedings of the National Academy of Sciences},
  volume={95},
  number={25},
  pages={14863--14868},
  year={1998},
  publisher={National Acad Sciences}
}
@article{karmakar2019tight,
  title={Tight clustering for large datasets with an application to gene expression data},
  author={Karmakar, Bikram and Das, Sarmistha and Bhattacharya, Sohom  et al.},
  journal={Scientific reports},
  volume={9},
  number={1},
  pages={3053},
  year={2019},
  publisher={Nature Publishing Group}
}
@inproceedings{zhao2005tricluster,
  title={Tricluster: an effective algorithm for mining coherent clusters in {3D} microarray data},
  author={Zhao, Lizhuang and Zaki, Mohammed J},
  booktitle={Proceedings of the 2005 ACM SIGMOD int. conf. on Management of data},
  pages={694--705},
  address = {Baltimore, Maryland, USA},
  year={2005},
  organization={ACM}
}
@article{oyelade2016clustering,
  title={Clustering algorithms: Their application to gene expression data},
  author={Oyelade, Jelili and Isewon, Itunuoluwa and Oladipupo, Funke et al.},
  journal={Bioinformatics and Biology insights},
  volume={10},
  pages={BBI--S38316},
  year={2016},
  publisher={SAGE Publications Sage UK: London, England}
}
@book{zaccone2018deep,
  title={Deep Learning with TensorFlow: Explore neural networks and build intelligent systems with Python},
  author={Zaccone, Giancarlo and Karim, Md Rezaul},
  year={2018},
  publisher={Packt Publishing Ltd}
}
@article{martin2019traditional,
  title={Traditional and heavy-tailed self regularization in neural network models},
  author={Martin, Charles H and Mahoney, Michael W},
  journal={arXiv preprint arXiv:1901.08276},
  year={2019}
}
@article{tolstoy2005death,
  title={The Death of Ivan Ilyich},
  author={Tolstoy, Leo},
  journal={ACADEMIC MEDICINE-PHILADELPHIA-},
  volume={80},
  number={9},
  pages={856},
  year={2005},
  publisher={ASSOCIATION OF AMERICAN MEDICAL COLLEGES}
}
@article{kim2020extending,
  title={Extending Class Activation Mapping Using Gaussian Receptive Field},
  author={Kim, Bum Jun and Koo, Gyogwon and Choi, Hyeyeon and Kim, Sang Woo},
  journal={arXiv preprint arXiv:2001.05153},
  year={2020}
}
@book{karim2018java,
  title={Java Deep Learning Projects: Implement 10 real-world deep learning applications using Deeplearning4j and open source APIs},
  author={Karim, Md Rezaul},
  year={2018},
  publisher={Packt Publishing Ltd}
}
@inproceedings{zhou2016learning,
  title={Learning deep features for discriminative localization},
  author={Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2921--2929},
  year={2016}
}
@book{karim2018scala,
  title={Scala Machine Learning Projects: Build real-world machine learning and deep learning projects with Scala},
  author={Karim, Md Rezaul},
  year={2018},
  publisher={Packt Publishing Ltd}
}
@article{mitchell1997machine,
  title={Machine learning. 1997},
  author={Mitchell, Tom M and others},
  journal={Burr Ridge, IL: McGraw Hill},
  volume={45},
  number={37},
  pages={870--877},
  year={1997}
}
@article{singla2019understanding,
  title={Understanding Impacts of High-Order Loss Approximations and Features in Deep Learning Interpretation},
  author={Singla, Sahil and Wallace, Eric and Feng, Shi and Feizi, Soheil},
  journal={arXiv preprint arXiv:1902.00407},
  year={2019}
}
@book{molnar2019interpretable,
  title={Interpretable machine learning},
  author={Molnar, Christoph},
  year={2019},
  publisher={Lulu. com}
}
@article{baehrens2010explain,
  title={How to explain individual classification decisions},
  author={Baehrens, David and Schroeter, Timon and Harmeling, Stefan and Kawanabe, Motoaki and Hansen, Katja and M{\~A}{\v{z}}ller, Klaus-Robert},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Jun},
  pages={1803--1831},
  year={2010}
}

@inproceedings{ribeiro2018anchors,
  title={Anchors: High-precision model-agnostic explanations},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}
@inproceedings{bhatt2020explainable,
  title={Explainable machine learning in deployment},
  author={Bhatt, Umang and Xiang, Alice and Sharma, Shubham and Weller, Adrian and Taly, Ankur and Jia, Yunhan and Ghosh, Joydeep and Puri, Ruchir and Moura, Jos{\'e} MF and Eckersley, Peter},
  booktitle={Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
  pages={648--657},
  year={2020}
}
@article{sharma2019certifai,
  title={Certifai: Counterfactual explanations for robustness, transparency, interpretability, and fairness of artificial intelligence models},
  author={Sharma, Shubham and Henderson, Jette and Ghosh, Joydeep},
  journal={arXiv preprint arXiv:1905.07857},
  year={2019}
}
@article{tseng2005tight,
  title={Tight clustering: a resampling-based approach for identifying stable and tight patterns in data},
  author={Tseng, George C and Wong, Wing H},
  journal={Biometrics},
  volume={61},
  number={1},
  pages={10--16},
  year={2005},
  publisher={Wiley Online Library}
}
@article{proDBSCAN,
  title={A prototype-based modified {DBSCAN} for gene clustering},
  author={Edla, Damodar Reddy and Jana, Prasanta K and Member, IEEE Senior},
  journal={Procedia Technology},
  volume={6},
  pages={485--492},
  year={2012},
  publisher={Elsevier}
}
@inproceedings{motif,
  title={Constructing Super Rule Tree ({SRT}) for Protein Motif Clusters Using DBSCAN},
  author={Chen, Bernard and Suer, Sait and Ercan, Muhyeddin  et al.},
  booktitle={Proceedings of the International Conference on Bioinformatics \& Computational Biology (BIOCOMP)},
  pages={1},
  year={2011},
  organization={Citeseer}
}

@article{SEG,
  title={Segmentation of brain tumour from {MRI} image analysis of k-means and dbscan clustering},
  author={Bandyopadhyay, Samir Kumar and Paul, Tuhin Utsab},
  journal={International Journal of Research in Engineering and Science},
  volume={1},
  number={1},
  pages={48--57},
  year={2013}
}

@article{PS,
  title={{PSCAN}: Parallel, densitybased clustering of protein sequences},
  author={Brul{\'e}, Joshua},
  volume={1},
  number={1},
  pages={48--57},
  year={2015},
  journal={Intelligent Data Analysis},
  publisher={IOS Press}
}

@article{bisecting,
  title={A comparative analysis on the bisecting {K}-means and the {PDDP} clustering algorithms},
  author={Savaresi, Sergio M and Boley, Daniel L},
  journal={Intelligent Data Analysis},
  volume={8},
  number={4},
  pages={345--362},
  year={2004},
  publisher={IOS Press}
}
@article{yeung2001empirical,
  title={An empirical study on principal component analysis for clustering gene expression data},
  author={Yeung, Ka Yee and Ruzzo, Walter L},
  journal={Bioinformatics},
  volume={17},
  number={9},
  pages={763--774},
  year={2001}
}
@article{ADMIXTURE,
  title={Estimating African American admixture proportions by use of population-specific alleles},
  author={Parra, Esteban J and Marcini, Amy and Akey, Joshua  et al.},
  journal={The American Journal of Human Genetics},
  volume={63},
  number={6},
  pages={1839--1851},
  year={1998},
  publisher={Elsevier}
}
@article{variantspark,
  title={VariantSpark: population scale clustering of genotype information},
  author={O’Brien, Aidan R and Saunders, Neil FW and Guo, Yi  et al.},
  journal={BMC genomics},
  volume={16},
  number={1},
  pages={1052},
  year={2015},
  publisher={BioMed Central}
}
@article{eraslan2019single,
  title={Single-cell {RNA}-seq denoising using a deep count autoencoder},
  author={Eraslan, G{\"o}kcen and Simon, Lukas M and Mircea, Maria  et al.},
  journal={Nature communications},
  volume={10},
  number={1},
  pages={390},
  year={2019},
  publisher={Nature Publishing Group}
}
@article{vinh2010information,
  title={Information theoretic measures for clusterings comparison: Variants, properties, normalization and correction for chance},
  author={Vinh, Nguyen Xuan and Epps, Julien and Bailey, James},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Oct},
  pages={2837--2854},
  year={2010}
}

@article{rand1971objective,
  title={Objective criteria for the evaluation of clustering methods},
  author={Rand, William M},
  journal={Journal of the American Statistical association},
  volume={66},
  number={336},
  pages={846--850},
  year={1971},
  publisher={Taylor \& Francis Group}
}
@article{liu2008assessing,
  title={Assessing agreement of clustering methods with gene expression microarray data},
  author={Liu, Xueli and Lee, Sheng-Chien and Casella, George  et al.},
  journal={Computational Statistics \& Data Analysis},
  volume={52},
  number={12},
  pages={5356--5366},
  year={2008},
  publisher={Elsevier}
}
@article{MODEL,
  title={Model-based clustering and data transformations for gene expression data},
  author={Yeung, Ka Yee and Fraley, Chris and Murua, Alejandro  et al.},
  journal={Bioinformatics},
  volume={17},
  number={10},
  pages={977--987},
  year={2001},
  publisher={Oxford University Press}
}
@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton  et al.},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}
@misc{CA,
  title={Cluster analysis: Wiley series in probability and statistics},
  author={Everitt, Brian S and Landau, Sabine and Leese, Morven  et al.},
  year={2011},
  publisher={Wiley Chichester}
}
@inproceedings{OPTICS,
  title={{OPTICS}: ordering points to identify the clustering structure},
  author={Ankerst, Mihael and Breunig, Markus M and Kriegel, Hans-Peter  et al.},
  booktitle={ACM Sigmod record},
  volume={28},
  number={2},
  pages={49--60},
  year={1999},
  organization={ACM}
}


@inproceedings{DBSCAN,
  title={A density-based algorithm for discovering clusters in large spatial databases with noise.},
  author={Ester, Martin and Kriegel, Hans-Peter and Sander, J{\"o}rg  et al.},
  booktitle={Kdd},
  volume={96},
  number={34},
  pages={226--231},
  year={1996}
}


@article{UMMC,
  title={{CNN}-based joint clustering and representation learning with feature drift compensation for large-scale image data},
  author={Hsu, Chih-Chung and Lin, Chia-Wen},
  journal={IEEE Transactions on Multimedia},
  volume={20},
  number={2},
  pages={421--429},
  year={2018},
  publisher={IEEE}
}
@article{DCC,
  title={Deep continuous clustering},
  author={Shah, Sohil Atul and Koltun, Vladlen},
  journal={arXiv preprint arXiv:1803.01449},
  year={2018}
}

@article{IMSAT,
  title={Learning Latent Representations in Neural Networks for Clustering through Pseudo Supervision and Graph-based Activity Regularization},
  author={Kilinc, Ozsel and Uysal, Ismail},
  journal={arXiv preprint arXiv:1802.03063},
  year={2018}
}

@inproceedings{SCCNN,
  title={Speaker identification and clustering using convolutional neural networks},
  author={Lukic, Yanick and Vogt, Carlo and D{\"u}rr, Oliver  et al.},
  booktitle={26th IEEE International Workshop on Machine Learning for Signal Processing (MLSP), Vietri sul Mare, Italy, 13-16 Sept. 2016},
  year={2016},
  organization={IEEE}
}

@inproceedings{DEPICT,
  title={Deep clustering via joint convolutional autoencoder embedding and relative entropy minimization},
  author={Dizaji, Kamran Ghasedi and Herandi, Amirhossein and Deng, Cheng  et al.},
  booktitle={Computer Vision (ICCV), 2017 IEEE International Conference on},
  pages={5747--5756},
  address={Venice, Italy},
  year={2017},
  organization={IEEE}
}

@inproceedings{DEN,
  title={Deep embedding network for clustering},
  author={Huang, Peihao and Huang, Yan and Wang, Wei  et al.},
  booktitle={Pattern Recognition (ICPR), 2014 22nd International Conference on},
  pages={1532--1537},
  year={2014},
  address={Stockholm, Sweden},
  organization={IEEE}
}
@article{UNET,
  author    = {Olaf Ronneberger and Philipp Fischer and Thomas Brox},
  title     = {{U-Net}: Convolutional Networks for Biomedical Image Segmentation},
  journal   = {CoRR},
  volume    = {abs/1505.04597}
}
@article{pancan,
  title={The cancer genome atlas pan-cancer analysis project},
  author={Weinstein, John N and Collisson, Eric A and Mills, Gordon B  et al.},
  journal={Nature genetics},
  volume={45},
  number={10},
  pages={1113},
  year={2013},
  publisher={Nature Publishing Group}
}
@article{PCA,
author = {Yeung, K. Y. and Ruzzo, W. L.},
title = {Principal component analysis for clustering gene expression
  data },
journal = {Bioinformatics},
volume = {17},
number = {9},
pages = {763-774},
year = {2001}
}
@article{hofmann2008kernel,
  title={Kernel methods in machine learning},
  author={Hofmann, Thomas and Sch{\"o}lkopf, Bernhard and Smola, Alexander J},
  journal={The annals of statistics},
  pages={1171--1220},
  year={2008},
  publisher={JSTOR}
}
@inproceedings{davidson2005agglomerative,
  title={Agglomerative hierarchical clustering with constraints: Theoretical and empirical results},
  author={Davidson, Ian and Ravi, SS},
  booktitle={European Conference on Principles of Data Mining and Knowledge Discovery},
  pages={59--70},
  address = {Heidelberg, Germany},
  year={2005},
  organization={Springer}
}

@article{estivill2002so,
  title={Why so many clustering algorithms: a position paper.},
  author={Estivill-Castro, Vladimir},
  journal={SIGKDD explorations},
  volume={4},
  number={1},
  pages={65--75},
  year={2002}
}
@inproceedings{ng2002spectral,
  title={On spectral clustering: Analysis and an algorithm},
  author={Ng, Andrew Y and Jordan, Michael I and Weiss, Yair},
  booktitle={Advances in neural information processing systems},
  pages={849--856},
  year={2002}
}
@inproceedings{SDAE2008,
  title={Extracting and composing robust features with denoising autoencoders},
  author={Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua  et al.},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={1096--1103},
  address={Lille, France},
  year={2008},
  organization={ACM}
}
@inproceedings{LSTM_Autoencoder,
  title={Unsupervised learning of video representations using lstms},
  author={Srivastava, Nitish and Mansimov, Elman and Salakhudinov, Ruslan},
  booktitle={International conference on machine learning},
  pages={843--852},
  year={2015}
}
@article{pam,
  title={Partitioning around medoids (program pam)},
  author={Kaufman, Leonard and Rousseeuw, Peter J},
  journal={Finding groups in data: an introduction to cluster analysis},
  pages={68--125},
  year={1990},
  publisher={Wiley New York}
}
@article{hc,
  title={Gene expression patterns of breast carcinomas distinguish tumor subclasses with clinical implications},
  author={S{\o}rlie, Therese and Perou, Charles M and Tibshirani, Robert  et al.},
  journal={Proceedings of the National Academy of Sciences},
  volume={98},
  number={19},
  pages={10869--10874},
  year={2001},
  publisher={National Acad Sciences}
}
@article{li2018discriminatively,
  title={Discriminatively boosted image clustering with fully convolutional auto-encoders},
  author={Li, Fengfu and Qiao, Hong and Zhang, Bo},
  journal={Pattern Recognition},
  volume={83},
  pages={161--173},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{kmeans1967,
  title={Some methods for classification and analysis of multivariate observations},
  author={MacQueen, James and others},
  booktitle={Proceedings of the 5th Berkeley symposium on mathematical statistics \& probability},
  volume={1},
  pages={281--297},
  year={1967},
  address={Oakland, USA}
}

@inproceedings{yang2016joint,
  title={Joint unsupervised learning of deep representations and image clusters},
  author={Yang, Jianwei and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={5147--5156},
  address={},
  year={2016},
  organization={IEEE}
}
@inproceedings{zivkovic2004improved,
  title={Improved adaptive Gaussian mixture model for background subtraction},
  author={Zivkovic, Zoran},
  booktitle={Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.},
  volume={2},
  pages={28--31},
  address={Cambridge, UK},
  year={2004},
  organization={IEEE}
}

@article{lin2019depth,
  title={Depth estimation and semantic segmentation from a single RGB image using a hybrid convolutional neural network},
  author={Lin, Xiao and S{\'a}nchez-Escobedo, Dalila and Casas, Josep R  et al.},
  journal={Sensors},
  volume={19},
  number={8},
  pages={1795},
  year={2019},
  publisher={Multidisciplinary Digital Publishing Institute}
}
@article{chiu2017dental,
  title={Dental health status of community-dwelling older Singaporeans: findings from a nationally representative survey},
  author={Chiu, Chi-Tsun and Malhotra, Rahul and others},
  authorALL={Chiu, Chi-Tsun and Malhotra, Rahul and Tan, See Mieng  et al.},
  journal={Gerodontology},
  volume={34},
  number={1},
  pages={57--67},
  year={2017},
  publisher={Wiley Online Library}
}
@article{som,
  title={The self-organizing map},
  author={Kohonen, Teuvo},
  journal={Neurocomputing},
  volume={21},
  number={1-3},
  pages={1--6},
  year={1998},
  publisher={Elsevier}
}
@article{araujo2017classification,
  title={Classification of breast cancer histology images using convolutional neural networks},
  author={Ara{\'u}jo, Teresa and Aresta, Guilherme and Castro, Eduardo  et al.},
  journal={PloS one},
  volume={12},
  number={6},
  pages={e0177544},
  year={2017},
  publisher={Public Library of Science}
}
@article{chowdary2014evaluating,
  title={Evaluating and analyzing clusters in data mining using different algorithms},
  author={Chowdary, N Sunil and Prasanna, DS and Sudhakar, P},
  journal={Int. J. Comput. Sci. Mob. Comput},
  volume={3},
  pages={86--99},
  year={2014}
}
@book{CHARU,
  title={Data clustering: theory, algorithms, and applications},
  author={Gan, Guojun and Ma, Chaoqun and Wu, Jianhong},
  volume={20},
  year={2007},
  publisher={Wiley Online Library}
}
@article{fu2012cd,
  title={CD-HIT: accelerated for clustering the next-generation sequencing data},
  author={Fu, Limin and Niu, Beifang and Zhu, Zhengwei  et al.},
  journal={Bioinformatics},
  volume={28},
  number={23},
  pages={3150--3152},
  year={2012},
  publisher={Oxford University Press}
}
@article{UDA,
  title={Unsupervised Data Augmentation for Consistency Training},
  author={Xie, Qizhe and Dai, Zihang and Hovy, Eduard  et al.},
  journal={arXiv preprint arXiv:1904.12848},
  year={2019}
}
@inproceedings{janssens2007dynamic,
  title={Dynamic hybrid clustering of bioinformatics by incorporating text mining and citation analysis},
  author={Janssens, Frizo and Gl{\"a}nzel, Wolfgang and De Moor, Bart},
  booktitle={Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={360--369},
  year={2007},
  organization={ACM}
}
@article{jiang2004cluster,
  title={Cluster analysis for gene expression data: A survey},
  author={Jiang, Daxin and Tang, Chun and Zhang, Aidong},
  journal={IEEE Transactions on Knowledge \& Data Engineering},
  volume={11},
  pages={1370--1386},
  year={2004},
  publisher={IEEE}
}
@article{de2008clustering,
  title={Clustering cancer gene expression data: a comparative study},
  author={De Souto, Marcilio CP and Costa, Ivan G and de Araujo, Daniel SA  et al.},
  journal={BMC bioinformatics},
  volume={9},
  number={1},
  pages={497},
  year={2008},
  publisher={BioMed Central}
}
@article{wold1987principal,
  title={Principal component analysis},
  author={Wold, Svante and Esbensen, Kim and Geladi, Paul},
  journal={Chemometrics and intelligent laboratory systems},
  volume={2},
  number={1-3},
  pages={37--52},
  year={1987},
  publisher={Elsevier}
}
@inproceedings{DAC,
  title={Deep adaptive image clustering},
  author={Chang, Jianlong and Wang, Lingfeng and Meng, Gaofeng  et al.},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={5879--5887},
  year={2017},
  publisher={IEEE}
}
@article{AAE,
  title={Adversarial autoencoders},
  author={Makhzani, Alireza and Shlens, Jonathon and Jaitly, Navdeep  et al.},
  journal={arXiv preprint arXiv:1511.05644},
  year={2015}
}
@article{min2018survey,
  title={A survey of clustering with deep learning: From the perspective of network architecture},
  author={Min, Erxue and Guo, Xifeng and Liu, Qiang  et al.},
  journal={IEEE Access},
  volume={6},
  pages={39501--39514},
  year={2018},
  publisher={IEEE}
}
@article{jaskowiak2013proximity,
  title={Proximity measures for clustering gene expression microarray data: a validation methodology and a comparative analysis},
  author={Jaskowiak, Pablo A and Campello, Ricardo JGB and Costa Filho, Ivan G},
  journal={IEEE/ACM Transactions on Computational Biology and Bioinformatics (TCBB)},
  volume={10},
  number={4},
  pages={845--857},
  year={2013},
  publisher={IEEE Computer Society Press}
}
@article{costa2004comparative,
  title={Comparative analysis of clustering methods for gene expression time course data},
  author={Costa, Ivan G and de Carvalho, Francisco de AT and de Souto, Marc{\'\i}lio CP},
  journal={Genetics and Molecular Biology},
  volume={27},
  number={4},
  pages={623--631},
  year={2004},
  publisher={SciELO Brasil}
}
@article{som_use,
  title={Gene expression clustering using self-organizing maps: analysis of the macrophage response to particulate biomaterials},
  author={Garrigues, Grant E and Cho, David R and Rubash, Harry E  et al.},
  journal={Biomaterials},
  volume={26},
  number={16},
  pages={2933--2945},
  year={2005},
  publisher={Elsevier}
}
@article{KLD,
  title={{Kullback-Leibler} divergence},
  author={Joyce, James M},
  journal={International encyclopedia of statistical science},
  pages={720--722},
  year={2011},
  publisher={Springer}
}
@article{hsu2015neural,
  title={Neural network-based clustering using pairwise constraints},
  author={Hsu, Yen-Chang and Kira, Zsolt},
  journal={arXiv preprint arXiv:1511.06321},
  year={2015}
}
@article{1,
  title={Improving data workflow systems with cloud services and use of open data for bioinformatics research},
  author={Karim, Md Rezaul and Michel, Audrey and Zappa, Achille  et al.},
  journal={Briefings in Bioinformatics},
  pages={bbx039},
  year={2017},
  publisher={Oxford University Press}
}

@article{2,
  title={Fast model-based estimation of ancestry in unrelated individuals},
  author={Alexander, David H and Novembre, John and Lange, Kenneth},
  journal={Genome research},
  volume={19},
  number={9},
  pages={1655--1664},
  year={2009},
  publisher={Cold Spring Harbor Lab}
}
@article{spellman1998comprehensive,
  title={Comprehensive identification of cell cycle--regulated genes of the yeast Saccharomyces cerevisiae by microarray hybridization},
  author={Spellman, Paul T and Sherlock, Gavin and Zhang, Michael Q  et al.},
  journal={Molecular biology of the cell},
  volume={9},
  number={12},
  pages={3273--3297},
  year={1998},
  publisher={Am Soc Cell Biol}
}
@article{tavazoie1999systematic,
  title={Systematic determination of genetic network architecture},
  author={Tavazoie, Saeed and Hughes, Jason D and Campbell, Michael J  et al.},
  journal={Nature genetics},
  volume={22},
  number={3},
  pages={281},
  year={1999},
  publisher={Nature Publishing Group}
}
@inproceedings{shahapurkar2004comparison,
  title={Comparison of self-organizing map with k-means hierarchical clustering for bioinformatics applications},
  author={Shahapurkar, Somnath S and Sundareshan, Malur K},
  booktitle={Neural Networks, 2004. Proceedings. 2004 IEEE International Joint Conference on},
  volume={2},
  pages={1221--1226},
  address={Budapest, Hungary},
  year={2004},
  organization={IEEE}
}

@article{min2017deep,
  title={Deep learning in bioinformatics},
  author={Min, Seonwoo and Lee, Byunghan and Yoon, Sungroh},
  journal={Briefings in bioinformatics},
  volume={18},
  number={5},
  pages={851--869},
  year={2017},
  publisher={Oxford University Press}
}

@article{3,
  title={Human population structure detection via multilocus genotype clustering},
  author={Gao, Xiaoyi and Starmer, Joshua},
  journal={BMC genetics},
  volume={8},
  number={1},
  pages={34},
  year={2007},
  publisher={BioMed Central}
}

@article{4,
  title={Inferring ancestry from population genomic data and its applications},
  author={Padhukasahasram, Badri},
  journal={Frontiers in genetics},
  volume={5},
  year={2014},
  publisher={Frontiers Media SA}
}

@article{5,
  title={Population genetic inference from personal genome data: impact of ancestry and admixture on human genomic variation},
  author={Kidd, Jeffrey M and Gravel, Simon and Byrnes, Jake  et al.},
  journal={The American Journal of Human Genetics},
  volume={91},
  number={4},
  pages={660--671},
  year={2012},
  publisher={Elsevier}
}

@article{6,
  title={An integrated map of genetic variation from 1,092 human genomes},
  author={1000 Genomes Project Consortium and others},
  journal={Nature},
  volume={491},
  number={7422},
  pages={56},
  year={2012},
  publisher={Europe PMC Funders}
}

@article{7,
  title={Deep learning in bioinformatics},
  author={Min, Seonwoo and Lee, Byunghan and Yoon, Sungroh},
  journal={Briefings in bioinformatics},
  pages={bbw068},
  year={2016},
  publisher={Oxford University Press}
}

@article{aljalbout2018clustering,
  title={Clustering with Deep Learning: Taxonomy and New Methods},
  author={Aljalbout, Elie and Golkov, Vladimir and Siddiqui, Yawar  et al.},
  journal={arXiv preprint arXiv:1801.07648},
  year={2018}
}

@article{VADE,
  title={Variational deep embedding: A generative approach to clustering},
  author={Zheng, Yin and Tan, Huachun and Tang, Bangsheng  et al.},
  journal={arXiv preprint arXiv:1611.05148},
  volume={1},
  number={2},
  pages={5},
  year={2016}
}
@book{lintas2017artificial,
  title={Artificial Neural Networks and Machine Learning--ICANN 2017: 26th International Conference on Artificial Neural Networks, Alghero, Italy, September 11-14, 2017, Proceedings},
  author={Lintas, Alessandra and Rovetta, Stefano and Verschure, Paul FMJ  et al.},
  volume={10614},
  year={2017},
  publisher={Springer}
}

@inproceedings{EC,
  title={Spectral ensemble clustering},
  author={Liu, Hongfu and Liu, Tongliang and Wu, Junjie  et al.},
  booktitle={Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={715--724},
  year={2015},
  organization={ACM}
}

@article{zheng2016variational,
  title={Variational deep embedding: A generative approach to clustering},
  author={Zheng, Yin and Tan, Huachun and Tang, Bangsheng  et al.},
  journal={arXiv preprint arXiv:1611.05148},
  volume={1},
  number={2},
  pages={5},
  year={2016}
}

@article{li2017discriminatively,
  title={Discriminatively Boosted Image Clustering with Fully Convolutional Auto-Encoders},
  author={Li, Fengfu and Qiao, Hong and Zhang, Bo  et al.},
  journal={arXiv preprint arXiv:1703.07980},
  year={2017}
}

@article{10002015global,
  title={A global reference for human genetic variation},
  author={1000 Genomes Project Consortium and others},
  journal={Nature},
  volume={526},
  number={7571},
  pages={68},
  year={2015},
  publisher={Nature Publishing Group}
}

@misc{8,
  title={Hands on Machine Learning with scikit-learn and {Tensorflow}},
  author={G{\'e}ron, Aur{\'e}lien},
  year={2017},
  publisher={O’Reilly Media}
}

@article{laitman2013haplotype,
  title={Haplotype analysis of the {185delAG} {BRCA1} mutation in ethnically diverse populations},
  author={Laitman, Yael and Feng, Bing-Jian and Zamir, Itay M  et al.},
  journal={European Journal of Human Genetics},
  volume={21},
  number={2},
  pages={212},
  year={2013},
  publisher={Nature Publishing Group}
}

@misc{smlp,
  title={Scala Machine Learning Projects},
  author={M.R. Karim},
  edition={1st},
  year={2018},
  publisher={Packt Publishing Ltd.}
}

@article{10,
  title={Machine learning in genomic medicine: a review of computational problems and data sets},
  author={Leung, Michael KK and Delong, Andrew and Alipanahi, Babak  et al.},
  journal={Proceedings of the IEEE},
  volume={104},
  number={1},
  pages={176--197},
  year={2016},
  publisher={IEEE}
}

@article{15,
  title={Adam: Genomics formats and processing patterns for cloud scale computing},
  author={Massie, Matt and Nothaft, Frank and Hartl, Christopher  et al.},
  journal={EECS Department, University of California, Berkeley, Tech. Rep. UCB/EECS-2013-207},
  year={2013}
}

@inproceedings{karimdeep,
  title={A Deep Learning Approach to Genomics Data for Population Scale Clustering and Ethnicity Prediction},
  author={Karim, Md Rezaul and Zappa, Achille and Sahay, Ratnesh  et al.},
  booktitle={Proceedings of ESWC workshop on Semantic Web solutions for Large-scale Biomedical Data Analytics~(SeWeBMeDA'17)},
  pages={1--15},
  organization={ESWC},
  year={2017}
}
@inproceedings{16,
	title={
	Accelerating spark with {RDMA} for big data processing: Early experiences},
	author={Lu, Xiaoyi and Rahman, Md Wasi Ur and Islam, Nusrat  et al.},
	booktitle={High-performance interconnects (HOTI), 2014 IEEE 22nd annual symposium on},
	pages={9--16},
	year={2014},
	organization={IEEE}
}
@inproceedings{kl,
  title={Approximating the {Kullback} {Leibler} divergence between {Gaussian} mixture models},
  author={Hershey, John R and Olsen, Peder A},
  booktitle={Acoustics, Speech and Signal Processing, 2007. ICASSP 2007. IEEE International Conference on},
  volume={4},
  pages={IV--317},
  year={2007},
  organization={IEEE}
}
@article{26,
  title={Limitations of maximum likelihood estimation procedures when a majority of the observations are below the limit of detection},
  author={Jain, Ram B and Wang, Richard Y},
  journal={Analytical chemistry},
  volume={80},
  number={12},
  pages={4767--4772},
  year={2008},
  publisher={ACS Publications}
}
@article{weinstein2013cancer,
  title={The cancer genome atlas pan-cancer analysis project},
  author={Weinstein, John N and Collisson, Eric A and Mills, Gordon B and Shaw, Kenna R Mills and Ozenberger, Brad A and Ellrott, Kyle and Shmulevich, Ilya and Sander, Chris and Stuart, Joshua M and Cancer Genome Atlas Research Network and others},
  journal={Nature genetics},
  volume={45},
  number={10},
  pages={1113},
  year={2013},
  publisher={Nature Publishing Group}
}
@inproceedings{yu2019unsupervised,
  title={Unsupervised Out-of-Distribution Detection by Maximum Classifier Discrepancy},
  author={Yu, Qing and Aizawa, Kiyoharu},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={9518--9526},
  year={2019}
}
@inproceedings{horn1990hadamard,
  title={The hadamard product},
  author={Horn, Roger A},
  booktitle={Proc. Symp. Appl. Math},
  volume={40},
  pages={87--169},
  year={1990}
}
@book{branzei2008models,
  title={Models in cooperative game theory},
  author={Branzei, Rodica and Dimitrov, Dinko and Tijs, Stef},
  volume={556},
  year={2008},
  publisher={Springer Science \& Business Media}
}
@article{elbow,
  title={Estimating the number of clusters in a data set via the gap statistic},
  author={Tibshirani, Robert and Walther, Guenther and Hastie, Trevor},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={63},
  number={2},
  pages={411--423},
  year={2001},
  publisher={Wiley Online Library}
}
@article{alirezaie2019semantic,
  title={Semantic Referee: A Neural-Symbolic Framework for Enhancing Geospatial Semantic Segmentation},
  author={Alirezaie, Marjan and L{\"a}ngkvist, Martin and Sioutis, Michael and Loutfi, Amy},
  journal={arXiv preprint arXiv:1904.13196},
  year={2019}
}
@article{KarimIEEEAccess2019,
author={M. R. {Karim} and G. {Wicaksono} and I. {G. Costa}  et al.},
journal={IEEE Access},
title={Prognostically Relevant Subtypes and Survival Prediction for Breast Cancer Based on Multimodal Genomics Data},
year={2019},
volume={7},
number={},
pages={133850-133864}
}
@article{KarimNCCA2019,
author={M. R. {Karim} and A. {Rahman} and S. {Decker} and O. {Beyan}},
journal={Neural Computing and Applications},
title={A Snapshot Neural Ensemble Method for Cancer Type Prediction Based on Copy Number Variations},
year={2019},
volume={2},
number={},
pages={21-45}
}

@inproceedings{karim2019drug,
  title={Drug-Drug Interaction Prediction Based on Knowledge Graph Embeddings and Convolutional-LSTM Network},
  author={Karim, Md Rezaul and Cochez, Michael and Jares, Joao Bosco  et al.},
  booktitle={Proceedings of the 10th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics},
  pages={113--123},
  address={Niagara Falls, NY, USA},
  year={2019},
  organization={ACM}
}
@article{karim2019onconetexplainer,
  title={{OncoNetExplainer}: Explainable Predictions of Cancer Types Based on Gene Expression Data},
  author={Karim, Md and Cochez, Michael and Beyan, Oya  et al.},
  journal={arXiv preprint arXiv:1909.04169},
  year={2019}
}
@inproceedings{glorot2010understanding,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Proceedings of the 13th international conf. on artificial intelligence and statistics},
  pages={249--256},
  year={2010}
}
@article{pidsley2013data,
  title={A data-driven approach to preprocessing Illumina 450K methylation array data},
  author={Pidsley, Ruth and Wong, Chloe CY and Volta, Manuela and Lunnon, Katie and Mill, Jonathan and Schalkwyk, Leonard C},
  journal={BMC genomics},
  volume={14},
  number={1},
  pages={293},
  year={2013},
  publisher={Springer}
}
@article{guo2017improvements,
  title={Improvements and impacts of GRCh38 human reference on high throughput sequencing data analysis},
  author={Guo, Yan and Dai, Yulin and Yu, Hui and Zhao, Shilin and Samuels, David C and Shyr, Yu},
  journal={Genomics},
  volume={109},
  number={2},
  pages={83--90},
  year={2017},
  publisher={Elsevier}
}
@article{gao2019before,
  title={Before and after: Comparison of legacy and harmonized TCGA genomic data commons’ data},
  author={Gao, Galen F and Parker, Joel S and Reynolds, Sheila M and Silva, Tiago C and Wang, Liang-Bo and Zhou, Wanding and Akbani, Rehan and Bailey, Matthew and Balu, Saianand and Berman, Benjamin P and others},
  journal={Cell systems},
  volume={9},
  number={1},
  pages={24--34},
  year={2019},
  publisher={Elsevier}
}
@inproceedings{OOD1,
  title={Likelihood ratios for out-of-distribution detection},
  author={Ren, Jie and Liu, Peter J and Fertig, Emily and Snoek, Jasper and Poplin, Ryan and Depristo, Mark and Dillon, Joshua and Lakshminarayanan, Balaji},
  booktitle={Advances in Neural Information Processing Systems},
  pages={14680--14691},
  year={2019}
}
@article{OOD2,
  title={Out-of-distribution Detection in Classifiers via Generation},
  author={Vernekar, Sachin and Gaurav, Ashish and Abdelzad, Vahdat and Denouden, Taylor and Salay, Rick and Czarnecki, Krzysztof},
  journal={arXiv preprint arXiv:1910.04241},
  year={2019}
}
@article{GNNEXPLAINER,
  title={Gnn explainer: A tool for post-hoc explanation of graph neural networks},
  author={Ying, Rex and Bourgeois, Dylan and You, Jiaxuan and Zitnik, Marinka and Leskovec, Jure},
  journal={arXiv preprint arXiv:1903.03894},
  year={2019}
}
@inproceedings{MUSE,
  title={Faithful and customizable explanations of black box models},
  author={Lakkaraju, Himabindu and Kamar, Ece and Caruana, Rich and Leskovec, Jure},
  booktitle={Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={131--138},
  year={2019}
}
@misc{LIME,
  title={Local Interpretable Model-Agnostic Explanations (LIME): An Introduction},
  author={Ribeiro, MT and Singh, S and Guestrin, C},
  year={2019}
}
@article{rezaul2019onconetexplainer,
  title={OncoNetExplainer: Explainable Predictions of Cancer Types Based on Gene Expression Data},
  author={Rezaul Karim, Md and Cochez, Michael and Beyan, Oya and Decker, Stefan and Lange, Christoph},
  journal={arXiv preprint arXiv:1909.04169},
  year={2019}
}
@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}
@article{papernot2016transferability,
  title={Transferability in machine learning: from phenomena to black-box attacks using adversarial samples},
  author={Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian},
  journal={arXiv preprint arXiv:1605.07277},
  year={2016}
}
@inproceedings{dalvi2004adversarial,
  title={Adversarial classification},
  author={Dalvi, Nilesh and Domingos, Pedro and Sanghai, Sumit and Verma, Deepak},
  booktitle={Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={99--108},
  year={2004}
}
@inproceedings{biggio2013evasion,
  title={Evasion attacks against machine learning at test time},
  author={Biggio, Battista and Corona, Igino and Maiorca, Davide and Nelson, Blaine and {\v{S}}rndi{\'c}, Nedim and Laskov, Pavel and Giacinto, Giorgio and Roli, Fabio},
  booktitle={Joint European conference on machine learning and knowledge discovery in databases},
  pages={387--402},
  year={2013},
  organization={Springer}
}
@article{yuan2019adversarial,
  title={Adversarial examples: Attacks and defenses for deep learning},
  author={Yuan, Xiaoyong and He, Pan and Zhu, Qile and Li, Xiaolin},
  journal={IEEE transactions on neural networks and learning systems},
  volume={30},
  number={9},
  pages={2805--2824},
  year={2019},
  publisher={IEEE}
}
@article{OOD3,
  title={Learning confidence for out-of-distribution detection in neural networks},
  author={DeVries, Terrance and Taylor, Graham W},
  journal={arXiv preprint arXiv:1802.04865},
  year={2018}
}
@inproceedings{OOD4,
  title={Outlier Exposure with Confidence Control for Out-of-Distribution Detection},
  author={Papadopoulos, M. R. and Rajati, N. Shaikh and J., Wang},
  journal={arXiv preprint arXiv1906.03509},
  year={2019}
}
@article{OOD5,
  title={Deep anomaly detection with outlier exposure},
  author={D. Hendrycks, M. Mazeika and T. G. Dietterich},
  journal={arXiv preprint arXiv1812.04606},
  year={2019}
}
@article{BETA,
  title={Interpretable \& explorable approximations of black box models},
  author={Lakkaraju, Himabindu and Kamar, Ece and Caruana, Rich and Leskovec, Jure},
  journal={arXiv preprint arXiv:1707.01154},
  year={2017}
}
@inproceedings{SHAP,
  title={A unified approach to interpreting model predictions},
  author={Lundberg, Scott M and Lee, Su-In},
  booktitle={Advances in neural information processing systems},
  pages={4765--4774},
  year={2017}
}
@article{OOD6,
  title={Metric Learning for Novelty and Anomaly Detection},
  author={M. Masana and I. Ruiz, J. and Serrat, J. and van de Weijer and A. M. Lopez},
  journal={arXiv preprint arXiv1808.05492},
  year={2018}
}
@inproceedings{OOD7,
  title={Reducing Network Agnostophobia},
  author={A. R. Dhamija, M. Günther, and T. Boult},
  booktitle={Eds. Curran Associates, Inc.},
  pages={175–-9186},
  year={2018}
}
@article{OOD8,
  title={Out-of-distribution detection using an ensemble of self supervised leave-out classifiers},
  author={A. Vyas, N. Jammalamadaka and X. Zhu, D. Das and B. Kaul and T. L. Willke},
  journal={European Conference on Computer Vision},
  year={2018}
}
@article{OOD9,
  title={Enhancing the Robustness of Prior Network in Out-of-Distribution Detection},
  author={W. Chen, Y. Shen, X. Wang, and W. Wang},
  journal={arXiv preprint arXiv1811.07308},
  year={2018}
}
@article{almal2012implications,
  title={Implications of gene copy-number variation in health and diseases},
  author={Almal, Suhani H and Padh, Harish},
  journal={Journal of human genetics},
  volume={57},
  number={1},
  pages={6--13},
  year={2012},
  publisher={Nature Publishing Group}
}
@inproceedings{OOD10,
  title={Out-of-distribution detection using multiple semantic label representations},
  author={G. Shalev and Y. Adi and J. Keshet},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7386–-7396},
  year={2018}
}
@inproceedings{phan2016integration,
  title={Integration of multi-modal biomedical data to predict cancer grade and patient survival},
  author={Phan, John H and Hoffman, Ryan and Kothari, Sonal and Wu, Po-Yen and Wang, May D},
  booktitle={2016 IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI)},
  pages={577--580},
  year={2016},
  organization={IEEE}
}
@article{cheerla2019deep, 
  title={Deep learning with multimodal representation for pancancer prognosis prediction},
  author={Cheerla, Anika and Gevaert, Olivier},
  journal={Bioinformatics},
  volume={35},
  number={14},
  pages={i446--i454},
  year={2019},
  publisher={Oxford University Press}
}
@article{OOD11,
  title={Generative ensembles for robust anomaly detection},
  author={H. Choi and E. Jang},
  journal={arXiv preprint arXiv1810.01392},
  year={2018}
}
@article{OOD12,
  title={Detecting Out-Of-Distribution Samples Using Low-Order Deep Features Statistics},
  author={I. M. Quintanilha and R. de M. E. Filho and J. Lezama, M. Delbracio and L. O. Nunes},
  journal={arXiv preprint arXiv:1802.04865},
  year={2018}
}
@article{weng2018evaluating,
  title={Evaluating the robustness of neural networks: An extreme value theory approach},
  author={Weng, Tsui-Wei and Zhang, Huan and Chen, Pin-Yu and Yi, Jinfeng and Su, Dong and Gao, Yupeng and Hsieh, Cho-Jui and Daniel, Luca},
  journal={arXiv preprint arXiv:1801.10578},
  year={2018}
}
@article{arrieta2020explainable,
  title={Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI},
  author={Arrieta, Alejandro Barredo and D{\'\i}az-Rodr{\'\i}guez, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado, Alberto and Garc{\'\i}a, Salvador and Gil-L{\'o}pez, Sergio and Molina, Daniel and Benjamins, Richard and others},
  journal={Information Fusion},
  volume={58},
  pages={82--115},
  year={2020},
  publisher={Elsevier}
}
@article{lu2003cancer,
  title={Cancer classification using gene expression data},
  author={Lu, Ying and Han, Jiawei},
  journal={Information Systems},
  volume={28},
  number={4},
  pages={243--268},
  year={2003},
  publisher={Elsevier}
}
@inproceedings{OOD13,
  title={A simple unified framework for detecting out-of-distribution samples and adversarial attacks},
  author={K., Lee and K., Lee and H., Lee and J., Shin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={14680--14691},
  year={2019}
}
@article{OOD14,
  title={Anomaly Detection with Generative Adversarial Networks},
  author={L. Deecke, R. Vandermeulen, L. Ruff, S. Mandt, and M. Kloft},
  pages={7167–-7177},
  year={2018}
}
@article{OOD15,
  title={Novelty Detection with Generative Adversarial Networks},
  author={M. Kliger and S. Fleishman},
  journal={arXiv preprint arXiv:1802.10560},
  year={2018}
}
@inproceedings{OOD16,
  title={Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks},
  author={S. Liang, Y. Li, and R. Srikant},
  booktitle={ICLR},
  pages={14680--14691},
  year={2018}
}
@article{OOD17,
  title={Training Confidence-calibrated Classifiers for Detecting Out-of-Distribution Samples},
  author={K. Lee and H. Lee and K. Lee and J. Shin},
  journal={ICLR},
  year={2018}
}
@article{OOD18,
  title={A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks},
  author={D. Hendrycks and K. Gimpel},
  journal={ICLR},
  year={2017}
}




@inproceedings{OOD19,
  title={Towards Open Set Deep Networks},
  author={A. Bendale and T. E. Boult},
  booktitle={CVPR},
  pages={14680--14691},
  year={2016}
}
@misc{cerami2012cbio,
  title={The cBio cancer genomics portal: an open platform for exploring multidimensional cancer genomics data},
  author={Cerami, Ethan and Gao, Jianjiong and Dogrusoz, Ugur and Gross, Benjamin E and Sumer, Selcuk Onur and Aksoy, B{\"u}lent Arman and Jacobsen, Anders and Byrne, Caitlin J and Heuer, Michael L and Larsson, Erik and others},
  year={2012},
  publisher={AACR}
}
@article{kim2019design,
  title={Design characteristics of studies reporting the performance of artificial intelligence algorithms for diagnostic analysis of medical images: results from recently published papers},
  author={Kim, Dong Wook and Jang, Hye Young and Kim, Kyung Won and Shin, Youngbin and Park, Seong Ho},
  journal={Korean journal of radiology},
  volume={20},
  number={3},
  pages={405--410},
  year={2019}
}

@article{miller2001understanding,
  title={Understanding human disease mutations through the use of interspecific genetic variation},
  author={Miller, Mark P and Kumar, Sudhir},
  journal={Human molecular genetics},
  volume={10},
  number={21},
  pages={2319--2328},
  year={2001},
  publisher={Oxford University Press}
}

@article{srivastava2014dropout,
  title={Dropout: A simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex  et al.},
  journal={The Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}
@inproceedings{sutskever2013importance,
  title={On the importance of initialization and momentum in deep learning},
  author={Sutskever, Ilya and Martens, James and Dahl, George  et al.},
  booktitle={International conference on machine learning},
  pages={1139--1147},
  address={Atlanta, USA},
  year={2013},
  organization={International Machine Learning Society}
}
@article{maaten2008visualizing,
  title={Visualizing data using {t-SNE}},
  author={Maaten, Laurens van der and Hinton, Geoffrey},
  journal={Journal of machine learning research},
  volume={9},
  number={Nov},
  pages={2579--2605},
  year={2008}
}

@inproceedings{19,
  title={A Deep Learning Approach to Genomics Data for Population Scale Clustering and Ethnicity Prediction},
  author={Karim M. R., Zappa A., Sahay R. and Rebholz-Schuhmann D.},
  booktitle={In Proc. of the ESWC workshop on Semantic Web solutions for large-scale biomedical data analytics (SeWeBMeDA'2017)},
  year={2017},
  organization={ESWC'2017}
}
@article{mandal2018biomarker,
  tite={Biomarker Identification for Cancer Disease Using Biclustering Approach: An Empirical Study},
  author={Mandal, Koyel and Sarmah, Rosy and Bhattacharyya, Dhruba Kumar},
  journal={IEEE/ACM transactions on computational biology and bioinformatics},
  year={2018},
  publisher={IEEE}
}
@inproceedings{guo2017deep,
  title={Deep clustering with convolutional autoencoders},
  author={Guo, Xifeng and Liu, Xinwang and Zhu, En  et al.},
  booktitle={International Conference on Neural Information Processing},
  pages={373--382},
  address={Guangzhou, China},
  year={2017},
  organization={Springer}
}
@article{li2018learning,
  title={Learning mixtures of linear regressions with nearly optimal complexity},
  author={Li, Yuanzhi and Liang, Yingyu},
  journal={arXiv preprint arXiv:1802.07895},
  year={2018}
}
@inproceedings{zhu2018hidden,
  title={Hidden: Hiding data with deep networks},
  author={Zhu, Jiren and Kaplan, Russell and Johnson, Justin  et al.},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={657--672},
  address={Munich, Germany},
  year={2018},
  organization={Computer Vision Foundation}
}
@article{park2018multimodal,
  title={A multimodal anomaly detector for robot-assisted feeding using an lstm-based variational autoencoder},
  author={Park, Daehyung and Hoshi, Yuuna and Kemp, Charles C},
  journal={IEEE Robotics and Automation Letters},
  volume={3},
  number={3},
  pages={1544--1551},
  year={2018},
  publisher={IEEE}
}
@article{an2015variational,
  title={Variational autoencoder based anomaly detection using reconstruction probability},
  author={An, Jinwon and Cho, Sungzoon},
  journal={Special Lecture on IE},
  volume={2},
  number={1},
  year={2015}
}

@article{21,
  title={VariantSpark: population scale clustering of genotype information},
  author={O'Brien, Aidan R and Saunders, Neil FW and Guo, Yi  et al.},
  journal={BMC genomics},
  volume={16},
  number={1},
  pages={1052},
  year={2015},
  publisher={BioMed Central}
}
@article{wang2019mixed,
  title={A Mixed-Norm Laplacian Regularized Low-Rank Representation Method for Tumor Samples Clustering},
  author={Wang, Juan and Liu, Jin-Xing and Zheng, Chun-Hou  et al.},
  journal={IEEE/ACM Transactions on Computational Biology and Bioinformatics (TCBB)},
  volume={16},
  number={1},
  pages={172--182},
  year={2019},
  publisher={IEEE Computer Society Press}
}
@article{jaskowiak2018clustering,
  title={Clustering of RNA-Seq samples: Comparison study on cancer data},
  author={Jaskowiak, Pablo Andretta and Costa, Ivan G and Campello, Ricardo JGB},
  journal={Methods},
  volume={132},
  pages={42--49},
  year={2018},
  publisher={Elsevier}
}
@article{22,
  title={Avoiding overfitting in multilayer perceptrons with feeling-of-knowing using self-organizing maps},
  author={Murakoshi, Kazushi},
  journal={BioSystems},
  volume={80},
  number={1},
  pages={37--40},
  year={2005},
  publisher={Elsevier}
}

@article{24,
  title={A variational perspective on accelerated methods in optimization},
  author={Wibisono, Andre and Wilson, Ashia C and Jordan, Michael I},
  journal={Proceedings of the National Academy of Sciences},
  pages={201614734},
  year={2016},
  publisher={National Acad Sciences}
}
@article{zhao2007medical,
  title={Medical x-ray image enhancement based on kramer's PDE model},
  author={Zhao, Yan-Fei and Gao, Qing-Wei and Zhang, De-Xiang  et al.},
  journal={Journal of Electronic Science and Technology},
  volume={5},
  number={2},
  pages={187--190},
  year={2007}
}
@inproceedings{25,
  title={On the use of the adjusted rand index as a metric for evaluating supervised classification},
  author={Santos, Jorge M and Embrechts, Mark},
  booktitle={International Conference on Artificial Neural Networks},
  pages={175--184},
  address={Limassol, Cyprus},
  year={2009},
  organization={Springer}
}
@article{27,
  title={Analysis of protein-coding genetic variation in 60,706 humans},
  author={Lek, Monkol and Karczewski, Konrad and Minikel, Eric  et al.},
  journal={BioRxiv},
  pages={030338},
  year={2016},
  publisher={Cold Spring Harbor Labs Journals}
}
@article{rhee2017hybrid,
  title={Hybrid approach of relation network and localized graph convolutional filtering for breast cancer subtype classification},
  author={Rhee, Sungmin and Seo, Seokjun and Kim, Sun},
  journal={arXiv:1711.05859},
  year={2017}
}
@book{28,
  title={Data clustering: theory, algorithms, and applications},
  author={Gan, Guojun and Ma, Chaoqun and Wu, Jianhong},
  volume={20},
  year={2007},
  publisher={SIAM}
}
@article{bertucci2012basal,
  title={Basal breast cancer: a complex and deadly molecular subtype},
  author={Bertucci, F and Finetti, P and Birnbaum, D},
  journal={Current molecular medicine},
  volume={12},
  number={1},
  pages={96--110},
  year={2012},
  publisher={Bentham Science Publishers}
}
@article{30,
title = "{Y}-Chromosomal Diversity in {Europe} Is Clinal and Influenced Primarily by Geography, Rather than by Language",
journal = "The American Journal of Human Genetics",
volume = "67",
number = "6",
pages = "1526 - 1543",
year = "2000",
note = "",
issn = "0002-9297"
}

@article{31,
  title={Genetic variation, classification and race},
  author={Jorde, Lynn B and Wooding, Stephen P},
  journal={Nature genetics},
  volume={36},
  pages={S28--S33},
  year={2004},
  publisher={Nature Publishing Group}
}

@article{32,
  title={Dropout: a simple way to prevent neural networks from overfitting.},
  author={Srivastava, Nitish and Hinton, Geoffrey E and Krizhevsky, Alex  et al.},
  journal={Journal of machine learning research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014}
}

@article{34,
  title={Optimization methods for large-scale machine learning},
  author={Bottou, L{\'e}on and Curtis, Frank E and Nocedal, Jorge},
  journal={arXiv preprint arXiv:1606.04838},
  year={2016}
}

@article{35,
  title={Deep Learning with Deep Water},
  author={Dymczyk, Wen Phan Magnus Stensmo Mateusz and Kou, Arno Candel Qiang},
  year={2017}
}
@inproceedings{36,
  title={Modeling pixel means and covariances using factorized third-order Boltzmann machines},
  author={Ranzato, Marc'Aurelio and Hinton, Geoffrey E},
  booktitle={2010 IEEE computer society conference on computer vision and pattern recognition},
  pages={2551--2558},
  address={},
  year={2010},
  organization={IEEE}
}

@article{37,
  author    = {Matthew D. Zeiler},
  title     = {{ADADELTA:} An Adaptive Learning Rate Method},
  journal   = {CoRR},
  volume    = {abs/1212.5701},
  year      = {2012},
  url       = {http://arxiv.org/abs/1212.5701},
  timestamp = {Wed, 07 Jun 2017 14:43:02 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/abs-1212-5701},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}
@inproceedings{vincent2008extracting,
  title={Extracting and composing robust features with denoising autoencoders},
  author={Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre-Antoine},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={1096--1103},
  year={2008},
  organization={ACM}
}

@article{39,
  title={Human genomics: The end of the start for population sequencing},
  author={Birney, Ewan and Soranzo, Nicole},
  journal={Nature},
  volume={526},
  number={7571},
  pages={52--53},
  year={2015},
  publisher={Nature Research}
}
@inproceedings{xie2016unsupervised,
  title={Unsupervised deep embedding for clustering analysis},
  author={Xie, Junyuan and Girshick, Ross and Farhadi, Ali},
  booktitle={International conference on machine learning},
  pages={478--487},
  year={2016},
  address={New York City, NY, USA},
  organization={ICMLR}
}
@inproceedings{jaitly2011learning,
  title={Learning a better representation of speech soundwaves using restricted boltzmann machines},
  author={Jaitly, Navdeep and Hinton, Geoffrey},
  booktitle={2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5884--5887},
  year={2011},
  organization={IEEE}
}
























@inproceedings{LRP3,
  title={Understanding individual decisions of cnns via contrastive backpropagation},
  author={Gu, Jindong and Yang, Yinchong and Tresp, Volker},
  booktitle={Asian Conference on Computer Vision},
  pages={119--134},
  year={2018},
  organization={Springer}
}
@inproceedings{chattopadhay2018grad,
  title={Grad-{CAM}++: Generalized gradient-based visual explanations for deep convolutional networks},
  author={Chattopadhay, Aditya and Sarkar, Anirban},
  booktitle={Conf. on Applications of Computer Vision(WACV)},
  pages={839--847},
  year={2018},
  organization={IEEE}
}
@article{doshi2017towards,
  title={Towards a rigorous science of interpretable machine learning},
  author={Doshi-Velez, Finale and Kim, Been},
  journal={arXiv preprint arXiv:1702.08608},
  year={2017}
}
@article{simonyan2013deep,
  title={Deep inside convolutional networks: Visualising image classification models and saliency maps},
  author={Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1312.6034},
  year={2013}
}
@article{springenberg2014striving,
  title={Striving for simplicity: The all convolutional net},
  author={Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1412.6806},
  year={2014}
}
@article{bohle2019layer,
  title={Layer-wise relevance propagation for explaining deep neural network decisions in MRI-based Alzheimer’s disease classification},
  author={B{\"o}hle, Moritz and Eitel, Fabian and Weygandt, Martin and Ritter, Kerstin},
  journal={Frontiers in aging neuroscience},
  volume={11},
  pages={194},
  year={2019},
  publisher={Frontiers}
}
@article{tramer2017ensemble,
  title={Ensemble adversarial training: Attacks and defenses},
  author={Tram{\`e}r, Florian and Kurakin, Alexey and Papernot, Nicolas and Goodfellow, Ian and Boneh, Dan and McDaniel, Patrick},
  journal={arXiv preprint arXiv:1705.07204},
  year={2017}
}
@inproceedings{dong2018boosting,
  title={Boosting adversarial attacks with momentum},
  author={Dong, Yinpeng and Liao, Fangzhou and Pang, Tianyu and Su, Hang and Zhu, Jun and Hu, Xiaolin and Li, Jianguo},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={9185--9193},
  year={2018}
}
@inproceedings{rozsa2016adversarial,
  title={Adversarial diversity and hard positive generation},
  author={Rozsa, Andras and Rudd, Ethan M and Boult, Terrance E},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={25--32},
  year={2016}
}
@inproceedings{rifai2011higher,
  title={Higher order contractive auto-encoder},
  author={Rifai, Salah and Mesnil, Gr{\'e}goire and Vincent, Pascal and Muller, Xavier and Bengio, Yoshua and Dauphin, Yann and Glorot, Xavier},
  booktitle={Joint European conference on machine learning and knowledge discovery in databases},
  pages={645--660},
  year={2011},
  organization={Springer}
}

@online{RobustnessNotEnough,
  author = {Christian Kästner},
  title = {Why Robustness is not Enough for Safety and Security in Machine Learning},
  year = {2021},
  url = {https://towardsdatascience.com/why-robustness-is-not-enough-for-safety-and-security-in-machine-learning-1a35f6706601},
  urldate = {2021-02-01}
}

@online{GoogleBiasinMLPipeline,
  author = {Catherina Xu and Tulsee Doshi},
  title = {Fairness Indicators: Scalable Infrastructure for Fair ML Systems},
  year = {2019},
  url = {https://ai.googleblog.com/2019/12/fairness-indicators-scalable.html},
  urldate = {2020-02-25}
}
@online{GoogleBiasList,
  author = {Margaret Mitchell},
  title = {Fairness},
  year = 2019,
  url = {https://developers.google.com/machine-learning/crash-course/fairness/video-lecture},
  urldate = {2020-02-25}
}
@article{mehrabi2019survey,
  title={A survey on bias and fairness in machine learning},
  author={Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
  journal={arXiv preprint arXiv:1908.09635},
  year={2019}
}
@article{clauset2009power,
  title={Power-law distributions in empirical data},
  author={Clauset, Aaron and Shalizi, Cosma Rohilla and Newman, Mark EJ},
  journal={SIAM review},
  volume={51},
  number={4},
  pages={661--703},
  year={2009},
  publisher={SIAM}
}
@article{obermeyer2019dissecting,
  title={Dissecting racial bias in an algorithm used to manage the health of populations},
  author={Obermeyer, Ziad and Powers, Brian and Vogeli, Christine and Mullainathan, Sendhil},
  journal={Science},
  volume={366},
  number={6464},
  pages={447--453},
  year={2019},
  publisher={American Association for the Advancement of Science}
}
@inproceedings{ribeiro2016should,
  title={" Why should i trust you?" Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1135--1144},
  year={2016}
}
@article{stiglic2020interpretability,
  title={Interpretability of machine learning based prediction models in healthcare},
  author={Stiglic, Gregor and Kocbek, Primoz and Fijacko, Nino and Zitnik, Marinka and Verbert, Katrien and Cilar, Leona},
  journal={arXiv preprint arXiv:2002.08596},
  year={2020}
}
@article{post2015patient,
  title={Patient understanding of body mass index (BMI) in primary care practices: a two-state practice-based research (PBR) collaboration},
  author={Post, Robert E and Mendiratta, Megha and Haggerty, Treah and Bozek, Alexia and Doyle, Gregory and Xiang, Jun and King, Dana E},
  journal={The Journal of the American Board of Family Medicine},
  volume={28},
  number={4},
  pages={475--480},
  year={2015},
  publisher={Am Board Family Med}
}
@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={618--626},
  year={2017}
}
@inproceedings{114,
	title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
	author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
	booktitle={Proceedings of the IEEE International Conference on Computer Vision},
	pages={618--626},
	year={2017}
}
@inproceedings{moosavi2016deepfool,
  title={Deepfool: a simple and accurate method to fool deep neural networks},
  author={Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Frossard, Pascal},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2574--2582},
  year={2016}
}
@article{naulaerts2017precision,
  title={Precision and recall oncology: combining multiple gene mutations for improved identification of drug-sensitive tumours},
  author={Naulaerts, Stefan and Dang, Cuong C and Ballester, Pedro J},
  journal={Oncotarget},
  volume={8},
  number={57},
  pages={97025},
  year={2017},
  publisher={Impact Journals, LLC}
}
@article{zeiler2012adadelta,
  title={ADADELTA: an adaptive learning rate method},
  author={Zeiler, Matthew D},
  journal={arXiv preprint arXiv:1212.5701},
  year={2012}
}

%41
@Article{41Friedman,
  author =       "Friedman, J. M. and et al",
  title =        "Oligonucleotide microarray analysis of genomic imbalance in children with mental retardation",
  year =         "2006",
  journal =      "The American Journal of Human Genetics",
  volume =       "79(3)",
  pages =        "500-513",
}
Friedman, J. M., et al. "Oligonucleotide microarray analysis of genomic imbalance in children with mental retardation." The American Journal of Human Genetics 79.3 (2006): 500-513.



%42
@Article{42Marshall,
  author =       "Marshall, Christian",
  title =        "Structural variation of chromosomes in autism spectrum disorder",
  year =         "2008",
  journal =      "The American Journal of Human Genetics",
  volume =       "82(2)",
  pages =        "477-488",
}
Marshall, Christian R., et al. "Structural variation of chromosomes in autism spectrum disorder." The American Journal of Human Genetics 82.2 (2008): 477-488.
%45

%47
@Article{47Nørskov,
  author =       "Norskov, M. S. and et al",
  title =        "Copy number variation in glutathione-S-transferase {T1} and {M1} predicts incidence and 5-year survival from prostate and bladder cancer, and incidence of corpus uteri cancer in the general population",
  year =         "2011",
  journal =      "The pharmacogenomics journal",
  volume =       "11(4)",
  pages =        "292-299",
}
not good
Nørskov, M. S., et al. "Copy number variation in glutathione-S-transferase T1 and M1 predicts incidence and 5-year survival from prostate and bladder cancer, and incidence of corpus uteri cancer in the general population." The pharmacogenomics journal 11.4 (2011): 292-299.

%49
@Article{49MacDonald,
  author =       "MacDonald, Jeffrey R. and et al",
  title =        "The Database of Genomic Variants: a curated collection of structural variation in the human genome",
  year =         "2013",
  journal =      "Nucleic acids research",
  volume =       "42(D1)",
  pages =        "D986-D992",
}
MacDonald, Jeffrey R., et al. "The Database of Genomic Variants: a curated collection of structural variation in the human genome." Nucleic acids research 42.D1 (2013): D986-D992.



%50
@Article{50Buchanan,
  author =       "Buchanan, Janet A. and Stephen W. Scherer",
  title =        "Contemplating effects of genomic structural variatio",
  year =         "2008",
  journal =      "Genetics in Medicine",
  volume =       "10(9)",
  pages =        "639-647",
}
not good
Buchanan, Janet A., and Stephen W. Scherer. "Contemplating effects of genomic structural variation." Genetics in Medicine 10.9 (2008): 639-647.



%51
@Article{51Craddock,
  author =       "Craddock, Nick and et al",
  title =        "Genome-wide association study of {CNVs} in 16,000 cases of eight common diseases and 3,000 shared controls",
  year =         "2010",
  journal =      "Nature",
  volume =       "464(7289)",
  pages =        "713-720",
}
Craddock, Nick, et al. "Genome-wide association study of CNVs in 16,000 cases of eight common diseases and 3,000 shared controls." Nature 464.7289 (2010): 713-720.



%52
@Article{52Cantsilieris,
  author =       "Cantsilieris, Stuart and Stefan J. White",
  title =        "Correlating multiallelic copy number polymorphisms with disease susceptibility",
  year =         "2013",
  journal =      "Human mutation",
  volume =       "34(1)",
  pages =        "1-13",
}
not good
Cantsilieris, Stuart, and Stefan J. White. "Correlating multiallelic copy number polymorphisms with disease susceptibility." Human mutation 34.1 (2013): 1-13.


%53
@Article{53Bowcock,
  author =       "Bowcock, Anne M",
  title =        "Invited review DNA copy number changes as diagnostic tools for lung cancer",
  year =         "2013",
  journal =      "thoraxjnl",
  volume =       "",
  pages =        "2013",
}
very bad
Bowcock, Anne M. "Invited review DNA copy number changes as diagnostic tools for lung cancer." Thorax (2013): thoraxjnl-2013.


%54
@Article{54Wang,
  author =       "Wang, Kai and et al",
  title =        "{PennCNV}: an integrated hidden Markov model designed for high-resolution copy number variation detection in whole-genome {SNP} genotyping data",
  year =         "2007",
  journal =      "Genome research",
  volume =       "17(11)",
  pages =        "1665-1674",
}
Wang, Kai, et al. "PennCNV: an integrated hidden Markov model designed for high-resolution copy number variation detection in whole-genome SNP genotyping data." Genome research 17.11 (2007): 1665-1674.



%55
@Article{55Pinto,
  author =       "Pinto, Dalila and et al",
  title =        "Copy-number variation in control population cohorts",
  year =         "2007",
  journal =      "Human molecular genetics",
  volume =       "16(R2)",
  pages =        "R168-R173",
}
Pinto, Dalila, et al. "Copy-number variation in control population cohorts." Human molecular genetics 16.R2 (2007): R168-R173.



%56
@Article{56Kim,
  author =       "Kim, Ji-Hong and et al",
  title =        "{CNVRuler}: a copy number variation-based case–control association analysis tool",
  year =         "2012",
  journal =      "Bioinformatics",
  volume =       "28(13)",
  pages =        "1790-1792",
}
very bad
Kim, Ji-Hong, et al. "CNVRuler: a copy number variation-based case–control association analysis tool." Bioinformatics 28.13 (2012): 1790-1792.


%57
@Article{57Yan,
  author =       "Yan, P. Yu and et al",
  title =        "Genomic copy number variations in the genomes of leukocytes predict prostate cancer clinical outcomes",
  year =         "2015",
  journal =      "PloS one",
  volume =       "10(8)",
  pages =        "e0135982",
}
very bad
Yan, P. Yu, et al. "Genomic copy number variations in the genomes of leukocytes predict prostate cancer clinical outcomes." PloS one 10.8 (2015): e0135982.
%59
@Article{59Hinton,
  author =       "Hinton, Geoffrey E. and Simon Osindero and Yee-Whye Teh",
  title =        "A fast learning algorithm for deep belief nets",
  year =         "2006",
  journal =      "Neural computation",
  volume =       "18(7)",
  pages =        "1527-1554",
}
Hinton, Geoffrey E., Simon Osindero, and Yee-Whye Teh. "A fast learning algorithm for deep belief nets." Neural computation 18.7 (2006): 1527-1554.


%60
@Article{60Fischer,
  author =       "Fischer, Asja, and Christian Igel",
  title =        "Training restricted Boltzmann machines: An introduction",
  year =         "2014",
  journal =      "Pattern Recognition",
  volume =       "47(1)",
  pages =        "25-39",
}
Fischer, Asja, and Christian Igel. "Training restricted Boltzmann machines: An introduction." Pattern Recognition 47.1 (2014): 25-39.


%61
@Article{61Hinton,
  author =       "Hinton, Geoffrey",
  title =        "A practical guide to training Restricted Boltzmann Machines ({RBM})",
  year =         "2010",
  journal =      "Momentum",
  volume =       "9(1)",
  pages =        "926",
}
Hinton, Geoffrey. "A practical guide to training restricted Boltzmann machines." Momentum 9.1 (2010): 926.


%62
@Article{62Hopfield,
  author =       "Hopfield, John J.",
  title =        "Neural networks and physical systems with emergent collective computational abilities.",
  year =         "1982",
  journal =      "Proceedings of the national academy of sciences",
  volume =       "79(8)",
  pages =        "2554-2558",
}
Hopfield, John J. "Neural networks and physical systems with emergent collective computational abilities." Proceedings of the national academy of sciences 79.8 (1982): 2554-2558.


%63
@Article{63Hinton,
  author =       "Hinton, Geoffrey E.",
  title =        "Training products of experts by minimizing contrastive divergence",
  year =         "2002",
  journal =      "Neural computation",
  volume =       "14(8)",
  pages =        "1771-1800",
}
Hinton, Geoffrey E. "Training products of experts by minimizing contrastive divergence." Neural computation 14.8 (2002): 1771-1800.


%64
@Article{64Charchar,
  author =       "Charchar, Fadi J. and et al",
  title =        "Whole Genome Survey of Copy Number Variation in the Spontaneously Hypertensive Rat",
  year =         "2010",
  journal =      "Hypertension",
  volume =       "55(5)",
  pages =        "1231-1238",
}
very bad
Charchar, Fadi J., et al. "Whole Genome Survey of Copy Number Variation in the Spontaneously Hypertensive Rat." Hypertension 55.5 (2010): 1231-1238.


%65
@Article{65Hinton,
  author =       "Hinton, Geoffrey E.",
  title =        "Deep Belief Networks, Scholarpedia, 4 (5): 5947",
  year =         "2009",
  journal =      "Available electronically at scholarpedia http://www. scholarpedia. org/article/Deep\_belief\_networks Hoppensteadt",
  volume =       "Hoppensteadt, FC",
  pages =        "129-35",
}
bad
Hinton, Geoffrey E. "Deep belief networks, Scholarpedia, 4 (5): 5947." Available electronically at http://www. scholarpedia. org/article/Deep_belief_networks Hoppensteadt, FC (2009): 129-35.
http://www. scholarpedia. org/article/Deep_belief_networks Hoppensteadt

%68
@Article{68Hinton,
  author =       "Hinton, Geoffrey E. and et al",
  title =        "Improving neural networks by preventing co-adaptation of feature detectors",
  year =         "2012",
  journal =      "arXiv preprint arXiv",
  volume =       "1207(0580)",
  pages =        "",
}
Hinton, Geoffrey E., et al. "Improving neural networks by preventing co-adaptation of feature detectors." arXiv preprint arXiv:1207.0580 (2012).

%69
@Article{69Bengio,
  author =       "Bengio, Yoshua",
  title =        "Learning deep architectures for AI.",
  year =         "2009",
  journal =      "Foundations and trends in Machine Learning 2.1",
  volume =       "",
  pages =        "1-127",
}
Bengio, Yoshua. "Learning deep architectures for AI." Foundations and trends® in Machine Learning 2.1 (2009): 1-127.

%70
@Article{70Rezaul,
  author =       "Md. Rezaul Karim",
  title =        "Predictive Analytics with TensorFlow",
  year =         "2017",
  journal =      "Packt Publishing Ltd"
}

Md. Rezaul Karim, Predictive Analytics with TensorFlow, Packt Publishing Ltd., 2017

%72
@Article{72Breiman,
  author =       "Breiman, Leo",
  title =        "Random forests",
  year =         "2001",
  journal =      "Machine learning",
  volume =       "45(1)",
  pages =        "5-32",
}
Breiman, Leo. "Random forests." Machine learning 45.1 (2001): 5-32.

%73
@Article{73Breiman,
  author =       "Breiman, Leo",
  title =        "Bagging predictors",
  year =         "1996",
  journal =      "Machine learning",
  volume =       "24(2)",
  pages =        "123-140",
}
Breiman, Leo. "Bagging predictors." Machine learning 24.2 (1996): 123-140.

%74
@Article{74Dehzangi,
  author =       "Dehzangi, Abdollah, Somnuk Phon-Amnuaisuk, and Omid Dehzangi",
  title =        "Using Random Forest for Protein Fold Prediction Problem: An Empirical Study",
  year =         "2010",
  journal =      "J. Inf. Sci. Eng",
  volume =       "26(6)",
  pages =        "1941-1956",
}
Dehzangi, Abdollah, Somnuk Phon-Amnuaisuk, and Omid Dehzangi. "Using Random Forest for Protein Fold Prediction Problem: An Empirical Study." J. Inf. Sci. Eng. 26.6 (2010): 1941-1956.


%75
@Article{75Schapire,
  author =       "Schapire, Robert E",
  title =        "The strength of weak learnability",
  year =         "1990",
  journal =      "Machine learning",
  volume =       "5(2)",
  pages =        "197-227",
}
Schapire, Robert E. "The strength of weak learnability." Machine learning 5.2 (1990): 197-227.

%76
@Article{76Livingston,
  author =       "Livingston, Frederick",
  title =        "Implementation of Breiman random forest machine learning algorithm",
  year =         "2005",
  journal =      "Machine Learning Journal Paper",
  volume =       "ECE591Q",
  pages =        "",
}
Livingston, Frederick. "Implementation of Breiman’s random forest machine learning algorithm." ECE591Q Machine Learning Journal Paper (2005).

%77
@Article{77Breiman,
  author =       "Breiman, Leo and et al",
  title =        "Classification and regression trees",
  year =         "1984",
  journal =      "CRC press",
  volume =       "",
  pages =        "",
}
Breiman, Leo, et al. Classification and regression trees. CRC press, 1984.

%78
@Article{78Mingers,
  author =       "Mingers, John",
  title =        "An empirical comparison of selection measures for decision-tree induction",
  year =         "1989",
  journal =      "Machine learning",
  volume =       "3(4)",
  pages =        "319-342",
}
Mingers, John. "An empirical comparison of selection measures for decision-tree induction." Machine learning 3.4 (1989): 319-342.

%79
@Article{79Chan,
  author =       "Chan, Jonathan Cheung-Wai, and Desiré Paelinckx",
  title =        "Evaluation of Random Forest and Adaboost tree-based ensemble classification and spectral band selection for ecotope mapping using airborne hyperspectral imagery",
  year =         "2008",
  journal =      "Remote Sensing of Environment",
  volume =       "112(6)",
  pages =        "2999-3011",
}

Chan, Jonathan Cheung-Wai, and Desiré Paelinckx. "Evaluation of Random Forest and Adaboost tree-based ensemble classification and spectral band selection for ecotope mapping using airborne hyperspectral imagery." Remote Sensing of Environment 112.6 (2008): 2999-3011.

%80
@Article{80Pal,
  author =       "Pal, Mahesh, and Paul M. Mather",
  title =        "An assessment of the effectiveness of decision tree methods for land cover classification",
  year =         "2003",
  journal =      "Remote sensing of environment",
  volume =       "86(4)",
  pages =        "554-565",
}
Pal, Mahesh, and Paul M. Mather. "An assessment of the effectiveness of decision tree methods for land cover classification." Remote sensing of environment 86.4 (2003): 554-565.

%81
@Article{81Menze,
  author =       "Menze, Bjoern H. and et al",
  title =        "A comparison of random forest and its Gini importance with standard chemometric methods for the feature selection and classification of spectral data",
  year =         "2009",
  journal =      "BMC bioinformatics",
  volume =       "10(1)",
  pages =        "213",
}
Menze, Bjoern H., et al. "A comparison of random forest and its Gini importance with standard chemometric methods for the feature selection and classification of spectral data." BMC bioinformatics 10.1 (2009): 213.


@article{wang2009rna,
  title={RNA-Seq: a revolutionary tool for transcriptomics},
  author={Wang, Zhong and Gerstein, Mark and Snyder, Michael},
  journal={Nature reviews genetics},
  volume={10},
  number={1},
  pages={57},
  year={2009},
  publisher={Nature Publishing Group}
}

@article{bartel2009micrornas,
  title={MicroRNAs: target recognition and regulatory functions},
  author={Bartel, David P},
  journal={cell},
  volume={136},
  number={2},
  pages={215--233},
  year={2009},
  publisher={Elsevier}
}


@article{dna,
  title={Principles and challenges of genome-wide DNA methylation analysis},
  author={Laird, Peter W},
  journal={Nature Reviews Genetics},
  volume={11},
  number={3},
  pages={191},
  year={2010},
  publisher={Nature Publishing Group}
}
@article{dna2,
  title={A rapid method for determining sequences in DNA by primed synthesis with DNA polymerase},
  author={Sanger, Fred and Coulson, Alan R},
  journal={Journal of molecular biology},
  volume={94},
  number={3},
  pages={441--448},
  year={1975},
  publisher={Elsevier}
}
%84
@Article{84Lee,
  author =       "Lee, Taehoon, and Sungroh Yoon",
  title =        "Boosted categorical Restricted Boltzmann Machine for computational prediction of splice junctions",
  year =         "2015",
  journal =      "International Conference on Machine Learning",
  volume =       "",
  pages =        "",
}
Lee, Taehoon, and Sungroh Yoon. "Boosted categorical restricted Boltzmann machine for computational prediction of splice junctions." International Conference on Machine Learning. 2015.

%85
@Article{85Chen,
  author =       "Chen, Yifei and et al",
  title =        "Gene expression inference with deep learning",
  year =         "2016",
  journal =      "Bioinformatics",
  volume =       "32(12)",
  pages =        "1832-1839",
}
Chen, Yifei, et al. "Gene expression inference with deep learning." Bioinformatics 32.12 (2016): 1832-1839.

%86
@Article{86Leung,
  author =       "Leung, Michael KK and et al",
  title =        "Machine learning in genomic medicine: a review of computational problems and data sets",
  year =         "2016",
  journal =      "Proceedings of the IEEE",
  volume =       "104(1)",
  pages =        "176-197",
}
Leung, Michael KK, et al. "Machine learning in genomic medicine: a review of computational problems and data sets." Proceedings of the IEEE 104.1 (2016): 176-197.


%87
@Article{87Yim,
  author =       "Yim, Seon-Hee and et al",
  title =        "Clinical implications of copy number variations in autoimmune disorders",
  year =         "2015",
  journal =      "The Korean journal of internal medicine",
  volume =       "30(3)",
  pages =        "294",
}
Yim, Seon-Hee, et al. "Clinical implications of copy number variations in autoimmune disorders." The Korean journal of internal medicine 30.3 (2015): 294.


%88
@Article{88Lowe,
  author =       "Lowe, Craig B., et al",
  title =        "Detecting differential copy number variation between groups of samples",
  year =         "2017",
  journal =      "Genome research",
  volume =       "",
  pages =        "",
}
Lowe, Craig B., et al. "Detecting differential copy number variation between groups of samples." Genome research (2017).

%89
@Article{89Xie,
  author =       "Xie, Chao, and Martti T. Tammi",
  title =        "{CNV}-seq, a new method to detect copy number variation using high-throughput sequencing",
  year =         "2009",
  journal =      "BMC bioinformatics",
  volume =       "10(1)",
  pages =        "80",
}
Xie, Chao, and Martti T. Tammi. "CNV-seq, a new method to detect copy number variation using high-throughput sequencing." BMC bioinformatics 10.1 (2009): 80.

%90
@Article{90Rodriguez,
  author =       "Rodriguez-Galiano, Victor Francisco and et al",
  title =        "An assessment of the effectiveness of a random forest classifier for land-cover classification",
  year =         "2012",
  journal =      "{ISPRS} Journal of Photogrammetry and Remote Sensing",
  volume =       "67",
  pages =        "93-104",
}
Rodriguez-Galiano, Victor Francisco, et al. "An assessment of the effectiveness of a random forest classifier for land-cover classification." ISPRS Journal of Photogrammetry and Remote Sensing 67 (2012): 93-104.
%93
@Article{93Bahadure,
  author =       "Bahadure, Nilesh Bhaskarrao and et al",
  title =        "Image analysis for MRI based brain tumor detection and feature extraction using biologically inspired BWT and SVM",
  year =         "2017",
  journal =      "International journal of biomedical imaging",
  volume =       "",
  pages =        "",
}
Bahadure, Nilesh Bhaskarrao, Arun Kumar Ray, and Har Pal Thethi. "Image analysis for MRI based brain tumor detection and feature extraction using biologically inspired BWT and SVM." International journal of biomedical imaging 2017 (2017).

%94
@Article{94Padmanabhan,
  author =       "Padmanabhan, Sharanya, and Raji Sundararajan",
  title =        "Enhanced accuracy of breast cancer detection in digital mammograms using wavelet analysis",
  year =         "2012",
  journal =      "Machine Vision and Image Processing ({MVIP}), 2012 International Conference on",
  volume =       "{IEEE}",
  pages =        "",
}
Padmanabhan, Sharanya, and Raji Sundararajan. "Enhanced accuracy of breast cancer detection in digital mammograms using wavelet analysis." Machine Vision and Image Processing (MVIP), 2012 International Conference on. IEEE, 2012.


%96
@article{96Karim,
  title={A Deep Learning Approach to Genomics Data for Population Scale Clustering and Ethnicity Prediction},
  author={Karim, Md Rezaul and Zappa, Achille and Sahay, Ratnesh and Rebholz-Schuhmann, Dietrich},
  booktitle={Proceedings of 1st international {ESWC}'2017 workshop Semantic Web solutions for large-scale biomedical data analytics ({SeWeBMeDA}'17)},
  pages={1--15},
  publisher={ESWC},
  year={2017}
}
%
@Article{11111111111,
  author =       "and et al",
  title =        "",
  year =         "20",
  journal =      "",
  volume =       "()",
  pages =        "",
}

% bibtext

@article{Schweidtmann2020_GNNs,
abstract = {Prediction of combustion-related properties of (oxygenated) hydrocarbons is an important and challenging task for which quantitative structure-property relationship (QSPR) models are frequently employed. Recently, a machine learning method, graph neural networks (GNNs), has shown promising results for the prediction of structure-property relationships. GNNs utilize a graph representation of molecules, where atoms correspond to nodes and bonds to edges containing information about the molecular structure. More specifically, GNNs learn physico-chemical properties as a function of the molecular graph in a supervised learning setup using a backpropagation algorithm. This end-to-end learning approach eliminates the need for selection of molecular descriptors or structural groups, as it learns optimal fingerprints through graph convolutions and maps the fingerprints to the physico-chemical properties by deep learning. We develop GNN models for predicting three fuel ignition quality indicators, i.e., the derived cetane number (DCN), the research octane number (RON), and the motor octane number (MON), of oxygenated and non-oxygenated hydrocarbons. In light of limited experimental data in the order of hundreds, we propose a combination of multi-task learning, transfer learning, and ensemble learning. The results show competitive performance of the proposed GNN approach compared to state-of-the-art QSPR models making it a promising field for future research. The prediction tool is available via a web front-end at www.avt.rwth-aachen.de/gnn.},
author = {Schweidtmann, Artur M. and Rittig, Jan G. and K{\"{o}}nig, Andrea and Grohe, Martin and Mitsos, Alexander and Dahmen, Manuel},
doi = {10.1021/acs.energyfuels.0c01533},
issn = {0887-0624},
journal = {Energy {\&} Fuels},
mendeley-groups = {DFG{\_}GNNs},
number = {9},
pages = {11395--11407},
title = {{Graph Neural Networks for Prediction of Fuel Ignition Quality}},
volume = {34},
year = {2020}
}

@article{Polykovskiy2020,
archivePrefix = {arXiv},
arxivId = {1811.12823},
author = {Polykovskiy, Daniil and Zhebrak, Alexander and Sanchez-Lengeling, Benjamin and Golovanov, Sergey and Tatanov, Oktai and Belyaev, Stanislav and Kurbanov, Rauf and Artamonov, Aleksey and Aladinskiy, Vladimir and Veselov, Mark and Kadurin, Artur and Nikolenko, Sergey I and Aspuru-Guzik, Al{\'{a}}n and Zhavoronkov, Alex},
eprint = {1811.12823},
file = {:U$\backslash$:/Literature/Paper/Polykovskiy{\_}2020-Molecular Sets (MOSES){\_}A Benchmarking Platform for Molecular Generation Models.pdf:pdf},
journal = {arXiv:1811.12823},
mendeley-groups = {Datasets},
title = {{Molecular Sets (MOSES): A Benchmarking Platform for Molecular Generation Models}},
url = {http://arxiv.org/abs/1811.12823},
year = {2018}
}
@article{abu2020domain,
  title={Domain-specific Knowledge Graphs: A survey},
  author={Abu-Salih, Bilal},
  journal={arXiv preprint arXiv:2011.00235},
  year={2020}
}
@article{cao2019unsupervised,
  title={Unsupervised Construction of Knowledge Graphs From Text and Code},
  author={Cao, Kun and Fairbanks, James},
  journal={arXiv preprint arXiv:1908.09354},
  year={2019}
}
@article{venkatasubramanian2019promise,
  title={The promise of artificial intelligence in chemical engineering: Is it here, finally?},
  author={Venkatasubramanian, Venkat},
  journal={AIChE Journal},
  volume={65},
  number={2},
  pages={466--478},
  year={2019},
  publisher={Wiley Online Library}
}
@article{hogan2020knowledge,
  title={Knowledge graphs},
  author={Hogan, Aidan and Blomqvist, Eva and Cochez, Michael and d'Amato, Claudia and de Melo, Gerard and Gutierrez, Claudio and Gayo, Jos{\'e} Emilio Labra and Kirrane, Sabrina and Neumaier, Sebastian and Polleres, Axel and others},
  journal={arXiv preprint arXiv:2003.02320},
  year={2020}
}
@article{zhu2019deep,
  title={A Deep Learning Approach on Industrial Pyrolysis Reactor Monitoring},
  author={Zhu, Wenbo and Zhan, Yibin and Romagnoli, Jose},
  journal={Chemical Engineering Transactions},
  volume={74},
  pages={691--696},
  year={2019}
}
@article{jha2018elemnet,
  title={Elemnet: Deep learning the chemistry of materials from only elemental composition},
  author={Jha, Dipendra and Ward, Logan and Paul, Arindam and Liao, Wei-keng and Choudhary, Alok and Wolverton, Chris and Agrawal, Ankit},
  journal={Scientific reports},
  volume={8},
  number={1},
  pages={1--13},
  year={2018},
  publisher={Nature Publishing Group}
}
@article{yun2020deep,
  title={Deep Neural Network for Automatic Image Recognition of Engineering Diagrams},
  author={Yun, Dong-Yeol and Seo, Seung-Kwon and Zahid, Umer and Lee, Chul-Jin},
  journal={Applied Sciences},
  volume={10},
  number={11},
  pages={4005},
  year={2020},
  publisher={Multidisciplinary Digital Publishing Institute}
}
@article{lee2020biobert,
  title={BioBERT: a pre-trained biomedical language representation model for biomedical text mining},
  author={Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
  journal={Bioinformatics},
  volume={36},
  number={4},
  pages={1234--1240},
  year={2020},
  publisher={Oxford University Press}
}
@article{menon2019database,
  title={From database to knowledge graph—using data in chemistry},
  author={Menon, Angiras and Krdzavac, Nenad B and Kraft, Markus},
  journal={Current Opinion in Chemical Engineering},
  volume={26},
  pages={33--37},
  year={2019},
  publisher={Elsevier}
}
@article{farazi2020knowledge,
  title={Knowledge Graph Approach to Combustion Chemistry and Interoperability},
  author={Farazi, Feroz and Salamanca, Maurin and Mosbach, Sebastian and Eibeck, Andreas and Aditya, Leonardus Kevin and Chadzynski, Arkadiusz and Pan, Kang and Zhou, Xiaochi and Zhang, Shaocong and others},
  journal={ACS omega},
  volume={5},
  number={29},
  pages={18342--18348},
  year={2020},
  publisher={ACS Publications}
}
@inproceedings{zhang2018link,
  title={Link prediction based on graph neural networks},
  author={Zhang, Muhan and Chen, Yixin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5165--5175},
  year={2018}
}
@article{anantharangachar2013ontology,
  title={Ontology guided information extraction from unstructured text},
  author={Anantharangachar, Raghu and Ramani, Srinivasan and Rajagopalan, S},
  journal={arXiv preprint arXiv:1302.1335},
  year={2013}
}
@article{kanwal2019pubmedinfo,
  title={PubMedInfo Crawler: An innovative extraction process that leads towards biological information mining},
  author={Kanwal, Attiya and Fazal, Sahar and Bhatti, Aamir Iqbal and Ullah, Mukhar and Khalid, Muhammad Arslan},
  journal={Meta Gene},
  volume={20},
  pages={100550},
  year={2019},
  publisher={Elsevier}
}
@article{sun2020biomedical,
  title={Biomedical named entity recognition using BERT in the machine reading comprehension framework},
  author={Sun, Cong and Yang, Zhihao and Wang, Lei and Zhang, Yin and Lin, Hongfei and Wang, Jian},
  journal={arXiv preprint arXiv:2009.01560},
  year={2020}
}
@article{dai2020drug,
  title={Drug--drug interaction prediction with Wasserstein Adversarial Autoencoder-based knowledge graph embeddings},
  author={Dai, Yuanfei and Guo, Chenhao and Guo, Wenzhong and Eickhoff, Carsten},
  journal={Briefings in Bioinformatics},
  year={2020}
}
@article{alamaffinity,
  title={Affinity Dependent Negative Sampling for Knowledge Graph Embeddings},
  author={Alam, Mirza Mohtashim and Jabeen, Hajira and Ali, Mehdi and Mohiuddin, Karishma and Lehmann, Jens},
  journal={ESWC Workshop on Deep Learning for Knowledge Graphs~(DL4KG 2020)},
  year={2020}
}
@misc{cascadetabnet2020,
    title={CascadeTabNet: An approach for end to end table detection and structure recognition from image-based documents},
    author={Devashish Prasad and Ayan Gadpal and Kshitij Kapadni and Manish Visave and Kavita Sultanpure},
    year={2020},
    eprint={2004.12629},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
@inproceedings{ristoski2016rdf2vec,
  title={Rdf2vec: {RDF} graph embeddings for data mining},
  author={Ristoski, Petar and Paulheim, Heiko},
  booktitle={International Semantic Web Conference},
  pages={498--514},
  year={2016},
  organization={Springer}
}
@article{zhang2020semi,
  title={Semi-Supervised Bidirectional-{LSTM} and Conditional Random Fields Model for Named-Entity Recognition Using Embeddings from Language Models Representations},
  author={Zhang, Min and Geng, Guohua and Chen, Jing},
  journal={Entropy},
  volume={22},
  number={2},
  pages={252},
  year={2020},
  publisher={Multidisciplinary Digital Publishing Institute}
}
@article{dogan2019fine,
  title={Fine-grained named entity recognition using {ELMo} and wikidata},
  author={Dogan, Cihan and Dutra, Aimore and Gara, Adam and Gemma, Alfredo and Shi, Lei and Sigamani, Michael and Walters, Ella},
  journal={arXiv preprint arXiv:1904.10503},
  year={2019}
}
@inproceedings{Beltagy2019SciBERT,
  title={SciBERT: Pretrained Language Model for Scientific Text},
  author={Iz Beltagy and Kyle Lo and Arman Cohan},
  year={2019},
  booktitle={EMNLP},
  Eprint={arXiv:1903.10676}
}
@article{chithrananda2020chemberta,
  title={ChemBERTa: Large-Scale Self-Supervised Pretraining for Molecular Property Prediction},
  author={Chithrananda, Seyone and Grand, Gabe and Ramsundar, Bharath},
  journal={arXiv preprint arXiv:2010.09885},
  year={2020}
}
@article{debattista2016luzzu,
  title={Luzzu—a methodology and framework for linked data quality assessment},
  author={Debattista, Jeremy and Auer, S{\"o}ren and Lange, Christoph},
  journal={Journal of Data and Information Quality (JDIQ)},
  volume={8},
  number={1},
  pages={1--32},
  year={2016},
  publisher={ACM New York, NY, USA}
}
@inproceedings{Morris2019,
author = {Morris, C and Ritzert, M and Fey, M and Hamilton, W and Lenssen, J E and Rattan, G and Grohe, M},
LONGbooktitle = {Proceedings of the 33rd AAAI Conference on Artificial Intelligence},
booktitle = {33rd Conf. Artificial Intelligence},
HIDEaddress = {Honolulu, HI, USA},
LONGpublisher = {{AAAI} Press},
publisher = {{AAAI}},
title = {Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks},
volume = {4602-4609},
HIDEmonth = {27. Jan. -- 2. Feb.}, 
year = {2019},
url = {http://arxiv.org/pdf/1810.02244v2},
}

@article{Scarselli2004,
abstract = {In this paper, we present a new neural network model, called graph neural network model, which is a generalization of two existing approaches, viz., the graph focused approach, and the node focused approach. The graph focused approach considers the mapping from a graph structure to a real vector, in which the mapping is independent of the particular node involved; while the node focused approach considers the mapping from a graph structure to a real vector, in which the mapping depends on the properties of the node involved. It is shown that the graph neural network model maintains some of the characteristics of the graph focused models and the node focused models respectively. A supervised learning algorithm is derived to estimate the parameters of the graph neural network model. Some experimental results are shown to validate the proposed learning algorithm, and demonstrate the generalization capability of the proposed model. {\&} Springer-Verfag 2004.},
author = {Scarselli, Franco and Tsoi, Ah Chung and Gori, Marco and Hagenbuchner, Markus},
doi = {10.1007/978-3-540-27868-9_4},
isbn = {9783540225706},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
mendeley-groups = {Graph Neural Networks/Basics},
pages = {42--56},
title = {{Graphical-based learning environments for pattern recognition}},
volume = {3138},
year = {2004}
}

@article{Schweidtmann2020_Validity,
abstract = {Data-driven models are becoming increasingly popular in engineering, on their own or in combination with mechanistic models. Commonly, the trained models are subsequently used in model-based optimization of design and/or operation of processes. Thus, it is critical to ensure that data-driven models are not evaluated outside their validity domain during process optimization. We propose a method to learn this validity domain and encode it as constraints in process optimization. We first perform a topological data analysis using persistent homology identifying potential holes or separated clusters in the training data. In case clusters or holes are identified, we train a one-class classifier, i.e., a one-class support vector machine, on the training data domain and encode it as constraints in the subsequent process optimization. Otherwise, we construct the convex hull of the data and encode it as constraints. We finally perform deterministic global process optimization with the data-driven models subject to their respective validity constraints. To ensure computational tractability, we develop a reduced-space formulation for trained one-class support vector machines and show that our formulation outperforms common full-space formulations by a factor of over 3,000, making it a viable tool for engineering applications. The method is ready-to-use and available open-source as part of our MeLOn toolbox (https://git.rwth-aachen.de/avt.svt/public/MeLOn).},
archivePrefix = {arXiv},
arxivId = {2010.03405},
author = {Schweidtmann, Artur M and Weber, Jana M and Wende, Christian and Netze, Linus and Mitsos, Alexander},
eprint = {2010.03405},
mendeley-groups = {Machine Learning/Validity domain},
journal = {arXiv preprint arXiv:2010.03405},
title = {{Obey validity limits of data-driven models}},
url = {http://arxiv.org/abs/2010.03405},
year = {2020}
}

@article{Sivaraman2020,
abstract = {Computational tools encompassing integrated molecular prediction, analysis, and generation are key for molecular design in a variety of critical applications. In this work, we develop a workflow for molecular analysis (MOLAN) that integrates an ensemble of supervised and unsupervised machine learning techniques to analyze molecular data sets. The MOLAN workflow combines molecular featurization, clustering algorithms, uncertainty analysis, low-bias dataset construction, high-performance regression models, graph-based molecular embeddings and attribution, and a semi-supervised variational autoencoder based on the novel SELFIES representation to enable molecular design. We demonstrate the utility of the MOLAN workflow in the context of a challenging multi-molecule property prediction problem: the determination of melting points solely from single molecule structure. This application serves as a case study for how to employ the MOLAN workflow in the context of molecular property prediction.},
author = {Sivaraman, Ganesh and Jackson, Nicholas E and Sanchez-Lengeling, Benjamin and V{\'{a}}zquez-Mayagoitia, {\'{A}}lvaro and Aspuru-Guzik, Al{\'{a}}n and Vishwanath, Venkatram and de Pablo, Juan J},
doi = {10.1088/2632-2153/ab8aa3},
journal = {Machine Learning: Science and Technology},
mendeley-groups = {Graph Neural Networks/Interpretability},
number = {2},
pages = {025015},
title = {{A machine learning workflow for molecular analysis: application to melting points}},
volume = {1},
year = {2020}
}

@article{Pope2018,
abstract = {Functional groups (FGs) are molecular substructures that are served as a foundation for analyzing and predicting chemical properties of molecules. Automatic discovery of FGs will impact various fields of research, including medicinal chemistry and material sciences, by reducing the amount of lab experiments required for discovery or synthesis of new molecules. In this paper, we investigate methods based on graph convolutional neural networks (GCNNs) for localizing FGs that contribute to specific chemical properties of interest. In our framework, molecules are modeled as undirected relational graphs with atoms as nodes and bonds as edges. Using this relational graph structure, we trained GCNNs in a supervised way on experimentally-validated molecular training sets to predict specific chemical properties, e.g., toxicity. Upon learning a GCNN, we analyzed its activation patterns to automatically identify FGs using four different explainability methods that we have developed: gradient-based saliency maps, Class Activation Mapping (CAM), gradient-weighted CAM (Grad-CAM), and Excitation Back-Propagation. Although these methods are originally derived for convolutional neural networks (CNNs), we adapt them to develop the corresponding suitable versions for GCNNs. We evaluated the contrastive power of these methods with respect to the specificity of the identified molecular substructures and their relevance for chemical functions. Grad-CAM had the highest contrastive power and generated qualitatively the best FGs. This work paves the way for automatic analysis and design of new molecules.},
archivePrefix = {arXiv},
arxivId = {1812.00265},
author = {Pope, Phillip and Kolouri, Soheil and Rostrami, Mohammad and Martin, Charles and Hoffmann, Heiko},
eprint = {1812.00265},
mendeley-groups = {Graph Neural Networks/Property prediction,Graph Neural Networks/Interpretability},
journal={arXiv preprint arXiv:1812.00265},
title = {{Discovering Molecular Functional Groups Using Graph Convolutional Neural Networks}},
url = {http://arxiv.org/abs/1812.00265},
year = {2018}
}


@article{Selvaraju2020,
abstract = {We propose a technique for producing ‘visual explanations' for decisions from a large class of Convolutional Neural Network (CNN)-based models, making them more transparent and explainable. Our approach—Gradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of any target concept (say ‘dog' in a classification network or a sequence of words in captioning network) flowing into the final convolutional layer to produce a coarse localization map highlighting the important regions in the image for predicting the concept. Unlike previous approaches, Grad-CAM is applicable to a wide variety of CNN model-families: (1) CNNs with fully-connected layers (e.g.VGG), (2) CNNs used for structured outputs (e.g.captioning), (3) CNNs used in tasks with multi-modal inputs (e.g.visual question answering) or reinforcement learning, all without architectural changes or re-training. We combine Grad-CAM with existing fine-grained visualizations to create a high-resolution class-discriminative visualization, Guided Grad-CAM, and apply it to image classification, image captioning, and visual question answering (VQA) models, including ResNet-based architectures. In the context of image classification models, our visualizations (a) lend insights into failure modes of these models (showing that seemingly unreasonable predictions have reasonable explanations), (b) outperform previous methods on the ILSVRC-15 weakly-supervised localization task, (c) are robust to adversarial perturbations, (d) are more faithful to the underlying model, and (e) help achieve model generalization by identifying dataset bias. For image captioning and VQA, our visualizations show that even non-attention based models learn to localize discriminative regions of input image. We devise a way to identify important neurons through Grad-CAM and combine it with neuron names (Bau et al. in Computer vision and pattern recognition, 2017) to provide textual explanations for model decisions. Finally, we design and conduct human studies to measure if Grad-CAM explanations help users establish appropriate trust in predictions from deep networks and show that Grad-CAM helps untrained users successfully discern a ‘stronger' deep network from a ‘weaker' one even when both make identical predictions. Our code is available at https://github.com/ramprs/grad-cam/, along with a demo on CloudCV (Agrawal et al., in: Mobile cloud visual media computing, pp 265–290. Springer, 2015) (http://gradcam.cloudcv.org) and a video at http://youtu.be/COjUB9Izk6E.},
author = {Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
doi = {10.1007/s11263-019-01228-7},
issn = {1573-1405},
journal = {International Journal of Computer Vision},
number = {2},
pages = {336--359},
title = {{Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization}},
url = {https://doi.org/10.1007/s11263-019-01228-7},
volume = {128},
year = {2020}
}


@article{Wang2020,
abstract = {Entity interaction prediction is essential in many important applications such as chemistry, biology, material science, and medical science. The problem becomes quite challenging when each entity is represented by a complex structure, namely structured entity, because two types of graphs are involved: local graphs for structured entities and a global graph to capture the interactions between structured entities. We observe that existing works on structured entity interaction prediction cannot properly exploit the unique graph of graphs model. In this paper, we propose a Graph of Graphs Neural Network, namely GoGNN, which extracts the features in both structured entity graphs and the entity interaction graph in a hierarchical way. We also propose the dual-attention mechanism that enables the model to preserve the neighbor importance in both levels of graphs. Extensive experiments on real-world datasets show that GoGNN outperforms the state-of-the-art methods on two representative structured entity interaction prediction tasks: chemical-chemical interaction prediction and drug-drug interaction prediction. Our code is available at Github.},
archivePrefix = {arXiv},
arxivId = {2005.05537},
author = {Wang, Hanchen and Lian, Defu and Zhang, Ying and Qin, Lu and Lin, Xuemin},
doi = {10.24963/ijcai.2020/183},
eprint = {2005.05537},
mendeley-groups = {Graph Neural Networks/Multi-input},
jounral={arXiv preprint arXiv:2005.05537},
pages = {1317--1323},
title = {{GoGNN: Graph of Graphs Neural Network for Predicting Structured Entity Interactions}},
year = {2020}
}
@article{Torng2019,
abstract = {Accurate determination of target-ligand interactions is crucial in the drug discovery process. In this paper, we propose a graph-convolutional (Graph-CNN) framework for predicting protein-ligand interactions. First, we built an unsupervised graph-autoencoder to learn fixed-size representations of protein pockets from a set of representative druggable protein binding sites. Second, we trained two Graph-CNNs to automatically extract features from pocket graphs and 2D ligand graphs, respectively, driven by binding classification labels. We demonstrate that graph-autoencoders can learn fixed-size representations for protein pockets of varying sizes and the Graph-CNN framework can effectively capture protein-ligand binding interactions without relying on target-ligand complexes. Across several metrics, Graph-CNNs achieved better or comparable performance to 3DCNN ligand-scoring, AutoDock Vina, RF-Score, and NNScore on common virtual screening benchmark data sets. Visualization of key pocket residues and ligand atoms contributing to the classification decisions confirms that our networks are able to detect important interface residues and ligand atoms within the pockets and ligands, respectively.},
author = {Torng, Wen and Altman, Russ B.},
doi = {10.1021/acs.jcim.9b00628},
issn = {15205142},
journal = {Journal of Chemical Information and Modeling},
mendeley-groups = {Graph Neural Networks/Multi-input},
pmid = {31580672},
title = {{Graph Convolutional Neural Networks for Predicting Drug-Target Interactions}},
year = {2019}
}
@article{Cho2020,
abstract = {Expanding the scope of graph-based, deep-learning models to noncovalent protein-ligand interactions has earned increasing attention in structure-based drug design. Modeling the protein-ligand interactions with graph neural networks (GNNs) has experienced difficulties in the conversion of protein-ligand complex structures into the graph representation and left questions regarding whether the trained models properly learn the appropriate noncovalent interactions. Here, we proposed a GNN architecture, denoted as InteractionNet, which learns two separated molecular graphs, being covalent and noncovalent, through distinct convolution layers. We also analyzed the InteractionNet model with an explainability technique, i.e., layer-wise relevance propagation, for examination of the chemical relevance of the model's predictions. Separation of the covalent and noncovalent convolutional steps made it possible to evaluate the contribution of each step independently and analyze the graph-building strategy for noncovalent interactions. We applied InteractionNet to the prediction of protein-ligand binding affinity and showed that our model successfully predicted the noncovalent interactions in both performance and relevance in chemical interpretation.},
archivePrefix = {arXiv},
arxivId = {q-bio.BM/2005.13438},
author = {Cho, Hyeoncheol and Lee, Eok Kyun and Choi, Insung S},
eprint = {2005.13438},
journal = {arXiv},
mendeley-groups = {Graph Neural Networks/Multi-input},
primaryClass = {q-bio.BM},
title = {{InteractionNet: Modeling and Explaining of Noncovalent Protein-Ligand Interactions with Noncovalent Graph Neural Network and Layer-Wise Relevance Propagation}},
year = {2020}
}
@article{hamilton2017representation,
  title={Representation learning on graphs: Methods and applications},
  author={Hamilton, William L and Ying, Rex and Leskovec, Jure},
  journal={arXiv preprint arXiv:1709.05584},
  year={2017}
}
@article{zheng2017joint,
  title={Joint extraction of entities and relations based on a novel tagging scheme},
  author={Zheng, Suncong and Wang, Feng and Bao, Hongyun and Hao, Yuexing and Zhou, Peng and Xu, Bo},
  journal={arXiv preprint arXiv:1706.05075},
  year={2017}
}
@inproceedings{xue2019fine,
  title={Fine-tuning BERT for joint entity and relation extraction in chinese medical text},
  author={Xue, Kui and Zhou, Yangming and Ma, Zhiyuan and Ruan, Tong and Zhang, Huanhuan and He, Ping},
  LONGbooktitle={2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
  booktitle={Int. Conf. Bioinformatics and Biomedicine (BIBM)},
  pages={892--897},
  year={2019},
  organization={IEEE}
}
@article{wilkinson2016fair,
  title={The FAIR Guiding Principles for scientific data management and stewardship},
  author={Wilkinson, Mark D and Dumontier, Michel and Aalbersberg, IJsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and da Silva Santos, Luiz Bonino and Bourne, Philip E and others},
  journal={Scientific data},
  volume={3},
  number={1},
  pages={1--9},
  year={2016},
  publisher={Nature Publishing Group}
}
@inproceedings{wang2014knowledge,
  title={Knowledge graph embedding by translating on hyperplanes},
  author={Wang, Zhen and Zhang, Jianwen and Feng, Jianlin and Chen, Zheng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={28},
  year={2014}
}
@inproceedings{nickel2016holographic,
  title={Holographic embeddings of knowledge graphs},
  author={Nickel, Maximilian and Rosasco, Lorenzo and Poggio, Tomaso},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={30},
  year={2016}
}
@inproceedings{varma2019multi,
  title={Multi-resolution weak supervision for sequential data},
  author={Varma, Paroma and Sala, Frederic and Sagawa, Shiori and Fries, Jason and Fu, Daniel and Khattar, Saelig and Ramamoorthy, Ashwini and Xiao, Ke and Fatahalian, Kayvon and Priest, James and others},
  booktitle={Advances in Neural Information Processing Systems},
  pages={192--203},
  year={2019}
}
@inproceedings{trouillon2016complex,
  title={Complex embeddings for simple link prediction},
  author={Trouillon, Th{\'e}o and Welbl, Johannes and Riedel, Sebastian and Gaussier, {\'E}ric and Bouchard, Guillaume},
  year={2016},
  booktitle={Proceedings of the International Conference on Machine Learning~(ICML)}
}
@inproceedings{dettmers2018convolutional,
  title={Convolutional 2d knowledge graph embeddings},
  author={Dettmers, Tim and Minervini, Pasquale and Stenetorp, Pontus and Riedel, Sebastian},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  year={2018}
}
@article{peters2018deep,
  title={Deep contextualized word representations},
  author={Peters, Matthew E and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1802.05365},
  year={2018}
}
@article{Kipf2016,
archivePrefix = {arXiv},
arxivId = {stat.ML/1611.07308},
author = {Kipf, Thomas N and Welling, Max},
eprint = {1611.07308},
journal = {arXiv preprint arXiv:1611.07308}, 
file = {:U$\backslash$:/Literature/Paper/Kipf{\_}2016-Variational Graph Auto-Encoders.pdf:pdf},
mendeley-groups = {Machine Learning/Autoencoder/Molecular VAEs},
primaryClass = {stat.ML},
title = {{Variational Graph Auto-Encoders}},
year = {2016}
}


@article{Xu2019,
abstract = {Predicting interactions between structured entities lies at the core of numerous tasks such as drug regimen and new material design. In recent years, graph neural networks have become attractive. They represent structured entities as graphs, and then extract features from each individual graph using graph convolution operations. However, these methods have some limitations: i) their networks only extract features from a fix-sized subgraph structure (i.e., a fix-sized receptive field) of each node, and ignore features in substructures of different sizes, and ii) features are extracted by considering each entity independently, which may not effectively reflect the interaction between two entities. To resolve these problems, we present MR-GNN, an end-to-end graph neural network with the following features: i) it uses a multi-resolution based architecture to extract node features from different neighborhoods of each node, and, ii) it uses dual graph-state long short-term memory networks (LSTMs) to summarize local features of each graph and extracts the interaction features between pairwise graphs. Experiments conducted on real-world datasets show that MR-GNN improves the prediction of state-of-the-art methods.},
archivePrefix = {arXiv},
arxivId = {1905.09558},
author = {Xu, Nuo and Wang, Pinghui and Chen, Long and Tao, Jing and Zhao, Junzhou},
doi = {10.24963/ijcai.2019/551},
eprint = {1905.09558},
isbn = {9780999241141},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
mendeley-groups = {Graph Neural Networks/Multi-input},
pages = {3968--3974},
title = {{MR-GNN: Multi-resolution and dual graph neural network for predicting structured entity interactions}},
volume = {2019-August},
year = {2019}
}


@inproceedings{You2018,
author = {You, Jiaxuan and Liu, Bowen and Ying, Zhitao and Pande, Vijay and Leskovec, Jure},
booktitle = {Advances in Neural Information Processing Systems 31},
pages = {6410--6421},
publisher = {Curran Associates, Inc.},
title = {{Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation}},
url = {https://proceedings.neurips.cc/paper/2018/file/d60678e8f2ba9c540798ebbde31177e8-Paper.pdf},
year = {2018}
}



@article{Jin2018,
abstract = {We seek to automate the design of molecules based on specific chemical properties. In computational terms, this task involves continuous embedding and generation of molecular graphs. Our primary contribution is the direct realization of molecular graphs, a task previously approached by generating linear SMILES strings instead of graphs. Our junction tree variational autoencoder generates molecular graphs in two phases, by first generating a tree-structured scaffold over chemical substructures, and then combining them into a molecule with a graph message passing network. This approach allows us to incrementally expand molecules while maintaining chemical validity at every step. We evaluate our model on multiple tasks ranging from molecular generation to optimization. Across these tasks, our model outperforms previous state-of-the-art baselines by a significant margin.},
archivePrefix = {arXiv},
arxivId = {1802.04364},
author = {Jin, Wengong and Barzilay, Regina and Jaakkola, Tbmmi},
eprint = {1802.04364},
file = {:U$\backslash$:/Literature/Paper/Jin{\_}2019-Junction Tree Variational Autoencoder for Molecular Graph Generation.pdf:pdf},
isbn = {9781510867963},
journal = {35th International Conference on Machine Learning, ICML 2018},
mendeley-groups = {Graph Neural Networks/Inverse design/Optimization,Graph Neural Networks/Autoencoder},
pages = {3632--3648},
title = {{Junction tree variational autoencoder for molecular graph generation}},
volume = {5},
year = {2018}
}

@article{Korolev2020,
abstract = {Nowadays the development of new functional materials/chemical compounds using machine learning (ML) techniques is a hot topic and includes several crucial steps, one of which is the choice of chemical structure representation. The classical approach of rigorous feature engineering in ML typically improves the performance of the predictive model, but at the same time, it narrows down the scope of applicability and decreases the physical interpretability of predicted results. In this study, we present graph convolutional neural networks (GCNNs) as an architecture that allows for successfully predicting the properties of compounds from diverse domains of chemical space, using a minimal set of meaningful descriptors. The applicability of GCNN models has been demonstrated by a wide range of chemical domain-specific properties. Their performance is comparable to state-of-the-art techniques; however, this architecture exempts from the need to carry out precise feature engineering.},
archivePrefix = {arXiv},
arxivId = {1906.06256},
author = {Korolev, Vadim and Mitrofanov, Artem and Korotcov, Alexandru and Tkachenko, Valery},
doi = {10.1021/acs.jcim.9b00587},
eprint = {1906.06256},
file = {:U$\backslash$:/Literature/Paper/Korolev{\_}2019-Graph Convolutional Neural Networks as General-Purpose Property Predictors{\_}The Universality and Limits of Applicability.pdf:pdf},
issn = {15205142},
journal = {Journal of Chemical Information and Modeling},
mendeley-groups = {Graph Neural Networks/Applicability},
number = {1},
pages = {22--28},
pmid = {31860296},
title = {{Graph Convolutional Neural Networks as "General-Purpose" Property Predictors: The Universality and Limits of Applicability}},
volume = {60},
year = {2020}
}

@article{Grambow2019,
abstract = {Machine learning provides promising new methods for accurate yet rapid prediction of molecular properties, including thermochemistry, which is an integral component of many computer simulations, particularly automated reaction mechanism generation. Often, very large data sets with tens of thousands of molecules are required for training the models, but most data sets of experimental or high-accuracy quantum mechanical quality are much smaller. To overcome these limitations, we calculate new high-level data sets and derive bond additivity corrections to significantly improve enthalpies of formation. We adopt a transfer learning technique to train neural network models that achieve good performance even with a relatively small set of high-accuracy data. The training data for the entropy model are carefully selected so that important conformational effects are captured. The resulting models are generally applicable thermochemistry predictors for organic compounds with oxygen and nitrogen heteroatoms that approach experimental and coupled cluster accuracy while only requiring molecular graph inputs. Due to their versatility and the ease of adding new training data, they are poised to replace conventional estimation methods for thermochemical parameters in reaction mechanism generation. Since high-accuracy data are often sparse, similar transfer learning approaches are expected to be useful for estimating many other molecular properties.},
author = {Grambow, Colin A. and Li, Yi Pei and Green, William H.},
doi = {10.1021/acs.jpca.9b04195},
file = {:U$\backslash$:/Literature/Paper/Grambrow{\_}2019-Accurate Thermochemistry with Small Data Sets{\_}A Bond Additivity Correction and Transfer Learning Approach.pdf:pdf},
issn = {15205215},
journal = {Journal of Physical Chemistry A},
mendeley-groups = {Graph Neural Networks/Property prediction},
number = {27},
pages = {5826--5835},
pmid = {31246465},
publisher = {American Chemical Society},
title = {{Accurate Thermochemistry with Small Data Sets: A Bond Additivity Correction and Transfer Learning Approach}},
volume = {123},
year = {2019}
}

@article{Coley2019,
abstract = {We present a supervised learning approach to predict the products of organic reactions given their reactants, reagents, and solvent(s). The prediction task is factored into two stages comparable to manual expert approaches: considering possible sites of reactivity and evaluating their relative likelihoods. By training on hundreds of thousands of reaction precedents covering a broad range of reaction types from the patent literature, the neural model makes informed predictions of chemical reactivity. The model predicts the major product correctly over 85{\%} of the time requiring around 100 ms per example, a significantly higher accuracy than achieved by previous machine learning approaches, and performs on par with expert chemists with years of formal training. We gain additional insight into predictions via the design of the neural model, revealing an understanding of chemistry qualitatively consistent with manual approaches.},
author = {Coley, Connor W. and Jin, Wengong and Rogers, Luke and Jamison, Timothy F. and Jaakkola, Tommi S. and Green, William H. and Barzilay, Regina and Jensen, Klavs F.},
doi = {10.1039/c8sc04228d},
file = {:U$\backslash$:/Literature/Paper/Coley{\_}2019-A graph-convolutional neural network model for the prediction of chemical reactivity.pdf:pdf},
issn = {20416539},
journal = {Chemical Science},
mendeley-groups = {Graph Neural Networks/Property prediction},
number = {2},
pages = {370--377},
publisher = {Royal Society of Chemistry},
title = {{A graph-convolutional neural network model for the prediction of chemical reactivity}},
volume = {10},
year = {2019}
}

@article{Yang2019,
abstract = {Advancements in neural machinery have led to a wide range of algorithmic solutions for molecular property prediction. Two classes of models in particular have yielded promising results: neural networks applied to computed molecular fingerprints or expert-crafted descriptors and graph convolutional neural networks that construct a learned molecular representation by operating on the graph structure of the molecule. However, recent literature has yet to clearly determine which of these two methods is superior when generalizing to new chemical space. Furthermore, prior research has rarely examined these new models in industry research settings in comparison to existing employed models. In this paper, we benchmark models extensively on 19 public and 16 proprietary industrial data sets spanning a wide variety of chemical end points. In addition, we introduce a graph convolutional model that consistently matches or outperforms models using fixed molecular descriptors as well as previous graph neural architectures on both public and proprietary data sets. Our empirical findings indicate that while approaches based on these representations have yet to reach the level of experimental reproducibility, our proposed model nevertheless offers significant improvements over models currently used in industrial workflows.},
archivePrefix = {arXiv},
arxivId = {1904.01561},
author = {Yang, Kevin and Swanson, Kyle and Jin, Wengong and Coley, Connor and Eiden, Philipp and Gao, Hua and Guzman-Perez, Angel and Hopper, Timothy and Kelley, Brian and Mathea, Miriam and Palmer, Andrew and Settels, Volker and Jaakkola, Tommi and Jensen, Klavs and Barzilay, Regina},
doi = {10.1021/acs.jcim.9b00237},
eprint = {1904.01561},
file = {:U$\backslash$:/Literature/Paper/Yang{\_}2019-Analyzing Learned Molecular Representations for Property Prediction.pdf:pdf},
issn = {15205142},
journal = {Journal of Chemical Information and Modeling},
mendeley-groups = {Graph Neural Networks/Property prediction},
number = {8},
pages = {3370--3388},
pmid = {31361484},
publisher = {American Chemical Society},
title = {{Analyzing Learned Molecular Representations for Property Prediction}},
volume = {59},
year = {2019}
}

@article{Coley2017,
abstract = {The task of learning an expressive molecular representation is central to developing quantitative structure-activity and property relationships. Traditional approaches rely on group additivity rules, empirical measurements or parameters, or generation of thousands of descriptors. In this paper, we employ a convolutional neural network for this embedding task by treating molecules as undirected graphs with attributed nodes and edges. Simple atom and bond attributes are used to construct atom-specific feature vectors that take into account the local chemical environment using different neighborhood radii. By working directly with the full molecular graph, there is a greater opportunity for models to identify important features relevant to a prediction task. Unlike other graph-based approaches, our atom featurization preserves molecule-level spatial information that significantly enhances model performance. Our models learn to identify important features of atom clusters for the prediction of aqueous solubility, octanol solubility, melting point, and toxicity. Extensions and limitations of this strategy are discussed.},
author = {Coley, Connor W. and Barzilay, Regina and Green, William H. and Jaakkola, Tommi S. and Jensen, Klavs F.},
doi = {10.1021/acs.jcim.6b00601},
file = {:U$\backslash$:/Literature/Paper/Coley{\_}2017-Convolutional Embedding of Attributed Molecular Graphs for Physical Property Prediction.pdf:pdf},
issn = {15205142},
journal = {Journal of Chemical Information and Modeling},
mendeley-groups = {Graph Neural Networks/Property prediction},
number = {8},
pages = {1757--1772},
pmid = {28696688},
title = {{Convolutional Embedding of Attributed Molecular Graphs for Physical Property Prediction}},
volume = {57},
year = {2017}
}

@article{Xie2018,
abstract = {The use of machine learning methods for accelerating the design of crystalline materials usually requires manually constructed feature vectors or complex transformation of atom coordinates to input the crystal structure, which either constrains the model to certain crystal types or makes it difficult to provide chemical insights. Here, we develop a crystal graph convolutional neural networks framework to directly learn material properties from the connection of atoms in the crystal, providing a universal and interpretable representation of crystalline materials. Our method provides a highly accurate prediction of density functional theory calculated properties for eight different properties of crystals with various structure types and compositions after being trained with 104 data points. Further, our framework is interpretable because one can extract the contributions from local chemical environments to global properties. Using an example of perovskites, we show how this information can be utilized to discover empirical rules for materials design.},
archivePrefix = {arXiv},
arxivId = {1710.10324},
author = {Xie, Tian and Grossman, Jeffrey C.},
doi = {10.1103/PhysRevLett.120.145301},
eprint = {1710.10324},
file = {:U$\backslash$:/Literature/Paper/Xie{\_}2017-Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material Properties.pdf:pdf},
issn = {10797114},
journal = {Physical Review Letters},
keywords = {doi:10.1103/PhysRevLett.120.145301 url:https://doi},
mendeley-groups = {Graph Neural Networks/Property prediction},
number = {14},
pages = {145301},
pmid = {29694125},
publisher = {American Physical Society},
title = {{Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material Properties}},
url = {https://doi.org/10.1103/PhysRevLett.120.145301},
volume = {120},
year = {2018}
}

@article{Cho2019,
abstract = {Deep learning has made great strides in tackling chemical problems, but still lacks full-fledged representations for three-dimensional (3D) molecular structures for its inner working. For example, the molecular graph, commonly used in chemistry and recently adapted to the graph convolutional network (GCN), is inherently a 2D representation of 3D molecules. Herein we propose an advanced version of the GCN, called 3DGCN, which receives 3D molecular information from a molecular graph augmented by information on bond direction. While outperforming state-of-the-art deep-learning models in the prediction of chemical and biological properties, 3DGCN has the ability to both generalize and distinguish molecular rotations in 3D, beyond 2D, which has great impact on drug discovery and development, not to mention the design of chemical reactions.},
author = {Cho, Hyeoncheol and Choi, Insung S.},
doi = {10.1002/cmdc.201900458},
file = {:U$\backslash$:/Literature/Paper/Chao{\_}2019-Enhanced Deep-Learning Prediction of MolecularProperties via Augmentation of Bond Topology.pdf:pdf},
issn = {18607187},
journal = {ChemMedChem},
keywords = {computational chemistry,machine learning,molecular graphs,molecular topology,structure–activity relationships},
mendeley-groups = {Graph Neural Networks/Property prediction},
number = {17},
pages = {1604--1609},
pmid = {31389167},
title = {{Enhanced Deep-Learning Prediction of Molecular Properties via Augmentation of Bond Topology}},
volume = {14},
year = {2019}
}

@article{Chen2019,
abstract = {Graph networks are a new machine learning (ML) paradigm that supports both relational reasoning and combinatorial generalization. Here, we develop universal MatErials Graph Network (MEGNet) models for accurate property prediction in both molecules and crystals. We demonstrate that the MEGNet models outperform prior ML models such as the SchNet in 11 out of 13 properties of the QM9 molecule data set. Similarly, we show that MEGNet models trained on ?60 000 crystals in the Materials Project substantially outperform prior ML models in the prediction of the formation energies, band gaps, and elastic moduli of crystals, achieving better than density functional theory accuracy over a much larger data set. We present two new strategies to address data limitations common in materials science and chemistry. First, we demonstrate a physically intuitive approach to unify four separate molecular MEGNet models for the internal energy at 0 K and room temperature, enthalpy, and Gibbs free energy into a single free energy MEGNet model by incorporating the temperature, pressure, and entropy as global state inputs. Second, we show that the learned element embeddings in MEGNet models encode periodic chemical trends and can be transfer-learned from a property model trained on a larger data set (formation energies) to improve property models with smaller amounts of data (band gaps and elastic moduli).},
archivePrefix = {arXiv},
arxivId = {1812.05055},
author = {Chen, Chi and Ye, Weike and Zuo, Yunxing and Zheng, Chen and Ong, Shyue Ping},
doi = {10.1021/acs.chemmater.9b01294},
eprint = {1812.05055},
file = {:U$\backslash$:/Literature/Paper/Chen{\_}2019-Graph Networks as a Universal Machine LearningFramework for Molecules and Crystals.pdf:pdf},
issn = {15205002},
journal = {Chemistry of Materials},
mendeley-groups = {Graph Neural Networks/Property prediction},
number = {9},
pages = {3564--3572},
title = {{Graph Networks as a Universal Machine Learning Framework for Molecules and Crystals}},
volume = {31},
year = {2019}
}

@article{Shui2020,
abstract = {As they carry great potential for modeling complex interactions, graph neural network (GNN)-based methods have been widely used to predict quantum mechanical properties of molecules. Most of the existing methods treat molecules as molecular graphs in which atoms are modeled as nodes. They characterize each atom's chemical environment by modeling its pairwise interactions with other atoms in the molecule. Although these methods achieve a great success, limited amount of works explicitly take many-body interactions, i.e., interactions between three and more atoms, into consideration. In this paper, we introduce a novel graph representation of molecules, heterogeneous molecular graph (HMG) in which nodes and edges are of various types, to model many-body interactions. HMGs have the potential to carry complex geometric information. To leverage the rich information stored in HMGs for chemical prediction problems, we build heterogeneous molecular graph neural networks (HMGNN) on the basis of a neural message passing scheme. HMGNN incorporates global molecule representations and an attention mechanism into the prediction process. The predictions of HMGNN are invariant to translation and rotation of atom coordinates, and permutation of atom indices. Our model achieves state-of-the-art performance in 9 out of 12 tasks on the QM9 dataset.},
archivePrefix = {arXiv},
arxivId = {2009.12710},
author = {Shui, Zeren and Karypis, George},
eprint = {2009.12710},
file = {:U$\backslash$:/Literature/Paper/Shui{\_}2020-Heterogeneous Molecular Graph Neural Networksfor Predicting Molecule Properties.pdf:pdf},
mendeley-groups = {Graph Neural Networks/Property prediction/Advanced models},
title = {{Heterogeneous Molecular Graph Neural Networks for Predicting Molecule Properties}},
url = {http://arxiv.org/abs/2009.12710},
year = {2020}
}

@article{Fey2020,
abstract = {We present a hierarchical neural message passing architecture for learning on molecular graphs. Our model takes in two complementary graph representations: the raw molecular graph representation and its associated junction tree, where nodes represent meaningful clusters in the original graph, e.g., rings or bridged compounds. We then proceed to learn a molecule's representation by passing messages inside each graph, and exchange messages between the two representations using a coarse-to-fine and fine-to-coarse information flow. Our method is able to overcome some of the restrictions known from classical GNNs, like detecting cycles, while still being very efficient to train. We validate its performance on the ZINC dataset and datasets stemming from the MoleculeNet benchmark collection.},
archivePrefix = {arXiv},
arxivId = {2006.12179},
author = {Fey, Matthias and Yuen, Jan-Gin and Weichert, Frank},
eprint = {2006.12179},
file = {:U$\backslash$:/Literature/Paper/Fey{\_}2020-Hierarchical Inter-Message Passing for Learning on Molecular Graphs.pdf:pdf},
mendeley-groups = {Graph Neural Networks/Property prediction/Advanced models},
title = {{Hierarchical Inter-Message Passing for Learning on Molecular Graphs}},
url = {http://arxiv.org/abs/2006.12179},
year = {2020}
}

@article{Dahmen2016,
abstract = {Oxygenates derived through the selective catalytic refunctionalization of carbohydrates of lignocellulosic biomass can be tailored to exhibit desired physicochemical fuel properties that unlock the full potential of advanced internal combustion engines. Considering the fuel'™s molecular structure to be a design degree of freedom, we present a framework for model-based fuel design that is envisioned to guide experimental investigation toward the most promising molecular entities. Following a generate-and-test approach to computer-aided molecular design, a novel rule-based generator of molecular structures is introduced to refunctionalize and join molecular graphs of predefined biobased intermediates in an attempt to resemble carbon-and energy-efficient biofuel synthesis. Computational property prediction is employed to virtually screen the generated structures with regard to key physicochemical fuel properties, e.g., the derived cetane number or fuel volatility. Two case studies are dedicated to the identification of biofuel components for use in (i) spark-ignition and (ii) compression-ignition engines.},
author = {Dahmen, Manuel and Marquardt, Wolfgang},
doi = {10.1021/acs.energyfuels.5b02674},
file = {:U$\backslash$:/Literature/Paper/Dahmen{\_}2016-Model-Based Design of Tailor-Made Biofuels.pdf:pdf},
issn = {15205029},
journal = {Energy and Fuels},
mendeley-groups = {QSPR/Biofuel property prediction},
number = {2},
pages = {1109--1134},
title = {{Model-Based Design of Tailor-Made Biofuels}},
volume = {30},
year = {2016}
}

@article{Sterling2015,
annote = {doi: 10.1021/acs.jcim.5b00559},
author = {Sterling, Teague and Irwin, John J},
doi = {10.1021/acs.jcim.5b00559},
file = {:U$\backslash$:/Literature/Paper/Sterling{\_}2015-ZINC 15-Ligand Discovery for Everyone.pdf:pdf},
issn = {1549-9596},
journal = {Journal of Chemical Information and Modeling},
mendeley-groups = {Datasets},
month = {Nov.},
number = {11},
pages = {2324--2337},
publisher = {American Chemical Society},
title = {{ZINC 15 - Ligand Discovery for Everyone}},
url = {https://doi.org/10.1021/acs.jcim.5b00559},
volume = {55},
year = {2015}
}

@article{Katritzky2010,
annote = {doi: 10.1021/cr900238d},
author = {Katritzky, Alan R and Kuanar, Minati and Slavov, Svetoslav and Hall, C Dennis and Karelson, Mati and Kahn, Iiris and Dobchev, Dimitar A},
doi = {10.1021/cr900238d},
issn = {0009-2665},
journal = {Chemical Reviews},
month = {Oct.},
number = {10},
pages = {5714--5789},
publisher = {American Chemical Society},
title = {{Quantitative Correlation of Physical and Chemical Properties with Chemical Structure: Utility for Prediction}},
url = {https://doi.org/10.1021/cr900238d},
volume = {110},
year = {2010}
}



@article{Faber2017,
abstract = {We investigate the impact of choosing regressors and molecular representations for the construction of fast machine learning (ML) models of thirteen electronic ground-state properties of organic molecules. The performance of each regressor/representation/property combination is assessed using learning curves which report out-of-sample errors as a function of training set size with up to {\$}\backslashsim{\$}117k distinct molecules. Molecular structures and properties at hybrid density functional theory (DFT) level of theory used for training and testing come from the QM9 database [Ramakrishnan et al, {\{}$\backslash$em Scientific Data{\}} {\{}$\backslash$bf 1{\}} 140022 (2014)] and include dipole moment, polarizability, HOMO/LUMO energies and gap, electronic spatial extent, zero point vibrational energy, enthalpies and free energies of atomization, heat capacity and the highest fundamental vibrational frequency. Various representations from the literature have been studied (Coulomb matrix, bag of bonds, BAML and ECFP4, molecular graphs (MG)), as well as newly developed distribution based variants including histograms of distances (HD), and angles (HDA/MARAD), and dihedrals (HDAD). Regressors include linear models (Bayesian ridge regression (BR) and linear regression with elastic net regularization (EN)), random forest (RF), kernel ridge regression (KRR) and two types of neural net works, graph convolutions (GC) and gated graph networks (GG). We present numerical evidence that ML model predictions deviate from DFT less than DFT deviates from experiment for all properties. Furthermore, our out-of-sample prediction errors with respect to hybrid DFT reference are on par with, or close to, chemical accuracy. Our findings suggest that ML models could be more accurate than hybrid DFT if explicitly electron correlated quantum (or experimental) data was available.},
archivePrefix = {arXiv},
arxivId = {1702.05532},
author = {Faber, Felix A. and Hutchison, Luke and Huang, Bing and Gilmer, Justin and Schoenholz, Samuel S. and Dahl, George E. and Vinyals, Oriol and Kearnes, Steven and Riley, Patrick F. and von Lilienfeld, O. Anatole},
doi = {10.1021/acs.jctc.7b00577},
eprint = {1702.05532},
file = {:U$\backslash$:/Literature/Paper/Faber{\_}2017-Machine learning prediction errors better than DFT accuracy.pdf:pdf},
mendeley-groups = {Graph Neural Networks/Property prediction},
pages = {1--12},
title = {{Machine learning prediction errors better than DFT accuracy}},
url = {http://arxiv.org/abs/1702.05532{\%}0Ahttp://dx.doi.org/10.1021/acs.jctc.7b00577},
year = {2017}
}

@article{Kearnes2016,
abstract = {Molecular “fingerprints” encoding structural information are the workhorse of cheminformatics and machine learning in drug discovery applications. However, fingerprint representations necessarily emphasize particular aspects of the molecular structure while ignoring others, rather than allowing the model to make data-driven decisions. We describe molecular graph convolutions, a machine learning architecture for learning from undirected graphs, specifically small molecules. Graph convolutions use a simple encoding of the molecular graph—atoms, bonds, distances, etc.—which allows the model to take greater advantage of information in the graph structure. Although graph convolutions do not outperform all fingerprint-based methods, they (along with other graph-based methods) represent a new paradigm in ligand-based virtual screening with exciting opportunities for future improvement.},
archivePrefix = {arXiv},
arxivId = {1603.00856},
author = {Kearnes, Steven and McCloskey, Kevin and Berndl, Marc and Pande, Vijay and Riley, Patrick},
doi = {10.1007/s10822-016-9938-8},
eprint = {1603.00856},
file = {:U$\backslash$:/Literature/Paper/Kearnes{\_}2016-Molecular Graph Convolutions{\_}Moving beyond Molecular Fingerprints.pdf:pdf},
issn = {15734951},
journal = {Journal of Computer-Aided Molecular Design},
keywords = {Artificial neural networks,Deep learning,Machine learning,Molecular descriptors,Virtual screening},
mendeley-groups = {Graph Neural Networks/Property prediction},
number = {8},
pages = {595--608},
pmid = {27558503},
title = {{Molecular graph convolutions: moving beyond fingerprints}},
volume = {30},
year = {2016}
}

@article{Lu2019,
abstract = {Predicting molecular properties (e.g., atomization energy) is an essential issue in quantum chemistry, which could speed up much research progress, such as drug designing and substance discovery. Traditional studies based on density functional theory (DFT) in physics are proved to be time-consuming for predicting large number of molecules. Recently, the machine learning methods, which consider much rule-based information, have also shown potentials for this issue. However, the complex inherent quantum interactions of molecules are still largely underexplored by existing solutions. In this paper, we propose a generalizable and transferable Multilevel Graph Convolutional neural Network (MGCN) for molecular property prediction. Specifically, we represent each molecule as a graph to preserve its internal structure. Moreover, the well-designed hierarchical graph neural network directly extracts features from the conformation and spatial information followed by the multilevel interactions. As a consequence, the multilevel overall representations can be utilized to make the prediction. Extensive experiments on both datasets of equilibrium and off-equilibrium molecules demonstrate the effectiveness of our model. Furthermore, the detailed results also prove that MGCN is generalizable and transferable for the prediction.},
archivePrefix = {arXiv},
arxivId = {1906.11081},
author = {Lu, Chengqiang and Liu, Qi and Wang, Chao and Huang, Zhenya and Lin, Peize and He, Lixin},
doi = {10.1609/aaai.v33i01.33011052},
eprint = {1906.11081},
file = {:U$\backslash$:/Literature/Paper/Lu{\_}2019-Molecular Property Prediction{\_}A Multilevel Quantum InteractionsModeling.pdf:pdf},
isbn = {9781577358091},
issn = {2159-5399},
journal = {33rd AAAI Conference on Artificial Intelligence, AAAI 2019, 31st Innovative Applications of Artificial Intelligence Conference, IAAI 2019 and the 9th AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019},
mendeley-groups = {Graph Neural Networks/Property prediction},
number = {Kollman},
pages = {1052--1060},
title = {{Molecular property prediction: A multilevel quantum interactions modeling perspective}},
year = {2019}
}

@article{Ma2020,
abstract = {The crux of molecular property prediction is to generate meaningful representations of the molecules. One promising route is to exploit the molecular graph structure through Graph Neural Networks (GNNs). It is well known that both atoms and bonds significantly affect the chemical properties of a molecule, so an expressive model shall be able to exploit both node (atom) and edge (bond) information simultaneously. Guided by this observation, we present Multi-View Graph Neural Network (MV-GNN), a multi-view message passing architecture to enable more accurate predictions of molecular properties. In MV-GNN, we introduce a shared self-attentive readout component and disagreement loss to stabilize the training process. This readout component also renders the whole architecture interpretable. We further boost the expressive power of MV-GNN by proposing a cross-dependent message passing scheme that enhances information communication of the two views, which results in the MV-GNN{\^{}}cross variant. Lastly, we theoretically justify the expressiveness of the two proposed models in terms of distinguishing non-isomorphism graphs. Extensive experiments demonstrate that MV-GNN models achieve remarkably superior performance over the state-of-the-art models on a variety of challenging benchmarks. Meanwhile, visualization results of the node importance are consistent with prior knowledge, which confirms the interpretability power of MV-GNN models.},
archivePrefix = {arXiv},
arxivId = {2005.13607},
author = {Ma, Hehuan and Bian, Yatao and Rong, Yu and Huang, Wenbing and Xu, Tingyang and Xie, Weiyang and Ye, Geyan and Huang, Junzhou},
eprint = {2005.13607},
file = {:U$\backslash$:/Literature/Paper/Ma{\_}2020-Multi-View Graph Neural Networksfor Molecular Property Prediction.pdf:pdf},
mendeley-groups = {Graph Neural Networks/Property prediction/Advanced models},
title = {{Multi-View Graph Neural Networks for Molecular Property Prediction}},
url = {http://arxiv.org/abs/2005.13607},
year = {2020}
}

@article{Gilmer2017,
abstract = {Supervised learning on molecules has incredible potential to be useful in chemistry, drug discovery, and materials science. Luckily, several promising and closely related neural network models invariant to molecular symmetries have already been described in the literature. These models learn a message passing algorithm and aggregation procedure to compute a function of their entire input graph. At this point, the next step is to find a particularly effective variant of this general approach and apply it to chemical prediction benchmarks until we either solve them or reach the limits of the approach. In this paper, we reformulate existing models into a single common framework we call Message Passing Neural Networks (MPNNs) and explore additional novel variations within this framework. Using MPNNs we demonstrate state of the art results on an important molecular property prediction benchmark; these results are strong enough that we believe future work should focus on datasets with larger molecules or more accurate ground truth labels.},
archivePrefix = {arXiv},
arxivId = {1704.01212},
author = {Gilmer, Justin and Schoenholz, Samuel S. and Riley, Patrick F. and Vinyals, Oriol and Dahl, George E.},
eprint = {1704.01212},
file = {:U$\backslash$:/Literature/Paper/Gilmer{\_}2017-Neural Message Passing for Quantum Chemistry.pdf:pdf},
isbn = {9781510855144},
journal = {34th International Conference on Machine Learning, ICML 2017},
keywords = {deep learning, chemistry, DFT},
mendeley-groups = {Graph Neural Networks/Property prediction},
pages = {2053--2070},
title = {{Neural message passing for quantum chemistry}},
volume = {3},
year = {2017}
}

@article{Flam-Shepherd2020,
abstract = {Graph neural network have achieved impressive results in predicting molecular properties, but they do not directly account for local and hidden structures in the graph such as functional groups and molecular geometry. At each propagation step, GNNs aggregate only over first order neighbours, ignoring important information contained in subsequent neighbours as well as the relationships between those higher order connections. In this work, we generalize graph neural nets to pass messages and aggregate across higher order paths. This allows for information to propagate over various levels and substructures of the graph. We demonstrate our model on a few tasks in molecular property prediction.},
archivePrefix = {arXiv},
arxivId = {2002.10413},
author = {Flam-Shepherd, Daniel and Wu, Tony and Friederich, Pascal and Aspuru-Guzik, Alan},
eprint = {2002.10413},
file = {:U$\backslash$:/Literature/Paper/Flam-Shepherd{\_}2020-Neural Message Passing on High Order Paths.pdf:pdf},
mendeley-groups = {Graph Neural Networks/Property prediction/Advanced models},
pages = {1--7},
title = {{Neural Message Passing on High Order Paths}},
url = {http://arxiv.org/abs/2002.10413},
year = {2020}
}

@article{Ye2020,
abstract = {Most of the current neural network models in quantum chemistry (QC) exclude the molecular symmetry and separate the well-correlated real space (R space) and momenta space (K space) into two individuals, which lack the essential physics in molecular chemistry. In this work, by endorsing the molecular symmetry and elementals of group theory, we propose a comprehendible method to apply symmetry in the graph neural network (SY-GNN), which extends the property-predicting coverage to orbital symmetry for both ground and excited states. SY-GNN is an end-to-end model that can predict multiple properties in both K and R space within a single model, and it shows excellent performance in predicting both the absolute and relative R and K space quantities. Besides the numerical properties, SY-GNN can also predict orbital properties, providing the active regions of chemical reactions. We believe the symmetry-endorsed deep learning scheme covers the significant physics inside and is essential for the application of neural networks in QC and many other research fields in the future.},
author = {Ye, Shuqian and Liang, Jiechun and Liu, Rulin and Zhu, Xi},
doi = {10.1021/acs.jpca.0c03201},
file = {:U$\backslash$:/Literature/Paper/Ye{\_}2020-Symmetrical Graph Neural Network for Quantum Chemistry withDual Real and Momenta Space.pdf:pdf},
issn = {15205215},
journal = {The journal of physical chemistry. A},
mendeley-groups = {Graph Neural Networks/Property prediction},
number = {34},
pages = {6945--6953},
pmid = {32786228},
title = {{Symmetrical Graph Neural Network for Quantum Chemistry with Dual Real and Momenta Space}},
volume = {124},
year = {2020}
}

@article{Sivaraman2019,
abstract = {The ability to predict multi-molecule processes, using only knowledge of single molecule structure, stands as a grand challenge for molecular modeling. Methods capable of predicting melting points (MP) solely from chemical structure represent a canonical example, and are highly desirable in many crucial industrial applications. In this work, we explore a data-driven approach utilizing machine learning (ML) techniques to predict and understand the MP of molecules. Several experimental databases are aggregated from the literature to design a low-bias dataset that includes 3D structural and quantum-chemical properties. Using experimental and polymorph-induced uncertainties, we derive a tenable lower limit for MP prediction accuracy, and apply graph neural networks and Gaussian processes to predict MP competitive with these error bounds. To further understand how MP correlates with molecular structure, we employ several semi-supervised and unsupervised ML techniques. First, we use unsu-pervised clustering methods to identify classes of molecules, their common fragments, and expected errors for each data set. We then build molecular geometric spaces shaped by MP with a semi-supervised variational autoencoder and graph embedding spaces, and apply graph attribution methods to highlight atom-level contributions to MP within the datasets. Overall, this work serves as a case study of how to employ a diversified ML toolkit to predict and understand correlations between molecular structures and thermophysical properties of interest.},
author = {Sivaraman, Ganesh and Jackson, Nicholas and Sanchez-Lengeling, Benjamin and Vazquez-Mayagoitia, Alvaro and Aspuru-Guzik, Alan and Vishwanath, Venkatram and de Pablo, Juan},
doi = {10.26434/chemrxiv.9914378},
file = {:U$\backslash$:/Literature/Paper/Sivaraman{\_}2019-A Diversified Machine Learning Strategy for Predicting and Understanding Molecular Melting Points.pdf:pdf},
keywords = {Active Learning Methodologies,Chemoinformatics - Computational Chemistry,Computational Chemistry and Modeling,Drug Discovery and Drug Delivery Systems,Generative model,Machine Learning,Thermodynamics (Chem. Eng.),drug molecule,machine Learning Predictions,thermophysical property,uncertainties,unsupervised method},
mendeley-groups = {Graph Neural Networks/Property prediction,Graph Neural Networks/Interpretability},
pages = {1--42},
title = {{A Diversified Machine Learning Strategy for Predicting and Understanding Molecular Melting Points}},
year = {2019}
}

@article{Pathak2020,
abstract = {Solubility of drug molecules is related to pharmacokinetic properties such as absorption and distribution, which affects the amount of drug that is available in the body for its action. Computational or experimental evaluation of solvation free energies of drug-like molecules/solute that quantify solubilities is an arduous task and hence development of reliable computationally tractable models is sought after in drug discovery tasks in pharmaceutical industry. Here, we report a novel method based on graph neural network to predict solvation free energies. Previous studies considered only the solute for solvation free energy prediction and ignored the nature of the solvent, limiting their practical applicability. The proposed model is an end-to-end framework comprising three phases namely, message passing, interaction and prediction phases. In the first phase, message passing neural network was used to compute inter-atomic interaction within both solute and solvent molecules represented as molecular graphs. In the interaction phase, features from the preceding step is used to calculate a solute-solvent interaction map, since the solvation free energy depends on how (un)favorable the solute and solvent molecules interact with each other. The calculated interaction map that captures the solute-solvent interactions along with the features from the message passing phase is used to predict the solvation free energies in the final phase. The model predicts solvation free energies involving a large number of solvents with high accuracy. We also show that the interaction map captures the electronic and steric factors that govern the solubility of drug-like molecules and hence is chemically interpretable.},
author = {Pathak, Yashaswi and Laghuvarapu, Siddhartha and Mehta, Sarvesh and Priyakumar, U. Deva},
doi = {10.1609/aaai.v34i01.5433},
file = {:U$\backslash$:/Literature/Paper/Pathak{\_}2020-Chemically Interpretable Graph Interaction Network for Prediction of Pharmacokinetic Properties of Drug-Like Molecules.pdf:pdf},
issn = {2159-5399},
journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
keywords = {Applications},
mendeley-groups = {Graph Neural Networks/Interpretability,Graph Neural Networks/Multi-input},
number = {01},
pages = {873--880},
title = {{Chemically Interpretable Graph Interaction Network for Prediction of Pharmacokinetic Properties of Drug-Like Molecules}},
volume = {34},
year = {2020}
}

@article{Fey2020_dgmc,
abstract = {This work presents a two-stage neural architecture for learning and refining structural correspondences between graphs. First, we use localized node embeddings computed by a graph neural network to obtain an initial ranking of soft correspondences between nodes. Secondly, we employ synchronous message passing networks to iteratively re-rank the soft correspondences to reach a matching consensus in local neighborhoods between graphs. We show, theoretically and empirically, that our message passing scheme computes a well-founded measure of consensus for corresponding neighborhoods, which is then used to guide the iterative re-ranking process. Our purely local and sparsity-aware architecture scales well to large, real-world inputs while still being able to recover global correspondences consistently. We demonstrate the practical effectiveness of our method on real-world tasks from the fields of computer vision and entity alignment between knowledge graphs, on which we improve upon the current state-of-the-art. Our source code is available under https://github.com/rusty1s/ deep-graph-matching-consensus.},
archivePrefix = {arXiv},
arxivId = {2001.09621},
author = {Fey, Matthias and Lenssen, Jan E. and Morris, Christopher and Masci, Jonathan and Kriege, Nils M.},
eprint = {2001.09621},
file = {:U$\backslash$:/Literature/Paper/Fey{\_}2020-Deep Graph Matching Consensus.pdf:pdf},
mendeley-groups = {Graph Neural Networks/Graph similarity},
pages = {1--23},
title = {{Deep Graph Matching Consensus}},
url = {http://arxiv.org/abs/2001.09621},
year = {2020}
}


@inproceedings{Ying2019,
author = {Ying, Zhitao and Bourgeois, Dylan and You, Jiaxuan and Zitnik, Marinka and Leskovec, Jure},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {9244--9255},
publisher = {Curran Associates, Inc.},
title = {{GNNExplainer: Generating Explanations for Graph Neural Networks}},
url = {https://proceedings.neurips.cc/paper/2019/file/d80b7040b773199015de6d3b4293c8ff-Paper.pdf},
year = {2019}
}


@article{Huang2020,
abstract = {Graph structured data has wide applicability in various domains such as physics, chemistry, biology, computer vision, and social networks, to name a few. Recently, graph neural networks (GNN) were shown to be successful in effectively representing graph structured data because of their good performance and generalization ability. GNN is a deep learning based method that learns a node representation by combining specific nodes and the structural/topological information of a graph. However, like other deep models, explaining the effectiveness of GNN models is a challenging task because of the complex nonlinear transformations made over the iterations. In this paper, we propose GraphLIME, a local interpretable model explanation for graphs using the Hilbert-Schmidt Independence Criterion (HSIC) Lasso, which is a nonlinear feature selection method. GraphLIME is a generic GNN-model explanation framework that learns a nonlinear interpretable model locally in the subgraph of the node being explained. More specifically, to explain a node, we generate a nonlinear interpretable model from its {\$}N{\$}-hop neighborhood and then compute the K most representative features as the explanations of its prediction using HSIC Lasso. Through experiments on two real-world datasets, the explanations of GraphLIME are found to be of extraordinary degree and more descriptive in comparison to the existing explanation methods.},
archivePrefix = {arXiv},
arxivId = {2001.06216},
author = {Huang, Qiang and Yamada, Makoto and Tian, Yuan and Singh, Dinesh and Yin, Dawei and Chang, Yi},
eprint = {2001.06216},
file = {:U$\backslash$:/Literature/Paper/Huang{\_}2020-GraphLIME{\_}Local Interpretable Model Explanationsfor Graph Neural Networks.pdf:pdf},
mendeley-groups = {Graph Neural Networks/Interpretability},
pages = {1--15},
title = {{GraphLIME: Local Interpretable Model Explanations for Graph Neural Networks}},
url = {http://arxiv.org/abs/2001.06216},
journal={arXiv preprint arXiv:2001.06216},
year = {2020}
}

@inbook{Preuer2019,
abstract = {Without any means of interpretation, neural networks that predict molecular properties and bioactivities are merely black boxes. We will unravel these black boxes and will demonstrate approaches to understand the learned representations which are hidden inside these models. We show how single neurons can be interpreted as classifiers which determine the presence or absence of pharmacophore- or toxicophore-like structures, thereby generating new insights and relevant knowledge for chemistry, pharmacology and biochemistry. We further discuss how these novel pharmacophores/toxicophores can be determined from the network by identifying the most relevant components of a compound for the prediction of the network. Additionally, we propose a method which can be used to extract new pharmacophores from a model and will show that these extracted structures are consistent with literature findings. We envision that having access to such interpretable knowledge is a crucial aid in the development and design of new pharmaceutically active molecules, and helps to investigate and understand failures and successes of current methods.},
address = {Cham},
author = {Preuer, Kristina and Klambauer, G{\"{u}}nter and Rippmann, Friedrich and Hochreiter, Sepp and Unterthiner, Thomas},
booktitle = {Explainable AI: Interpreting, Explaining and Visualizing Deep Learning},
doi = {10.1007/978-3-030-28954-6_18},
editor = {Samek, Wojciech and Montavon, Gr{\'{e}}goire and Vedaldi, Andrea and Hansen, Lars Kai and M{\"{u}}ller, Klaus-Robert},
isbn = {978-3-030-28954-6},
mendeley-groups = {Graph Neural Networks/Interpretability},
pages = {331--345},
publisher = {Springer International Publishing},
title = {{Interpretable Deep Learning in Drug Discovery}},
url = {https://doi.org/10.1007/978-3-030-28954-6{\_}18},
year = {2019}
}

@article{Lin2020,
abstract = {Graph Neural Networks (GNNs) are versatile, powerful machine learning methods that enable graph structure and feature representation learning, and have applications across many domains. For applications critically requiring interpretation, attention-based GNNs have been leveraged. However, these approaches either rely on specific model architectures or lack a joint consideration of graph structure and node features in their interpretation. Here we present a model-agnostic framework for interpreting important graph structure and node features, Graph neural networks Including SparSe inTerpretability (GISST). With any GNN model, GISST combines an attention mechanism and sparsity regularization to yield an important subgraph and node feature subset related to any graph-based task. Through a single self-attention layer, a GISST model learns an importance probability for each node feature and edge in the input graph. By including these importance probabilities in the model loss function, the probabilities are optimized end-to-end and tied to the task-specific performance. Furthermore, GISST sparsifies these importance probabilities with entropy and L1 regularization to reduce noise in the input graph topology and node features. Our GISST models achieve superior node feature and edge explanation precision in synthetic datasets, as compared to alternative interpretation approaches. Moreover, our GISST models are able to identify important graph structure in real-world datasets. We demonstrate in theory that edge feature importance and multiple edge types can be considered by incorporating them into the GISST edge probability computation. By jointly accounting for topology, node features, and edge features, GISST inherently provides simple and relevant interpretations for any GNN models and tasks.},
archivePrefix = {arXiv},
arxivId = {2007.00119},
author = {Lin, Chris and Sun, Gerald J. and Bulusu, Krishna C. and Dry, Jonathan R. and Hernandez, Marylens},
eprint = {2007.00119},
file = {:U$\backslash$:/Literature/Paper/Lin{\_}2020-Graph Neural Networks Including SparseInterpretability.pdf:pdf},
mendeley-groups = {Graph Neural Networks/Interpretability},
pages = {1--12},
title = {{Graph Neural Networks Including Sparse Interpretability}},
url = {http://arxiv.org/abs/2007.00119},
year = {2020}
}

@article{Huster2020,
abstract = {The performance of an organic Rankine cycle (ORC) relies on process design and operation. Simultaneous optimization of design and operation for a range of working fluids (WFs) is therefore a promising approach for WF selection. For this, deterministic global process optimization can guarantee to identify a global optimum, in contrast to local or stochastic global solution approaches. However, providing accurate thermodynamic models for a large number of WFs while maintaining computational tractability of the resulting optimization problems are open research questions. We integrate accurate thermodynamic and transport properties via artificial neural networks (ANNs) and solve the design problems with MAiNGO in a reduced-space formulation. We illustrate the approach for an ORC process for waste heat recovery of a diesel truck. After an automated preselection of 122 WFs, ANNs are automatically trained for the 37 selected WFs based on data retrieved from the thermodynamic library CoolProp. Then, we perform deterministic global optimization of design and operation for every WF individually. Therein, the trade-off between net power generation and investment cost is investigated by multiobjective optimization. Further, a thermoeconomic optimization finds a compromise between both objectives. The results show that, for the given conditions, monoaromatic hydrocarbons are a promising group of WFs. In future work, the proposed method and the trained ANNs can be applied to the design of a variety of energy processes.},
author = {Huster, Wolfgang R. and Schweidtmann, Artur M. and Mitsos, Alexander},
doi = {10.1007/s11081-019-09454-1},
file = {:U$\backslash$:/Literature/Paper/Huster{\_}2020-Working Fluid Selection For Organic Rankine Cycles.pdf:pdf},
isbn = {1108101909},
issn = {15732924},
journal = {Optimization and Engineering},
keywords = {Artificial neural networks,Hybrid modeling,MAiNGO,Multiobjective optimization,Thermoeconomic optimization,Waste heat recovery},
mendeley-groups = {SVT publications},
number = {2},
pages = {517--536},
publisher = {Springer US},
title = {{Working Fluid Selection for Organic Rankine Cycles via Deterministic Global Optimization of Design and Operation}},
url = {https://doi.org/10.1007/s11081-019-09454-1},
volume = {21},
year = {2020}
}

@article{Schweidtmann2019,
abstract = {Artificial neural networks are used in various applications for data-driven black-box modeling and subsequent optimization. Herein, we present an efficient method for deterministic global optimization of optimization problems with artificial neural networks embedded. The proposed method is based on relaxations of algorithms using McCormick relaxations in a reduced space (Mitsos et al. in SIAM J Optim 20(2):573–601, 2009) employing the convex and concave envelopes of the nonlinear activation function. The optimization problem is solved using our in-house deterministic global solver. The performance of the proposed method is shown in four optimization examples: an illustrative function, a fermentation process, a compressor plant and a chemical process. The results show that computational solution time is favorable compared to a state-of-the-art global general-purpose optimization solver.},
author = {Schweidtmann, Artur M. and Mitsos, Alexander},
doi = {10.1007/s10957-018-1396-0},
file = {:U$\backslash$:/Literature/Paper/Schweidtmann{\_}2019-Deterministic Global Optimization with ANNs embedded.pdf:pdf},
issn = {15732878},
journal = {Journal of Optimization Theory and Applications},
keywords = {MAiNGO,Machine learning,McCormick relaxations,Multilayer perceptron,Surrogate-based optimization},
mendeley-groups = {DFG{\_}GNNs},
number = {3},
pages = {925--948},
publisher = {Springer US},
title = {{Deterministic Global Optimization with Artificial Neural Networks Embedded}},
url = {https://doi.org/10.1007/s10957-018-1396-0},
volume = {180},
year = {2019}
}


@article{Schweidtmann2019b,
abstract = {Global deterministic process optimization problems have recently been solved efficiently in a reduced-space by automatic propagation of McCormick relaxations (Bongartz and Mitsos, J. Global Optim, 2017). However, the previous optimizations have been limited to simplified thermodynamic property models. Herein, we propose a method that learns accurate thermodynamic properties via artificial neural networks (ANNs) and integrates those in deterministic global process optimization. The resulting hybrid process model is solved using the recently developed method for deterministic global optimization problems with ANNs embedded (Schweidtmann and Mitsos, J. Optim. Theory Appl., 2018). The optimal operation of a validated steady state model of an organic Rankine cycle is solved as a case study. It is especially challenging as the thermodynamic properties are given by the implicit Helmholtz equation of state. The results show that modeling of thermodynamic properties via ANNs performs favorable in deterministic optimization. This method can rapidly be extended to include properties from existing thermodynamic libraries, based on models or data.},
author = {Schweidtmann, Artur M. and Huster, Wolfgang R. and L{\"{u}}thje, Jannik T. and Mitsos, Alexander},
doi = {10.1016/j.compchemeng.2018.10.007},
file = {:U$\backslash$:/Literature/Paper/Schweidtmann{\_}2019-Deterministic global process optimiyzation{\_}accurate properties via ANNs.pdf:pdf},
issn = {00981354},
journal = {Computers and Chemical Engineering},
keywords = {MAiNGO,McCormick relaxations,Organic Rankine cycle,Reduced-space formulation,Surrogate-based global optimization,Thermodynamic properties},
mendeley-groups = {SVT publications},
pages = {67--74},
publisher = {Elsevier Ltd},
title = {{Deterministic Global Process Optimization: Accurate (Single-Species) Properties via Artificial Neural Networks}},
url = {https://doi.org/10.1016/j.compchemeng.2018.10.007},
volume = {121},
year = {2019}
}

@article{Wu2020,
abstract = {Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications, where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on the existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this article, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art GNNs into four categories, namely, recurrent GNNs, convolutional GNNs, graph autoencoders, and spatial-temporal GNNs. We further discuss the applications of GNNs across various domains and summarize the open-source codes, benchmark data sets, and model evaluation of GNNs. Finally, we propose potential research directions in this rapidly growing field.},
author = {Wu, Z and Pan, S and Chen, F and Long, G and Zhang, C and Yu, P S},
doi = {10.1109/TNNLS.2020.2978386},
file = {:U$\backslash$:/Literature/Paper/Wu{\_}2019-A comprehensive survey on graph neural networks.pdf:pdf},
issn = {2162-2388 VO -},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {Data mining,Deep learning,Feature extraction,Kernel,Learning systems,Neural networks,Task analysis,graph autoencoder (GAE),graph convolutional networks (GCNs),graph neural networks (GNNs),graph representation learning,network embedding.},
mendeley-groups = {Graph Neural Networks/Basics},
title = {{A Comprehensive Survey on Graph Neural Networks}},
note = {Early access, Mar. 24, 2020, DOI: 10.1109/TNNLS.2020.2978386.}
}


@article{Zhang2020,
abstract = {Deep learning has been shown to be successful in a number of domains, ranging from acoustics, images, to natural language processing. However, applying deep learning to the ubiquitous graph data is non-trivial because of the unique characteristics of graphs. Recently, substantial research efforts have been devoted to applying deep learning methods to graphs, resulting in beneficial advances in graph analysis techniques. In this survey, we comprehensively review the different types of deep learning methods on graphs. We divide the existing methods into five categories based on their model architectures and training strategies: graph recurrent neural networks, graph convolutional networks, graph autoencoders, graph reinforcement learning, and graph adversarial methods. We then provide a comprehensive overview of these methods in a systematic manner mainly by following their development history. We also analyze the differences and compositions of different methods. Finally, we briefly outline the applications in which they have been used and discuss potential future research directions.},
archivePrefix = {arXiv},
arxivId = {1812.04202},
author = {Zhang, Ziwei and Cui, Peng and Zhu, Wenwu},
doi = {10.1109/tkde.2020.2981333},
eprint = {1812.04202},
journal = {IEEE Transactions on Knowledge and Data Engineering},
mendeley-groups = {Graph Neural Networks/Basics},
title = {{Deep Learning on Graphs: A Survey}},
note = {Early access, Mar. 17, 2020. DOI: 10.1109/TNNLS.2020.2978386.}
}

@article{Zhou2018,
abstract = {Lots of learning tasks require dealing with graph data which contains rich relation information among elements. Modeling physics system, learning molecular fingerprints, predicting protein interface, and classifying diseases require a model to learn from graph inputs. In other domains such as learning from non-structural data like texts and images, reasoning on extracted structures, like the dependency tree of sentences and the scene graph of images, is an important research topic which also needs graph reasoning models. Graph neural networks (GNNs) are connectionist models that capture the dependence of graphs via message passing between the nodes of graphs. Unlike standard neural networks, graph neural networks retain a state that can represent information from its neighborhood with arbitrary depth. Although the primitive GNNs have been found difficult to train for a fixed point, recent advances in network architectures, optimization techniques, and parallel computation have enabled successful learning with them. In recent years, systems based on variants of graph neural networks such as graph convolutional network (GCN), graph attention network (GAT), gated graph neural network (GGNN) have demonstrated ground-breaking performance on many tasks mentioned above. In this survey, we provide a detailed review over existing graph neural network models, systematically categorize the applications, and propose four open problems for future research.},
archivePrefix = {arXiv},
arxivId = {1812.08434},
author = {Zhou, Jie and Cui, Ganqu and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Wang, Lifeng and Li, Changcheng and Sun, Maosong},
eprint = {1812.08434},
mendeley-groups = {Graph Neural Networks/Basics},
journal= {arXiv preprint arXiv:1812.08434},
title = {{Graph Neural Networks: A Review of Methods and Applications}},
url = {http://arxiv.org/abs/1812.08434},
year = {2018}
}

@article{Hamilton2017,
abstract = {Low-dimensional embeddings of nodes in large graphs have proved extremely useful in a variety of prediction tasks, from content recommendation to identifying protein functions. However, most existing approaches require that all nodes in the graph are present during training of the embeddings; these previous approaches are inherently transductive and do not naturally generalize to unseen nodes. Here we present GraphSAGE, a general inductive framework that leverages node feature information (e.g., text attributes) to efficiently generate node embeddings for previously unseen data. Instead of training individual embeddings for each node, we learn a function that generates embeddings by sampling and aggregating features from a node's local neighborhood. Our algorithm outperforms strong baselines on three inductive node-classification benchmarks: we classify the category of unseen nodes in evolving information graphs based on citation and Reddit post data, and we show that our algorithm generalizes to completely unseen graphs using a multi-graph dataset of protein-protein interactions.},
archivePrefix = {arXiv},
arxivId = {1706.02216},
author = {Hamilton, William L. and Ying, Rex and Leskovec, Jure},
eprint = {1706.02216},
file = {:U$\backslash$:/Literature/Paper/Hamilton{\_}2018-Inductive Representation Learning on Large Graphs.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
mendeley-groups = {Graph Neural Networks/Basics},
number = {Nips},
pages = {1025--1035},
title = {{Inductive representation learning on large graphs}},
volume = {2017-Decem},
year = {2017}
}

@article{Grohe2018,
abstract = {The graph similarity problem, also known as approximate graph isomorphism or graph matching problem, has been extensively studied in the machine learning community, but has not received much attention in the algorithms community: Given two graphs G, H of the same order n with adjacency matrices AG, AH, a well-studied measure of similarity is the Frobenius distance dist(G, H):= min kA$\pi$G − AHkF , $\pi$ where $\pi$ ranges over all permutations of the vertex set of G, where A$\pi$G denotes the matrix obtained from AG by permuting rows and columns according to $\pi$, and where kMkF is the Frobenius norm of a matrix M. The (weighted) graph similarity problem, denoted by GSim (WSim), is the problem of computing this distance for two graphs of same order. This problem is closely related to the notoriously hard quadratic assignment problem (QAP), which is known to be NP-hard even for severely restricted cases. It is known that GSim (WSim) is NP-hard; we strengthen this hardness result by showing that the problem remains NP-hard even for the class of trees. Identifying the boundary of tractability for WSim is best done in the framework of linear algebra. We show that WSim is NP-hard as long as one of the matrices has unbounded rank or negative eigenvalues: hence, the realm of tractability is restricted to positive semi-definite matrices of bounded rank. Our main result is a polynomial time algorithm for the special case where the associated (weighted) adjacency graph for one of the matrices has a bounded number of twin equivalence classes. The key parameter underlying our algorithm is the clustering number of a graph; this parameter arises in context of the spectral graph drawing machinery.},
archivePrefix = {arXiv},
arxivId = {1802.08509},
author = {Grohe, Martin and Rattan, Gaurav and Woeginger, Gerhard J.},
doi = {10.4230/LIPIcs.MFCS.2018.20},
eprint = {1802.08509},
file = {:U$\backslash$:/Literature/Paper/Grohe{\_}2018-Graph Similarity and Approximate Isomorphism.pdf:pdf},
isbn = {9783959770866},
issn = {18688969},
journal = {Leibniz International Proceedings in Informatics, LIPIcs},
keywords = {Approximate graph isomorphism,Graph similarity,Quadratic assignment problem},
mendeley-groups = {Graph Neural Networks/Graph similarity},
title = {{Graph Similarity and Approximate Isomorphism}},
volume = {117},
year = {2018}
}

@techreport{tanimoto1958elementary,
  title={Elementary Mathematical Theory of Classification and Prediction},
  author={Tanimoto, Taffee T},
  year={1958},
  publisher={IBM Corp.},
  location={New York},
  type={Internal Rep}
}

@article{Pan2010,
abstract = {A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data-labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression, and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift. We also explore some potential future issues in transfer learning research. {\textcopyright} 2006 IEEE.},
author = {Pan, Sinno Jialin and Yang, Qiang},
doi = {10.1109/TKDE.2009.191},
file = {:U$\backslash$:/Literature/Paper/Pan{\_}2009-A survey on transfer learning.pdf:pdf},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Transfer learning,data mining.,machine learning,survey},
mendeley-groups = {Machine Learning/Transfer Learning},
number = {10},
pages = {1345--1359},
publisher = {IEEE},
title = {{A Survey on Transfer Learning}},
volume = {22},
year = {2010}
}

@INPROCEEDINGS{He2016,
  author={K. {He} and X. {Zhang} and S. {Ren} and J. {Sun}},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Deep Residual Learning for Image Recognition}, 
  address = {Las Vegas, NV, USA},
  year={2016},
  volume={},
  number={},
  pages={770-778},
  keywords={image classification;learning (artificial intelligence);neural nets;object detection;COCO segmentation;ImageNet localization;ILSVRC \& COCO 2015 competitions;deep residual nets;COCO object detection dataset;visual recognition tasks;CIFAR-10;ILSVRC 2015 classification task;ImageNet test set;VGG nets;residual nets;ImageNet dataset;residual function learning;deeper neural network training;image recognition;deep residual learning;Training;Degradation;Complexity theory;Image recognition;Neural networks;Visualization;Image segmentation},
  doi={10.1109/CVPR.2016.90},
  ISSN={1063-6919},
  month={27--30 June},
  }
  

@incollection{Krizhevsky2012,
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
booktitle = {Advances in Neural Information Processing Systems 25},
mendeley-groups = {Machine Learning/CNNs},
pages = {1097--1105},
publisher = {Curran Associates, Inc.},
title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
year = {2012}
}


@article{Gomez-Bombarelli2018,
abstract = {We report a method to convert discrete representations of molecules to and from a multidimensional continuous representation. This model allows us to generate new molecules for efficient exploration and optimization through open-ended spaces of chemical compounds. A deep neural network was trained on hundreds of thousands of existing chemical structures to construct three coupled functions: an encoder, a decoder, and a predictor. The encoder converts the discrete representation of a molecule into a real-valued continuous vector, and the decoder converts these continuous vectors back to discrete molecular representations. The predictor estimates chemical properties from the latent continuous vector representation of the molecule. Continuous representations of molecules allow us to automatically generate novel chemical structures by performing simple operations in the latent space, such as decoding random vectors, perturbing known chemical structures, or interpolating between molecules. Continuous representations also allow the use of powerful gradient-based optimization to efficiently guide the search for optimized functional compounds. We demonstrate our method in the domain of drug-like molecules and also in a set of molecules with fewer that nine heavy atoms.},
archivePrefix = {arXiv},
arxivId = {1610.02415},
author = {G{\'{o}}mez-Bombarelli, Rafael and Wei, Jennifer N. and Duvenaud, David and Hern{\'{a}}ndez-Lobato, Jos{\'{e}} Miguel and S{\'{a}}nchez-Lengeling, Benjam{\'{i}}n and Sheberla, Dennis and Aguilera-Iparraguirre, Jorge and Hirzel, Timothy D. and Adams, Ryan P. and Aspuru-Guzik, Al{\'{a}}n},
doi = {10.1021/acscentsci.7b00572},
eprint = {1610.02415},
file = {:U$\backslash$:/Literature/Paper/GomezBombarelli{\_}2018-Automatic Chemical Design Using a Data-Driven Continous Representation of Molecules.pdf:pdf},
issn = {23747951},
journal = {ACS Central Science},
mendeley-groups = {Machine Learning/GANs,Machine Learning/Autoencoder/Molecular VAEs},
number = {2},
pages = {268--276},
title = {{Automatic Chemical Design Using a Data-Driven Continuous Representation of Molecules}},
volume = {4},
year = {2018}
}

@article{Krenn2020,
abstract = {The discovery of novel materials and functional molecules can help to solve some of society's most urgent challenges, ranging from efficient energy harvesting and storage to uncovering novel pharmaceutical drug candidates. Traditionally matter engineering -- generally denoted as inverse design -- was based massively on human intuition and high-throughput virtual screening. The last few years have seen the emergence of significant interest in computer-inspired designs based on evolutionary or deep learning methods. The major challenge here is that the standard strings molecular representation SMILES shows substantial weaknesses in that task because large fractions of strings do not correspond to valid molecules. Here, we solve this problem at a fundamental level and introduce SELFIES (SELF-referencIng Embedded Strings), a string-based representation of molecules which is 100$\backslash${\%} robust. Every SELFIES string corresponds to a valid molecule, and SELFIES can represent every molecule. SELFIES can be directly applied in arbitrary machine learning models without the adaptation of the models; each of the generated molecule candidates is valid. In our experiments, the model's internal memory stores two orders of magnitude more diverse molecules than a similar test with SMILES. Furthermore, as all molecules are valid, it allows for explanation and interpretation of the internal working of the generative models.},
archivePrefix = {arXiv},
arxivId = {1905.13741},
author = {Krenn, Mario and Hase, Florian and Nigam, AkshatKumar and Friederich, Pascal and Aspuru-Guzik, Alan},
doi = {10.1088/2632-2153/aba947},
eprint = {1905.13741},
file = {:U$\backslash$:/Literature/Paper/Krenn{\_}2019-SELFIES{\_}a robust representation ofsemantically constrained graphswith an example application in chemistry.pdf:pdf;:U$\backslash$:/Literature/Paper/Krenn{\_}2020-Self-Referencing Embedded Strings (SELFIES){\_}A 100{\%} robustmolecular string representation.pdf:pdf},
journal = {Machine Learning: Science and Technology},
mendeley-groups = {Graph Neural Networks/Property prediction,Machine Learning/Autoencoder/Molecular VAEs},
title = {{Self-Referencing Embedded Strings (SELFIES): A 100{\%} robust molecular string representation}},
year = {2020}
}

@inproceedings{Kajino2019,
abstract = {Molecular optimization aims to discover novel molecules with desirable properties, and its two fundamental challenges are: (i) it is not trivial to generate valid molecules in a controllable way due to hard chemical constraints such as the valency conditions, and (ii) it is often costly to evaluate a property of a novel molecule, and therefore, the number of property evaluations is limited. These challenges are to some extent alleviated by a combination of a variational autoencoder (VAE) and Bayesian optimization (BO), where VAE converts a molecule into/from its latent continuous vector, and BO optimizes a latent continuous vector (and its corresponding molecule) within a limited number of property evaluations. While the most recent work, for the first time, achieved 100{\%} validity, its architecture is rather complex due to auxiliary neural networks other than VAE, making it difficult to train. This paper presents a molecular hypergraph grammar variational autoencoder (MHG-VAE), which uses a single VAE to achieve 100{\%} validity. Our idea is to develop a graph grammar encoding the hard chemical constraints, called molecular hypergraph grammar (MHG), which guides VAE to always generate valid molecules. We also present an algorithm to construct MHG from a set of molecules.},
address = {Long Beach, CA, USA},
author = {Kajino, Hiroshi},
file = {:U$\backslash$:/Literature/Paper/Kajino{\_}2019-Molecular Hypergraph Grammarwith Its Application to Molecular Optimization.pdf:pdf},
mendeley-groups = {Graph Neural Networks/Graph Autoencoder},
booktitle = {Proceedings of the 36th International Conference on Machine Learning},
pages = {3183--3191},
month = {09--15 June},
publisher = {PMLR},
series = {Proceedings of Machine Learning Research},
title = {{Molecular Hypergraph Grammar with Its Application to Molecular Optimization}},
url = {http://proceedings.mlr.press/v97/kajino19a.html},
volume = {97},
year = {2019}
}

 @InProceedings{pmlr-v97-kajino19a, title = {Molecular Hypergraph Grammar with Its Application to Molecular Optimization}, author = {Kajino, Hiroshi}, booktitle = {Proceedings of the 36th International Conference on Machine Learning}, pages = {3183--3191}, year = {2019}, editor = {Kamalika Chaudhuri and Ruslan Salakhutdinov}, volume = {97}, series = {Proceedings of Machine Learning Research}, address = {Long Beach, California, USA}, month = {09--15 Jun}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v97/kajino19a/kajino19a.pdf}, url = {http://proceedings.mlr.press/v97/kajino19a.html}, abstract = {Molecular optimization aims to discover novel molecules with desirable properties, and its two fundamental challenges are: (i) it is not trivial to generate valid molecules in a controllable way due to hard chemical constraints such as the valency conditions, and (ii) it is often costly to evaluate a property of a novel molecule, and therefore, the number of property evaluations is limited. These challenges are to some extent alleviated by a combination of a variational autoencoder (VAE) and Bayesian optimization (BO), where VAE converts a molecule into/from its latent continuous vector, and BO optimizes a latent continuous vector (and its corresponding molecule) within a limited number of property evaluations. While the most recent work, for the first time, achieved 100% validity, its architecture is rather complex due to auxiliary neural networks other than VAE, making it difficult to train. This paper presents a molecular hypergraph grammar variational autoencoder (MHG-VAE), which uses a single VAE to achieve 100% validity. Our idea is to develop a graph grammar encoding the hard chemical constraints, called molecular hypergraph grammar (MHG), which guides VAE to always generate valid molecules. We also present an algorithm to construct MHG from a set of molecules.} } 

@incollection{Goodfellow2014,
author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
booktitle = {Advances in Neural Information Processing Systems 27},
file = {:U$\backslash$:/Literature/Paper/Goodfellow{\_}2014-Generative Adversial Networks.pdf:pdf},
mendeley-groups = {Machine Learning/GANs},
pages = {2672--2680},
publisher = {Curran Associates, Inc.},
title = {{Generative Adversarial Nets}},
url = {http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf},
year = {2014}
}

@article{Schwalbe-Koda2020,
abstract = {Materials discovery is decisive for tackling urgent challenges related to energy, the environment, health care, and many others. In chemistry, conventional methodologies for innovation usually rely on expensive and incremental strategies to optimize properties from molecular structures. On the other hand, inverse approaches map properties to structures, thus expediting the design of novel useful compounds. In this chapter, we examine the way in which current deep generative models are addressing the inverse chemical discovery paradigm. We begin by revisiting early inverse design algorithms. Then, we introduce generative models for molecular systems and categorize them according to their architecture and molecular representation. Using this classification, we review the evolution and performance of important molecular generation schemes reported in the literature. Finally, we conclude highlighting the prospects and challenges of generative models as cutting edge tools in materials discovery.},
archivePrefix = {arXiv},
arxivId = {1907.01632},
author = {Schwalbe-Koda, Daniel and G{\'{o}}mez-Bombarelli, Rafael},
doi = {10.1007/978-3-030-40245-7_21},
eprint = {1907.01632},
file = {:U$\backslash$:/Literature/Paper/Schwalbe{\_}Koda{\_}2019-Generative Models for Automatic ChemicalDesign.pdf:pdf},
issn = {16166361},
journal = {Lecture Notes in Physics},
mendeley-groups = {Machine Learning/GANs},
pages = {445--467},
title = {{Generative Models for Automatic Chemical Design}},
volume = {968},
year = {2020}
}

@article{Sanchez-Lengeling2018,
abstract = {The discovery of newmaterials can bring enormous societal and technological progress. In this context, exploring completely the large space of potential materials is computationally intractable. Here, we review methods for achieving inverse design, which aims to discover tailored materials from the starting point of a particular desired functionality. Recent advances from the rapidly growing field of artificial intelligence, mostly from the subfield of machine learning, have resulted in a fertile exchange of ideas, where approaches to inverse molecular design are being proposed and employed at a rapid pace. Among these, deep generativemodels have been applied to numerous classes of materials: rational design of prospective drugs, synthetic routes to organic compounds, and optimization of photovoltaics and redox flow batteries, as well as a variety of other solid-state materials. 2017},
author = {Sanchez-Lengeling, Benjamin and Aspuru-Guzik, Alan},
doi = {10.1126/science.aat2663},
file = {:U$\backslash$:/Literature/Paper/SanchezLengeling{\_}AspuruGuzik{\_}2018-Inverse molecular design using machine learning{\_}Generative models for matter engineering.pdf:pdf},
issn = {10959203},
journal = {Science},
mendeley-groups = {Machine Learning/GANs},
number = {6400},
pages = {360--365},
pmid = {30049875},
title = {{Inverse molecular design using machine learning:Generative models for matter engineering}},
volume = {361},
year = {2018}
}

@article{Goodfellow2016,
abstract = {This report summarizes the tutorial presented by the author at NIPS 2016 on generative adversarial networks (GANs). The tutorial describes: (1) Why generative modeling is a topic worth studying, (2) how generative models work, and how GANs compare to other generative models, (3) the details of how GANs work, (4) research frontiers in GANs, and (5) state-of-the-art image models that combine GANs with other methods. Finally, the tutorial contains three exercises for readers to complete, and the solutions to these exercises.},
archivePrefix = {arXiv},
arxivId = {1701.00160},
author = {Goodfellow, Ian},
eprint = {1701.00160},
file = {:U$\backslash$:/Literature/Paper/Goodfellow{\_}2017-Generative Adversial Networks.pdf:pdf},
mendeley-groups = {Machine Learning/GANs},
title = {{NIPS 2016 Tutorial: Generative Adversarial Networks}},
url = {http://arxiv.org/abs/1701.00160},
year = {2016}
}

@article{Creswell2018,
abstract = {Generative adversarial networks (GANs) provide a way to learn deep representations without extensively annotated training data. They achieve this by deriving backpropagation signals through a competitive process involving a pair of networks. The representations that can be learned by GANs may be used in a variety of applications, including image synthesis, semantic image editing, style transfer, image superresolution, and classification. The aim of this review article is to provide an overview of GANs for the signal processing community, drawing on familiar analogies and concepts where possible. In addition to identifying different methods for training and constructing GANs, we also point to remaining challenges in their theory and application.},
archivePrefix = {arXiv},
arxivId = {1710.07035},
author = {Creswell, Antonia and White, Tom and Dumoulin, Vincent and Arulkumaran, Kai and Sengupta, Biswa and Bharath, Anil A.},
doi = {10.1109/MSP.2017.2765202},
eprint = {1710.07035},
file = {:U$\backslash$:/Literature/Paper/Creswell{\_}2018-Generative Adversial Networks{\_}An overview.pdf:pdf},
issn = {10535888},
journal = {IEEE Signal Processing Magazine},
mendeley-groups = {Machine Learning/GANs},
number = {1},
pages = {53--65},
publisher = {IEEE},
title = {{Generative Adversarial Networks: An Overview}},
volume = {35},
year = {2018}
}

@article{DeCao2018,
abstract = {Deep generative models for graph-structured data offer a new angle on the problem of chemical synthesis: by optimizing differentiable models that directly generate molecular graphs, it is possible to side-step expensive search procedures in the discrete and vast space of chemical structures. We introduce MolGAN, an implicit, likelihood-free generative model for small molecular graphs that circumvents the need for expensive graph matching procedures or node ordering heuristics of previous likelihood-based methods. Our method adapts generative adversarial networks (GANs) to operate directly on graph-structured data. We combine our approach with a reinforcement learning objective to encourage the generation of molecules with specific desired chemical properties. In experiments on the QM9 chemical database, we demonstrate that our model is capable of generating close to 100{\%} valid compounds. MolGAN compares favorably both to recent proposals that use string-based (SMILES) representations of molecules and to a likelihood-based method that directly generates graphs, albeit being susceptible to mode collapse.},
archivePrefix = {arXiv},
arxivId = {1805.11973},
author = {{De Cao}, Nicola and Kipf, Thomas},
eprint = {1805.11973},
file = {:U$\backslash$:/Literature/Paper/DeCao{\_}2018-MolGAN{\_}An implicit generative model for small molecular graphs.pdf:pdf},
journal = {arXiv preprint arXiv:1805.11973},
mendeley-groups = {Machine Learning/GANs,Machine Learning/GANs/Molecular GANs},
title = {{MolGAN: An implicit generative model for small molecular graphs}},
url = {http://arxiv.org/abs/1805.11973},
year = {2018}
}


@article{Kadurin2017,
abstract = {Deep generative adversarial networks (GANs) are the emerging technology in drug discovery and biomarker development. In our recent work, we demonstrated a proof-of-concept of implementing deep generative adversarial autoencoder (AAE) to identify new molecular fingerprints with predefined anticancer properties. Another popular generative model is the variational autoencoder (VAE), which is based on deep neural architectures. In this work, we developed an advanced AAE model for molecular feature extraction problems, and demonstrated its advantages compared to VAE in terms of (a) adjustability in generating molecular fingerprints; (b) capacity of processing very large molecular data sets; and (c) efficiency in unsupervised pretraining for regression model. Our results suggest that the proposed AAE model significantly enhances the capacity and efficiency of development of the new molecules with specific anticancer properties using the deep generative models.},
author = {Kadurin, Artur and Nikolenko, Sergey and Khrabrov, Kuzma and Aliper, Alex and Zhavoronkov, Alex},
doi = {10.1021/acs.molpharmaceut.7b00346},
file = {:U$\backslash$:/Literature/Paper/Kadurin{\_}2017-druGAN{\_}An Advanced Generative Adversarial Autoencoder Modelfor de Novo Generation of New Molecules with Desired MolecularPr.pdf:pdf},
issn = {15438392},
journal = {Molecular Pharmaceutics},
keywords = {adversarial autoencoder,deep learning,drug discovery,generative adversarial network,variational autoencoder},
mendeley-groups = {Machine Learning/GANs},
number = {9},
pages = {3098--3104},
pmid = {28703000},
title = {{DruGAN: An Advanced Generative Adversarial Autoencoder Model for de Novo Generation of New Molecules with Desired Molecular Properties in Silico}},
volume = {14},
year = {2017}
}

@misc{Guimaraes2018,
archivePrefix = {arXiv},
arxivId = {stat.ML/1705.10843},
author = {Guimaraes, Gabriel Lima and Sanchez-Lengeling, Benjamin and Outeiral, Carlos and Farias, Pedro Luis Cunha and Aspuru-Guzik, Al{\'{a}}n},
eprint = {1705.10843},
file = {:U$\backslash$:/Literature/Paper/Guimaraes{\_}2017-Objective-Reinforced Generative Adversarial Networks (ORGAN) for SequenceGeneration Models.pdf:pdf},
mendeley-groups = {Machine Learning/GANs},
primaryClass = {stat.ML},
title = {{Objective-Reinforced Generative Adversarial Networks (ORGAN) for Sequence Generation Models}},
year = {2018}
}

@incollection{Salimans2016,
author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi and Chen, Xi},
booktitle = {Advances in Neural Information Processing Systems 29},
file = {:U$\backslash$:/Literature/Paper/Salimans{\_}2016-Improved Techniques for Training GANs.pdf:pdf},
mendeley-groups = {Machine Learning/GANs},
pages = {2234--2242},
publisher = {Curran Associates, Inc.},
title = {{Improved Techniques for Training GANs}},
url = {http://papers.nips.cc/paper/6125-improved-techniques-for-training-gans.pdf},
year = {2016}
}

@article{Vanhaelen2020,
annote = {doi: 10.1021/acsmedchemlett.0c00088},
author = {Vanhaelen, Quentin and Lin, Yen-Chu and Zhavoronkov, Alex},
doi = {10.1021/acsmedchemlett.0c00088},
file = {:U$\backslash$:/Literature/Paper/Vanhaelen{\_}2020-The Advent of Generative Chemistry.pdf:pdf},
journal = {ACS Medicinal Chemistry Letters},
mendeley-groups = {Machine Learning/GANs},
month = {aug},
number = {8},
pages = {1496--1505},
publisher = {American Chemical Society},
title = {{The Advent of Generative Chemistry}},
url = {https://doi.org/10.1021/acsmedchemlett.0c00088},
volume = {11},
year = {2020}
}

@article{Blaschke2018,
abstract = {Abstract A major challenge in computational chemistry is the generation of novel molecular structures with desirable pharmacological and physiochemical properties. In this work, we investigate the potential use of autoencoder, a deep learning methodology, for de novo molecular design. Various generative autoencoders were used to map molecule structures into a continuous latent space and vice versa and their performance as structure generator was assessed. Our results show that the latent space preserves chemical similarity principle and thus can be used for the generation of analogue structures. Furthermore, the latent space created by autoencoders were searched systematically to generate novel compounds with predicted activity against dopamine receptor type?2 and compounds similar to known active compounds not included in the trainings set were identified.},
annote = {doi: 10.1002/minf.201700123},
author = {Blaschke, Thomas and Olivecrona, Marcus and Engkvist, Ola and Bajorath, J{\"{u}}rgen and Chen, Hongming},
doi = {10.1002/minf.201700123},
file = {:U$\backslash$:/Literature/Paper/Blaschke{\_}2017-Application of Generative Autoencoder in De Novo Molecular Design.pdf:pdf},
issn = {1868-1743},
journal = {Molecular Informatics},
keywords = {Autoencoder,chemoinformatics,de novo molecular design,deep learning,inverse QSAR},
month = {Jan.},
number = {1-2},
pages = {1700123},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{Application of Generative Autoencoder in De Novo Molecular Design}},
url = {https://doi.org/10.1002/minf.201700123},
volume = {37},
year = {2018}
}

@article{Li2018,
abstract = {Recently, deep generative models have revealed itself as a promising way of performing de novo molecule design. However, previous research has focused mainly on generating SMILES strings instead of molecular graphs. Although available, current graph generative models are are often too general and computationally expensive. In this work, a new de novo molecular design framework is proposed based on a type of sequential graph generators that do not use atom level recurrent units. Compared with previous graph generative models, the proposed method is much more tuned for molecule generation and has been scaled up to cover significantly larger molecules in the ChEMBL database. It is shown that the graph-based model outperforms SMILES based models in a variety of metrics, especially in the rate of valid outputs. For the application of drug design tasks, conditional graph generative model is employed. This method offers highe flexibility and is suitable for generation based on multiple objectives. The results have demonstrated that this approach can be effectively applied to solve several drug design problems, including the generation of compounds containing a given scaffold, compounds with specific drug-likeness and synthetic accessibility requirements, as well as dual inhibitors against JNK3 and GSK-3$\beta$.},
archivePrefix = {arXiv},
arxivId = {arXiv:1801.07299v3},
author = {Li, Yibo and Zhang, Liangren and Liu, Zhenming},
doi = {10.1186/s13321-018-0287-6},
eprint = {arXiv:1801.07299v3},
file = {:U$\backslash$:/Literature/Paper/Li{\_}2018-Multi-Objective De Novo Drug Design with Conditional Graph Genrative Model.pdf:pdf},
issn = {17582946},
journal = {Journal of Cheminformatics},
keywords = {De novo drug design,Deep learning,Graph generative model},
mendeley-groups = {Machine Learning/GANs},
number = {1},
title = {{Multi-objective de novo drug design with conditional graph generative model}},
volume = {10},
year = {2018}
}

@article{Zhou2019,
abstract = {We present a framework, which we call Molecule Deep Q-Networks (MolDQN), for molecule optimization by combining domain knowledge of chemistry and state-of-the-art reinforcement learning techniques (double Q-learning and randomized value functions). We directly define modifications on molecules, thereby ensuring 100{\%} chemical validity. Further, we operate without pre-training on any dataset to avoid possible bias from the choice of that set. MolDQN achieves comparable or better performance against several other recently published algorithms for benchmark molecular optimization tasks. However, we also argue that many of these tasks are not representative of real optimization problems in drug discovery. Inspired by problems faced during medicinal chemistry lead optimization, we extend our model with multi-objective reinforcement learning, which maximizes drug-likeness while maintaining similarity to the original molecule. We further show the path through chemical space to achieve optimization for a molecule to understand how the model works.},
author = {Zhou, Zhenpeng and Kearnes, Steven and Li, Li and Zare, Richard N and Riley, Patrick},
doi = {10.1038/s41598-019-47148-x},
file = {:U$\backslash$:/Literature/Paper/Zhou{\_}2019-Optimization of Molecules via Deep Reinforcement Learning.pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
mendeley-groups = {Machine Learning/Reinforcement Learning/Molecular RL},
number = {1},
pages = {10752},
title = {{Optimization of Molecules via Deep Reinforcement Learning}},
url = {https://doi.org/10.1038/s41598-019-47148-x},
volume = {9},
year = {2019}
}

@article{Fare2020,
abstract = {Chemical representations derived from deep learning are emerging as a powerful tool in areas such as drug discovery and materials innovation. Currently, this methodology has three major limitations-the cost of representation generation, risk of inherited bias, and the requirement for large amounts of data. We propose the use of multi-task learning in tandem with transfer learning to address these limitations directly. In order to avoid introducing unknown bias into multi-task learning through the task selection itself, we calculate task similarity through pairwise task affinity, and use this measure to programmatically select tasks. We test this methodology on several real-world data sets to demonstrate its potential for execution in complex and low-data environments. Finally, we utilise the task similarity to further probe the expressiveness of the learned representation through a comparison to a commonly used cheminformatics fingerprint, and show that the deep representation is able to capture more expressive task-based information.},
archivePrefix = {arXiv},
arxivId = {1809.06334},
author = {Fare, Clyde and Turcani, Lukas and Pyzer-Knapp, Edward O.},
doi = {10.1039/d0cp02319a},
eprint = {1809.06334},
file = {:U$\backslash$:/Literature/Paper/Fare{\_}2020-Powerful, transferable representations formolecules through intelligent task selection indeep multitask networks.pdf:pdf},
issn = {14639076},
journal = {Physical Chemistry Chemical Physics},
mendeley-groups = {Machine Learning/Transfer Learning},
number = {23},
pages = {13041--13048},
pmid = {32478374},
publisher = {Royal Society of Chemistry},
title = {{Powerful, transferable representations for molecules through intelligent task selection in deep multitask networks}},
volume = {22},
year = {2020}
}

@misc{sanchezlengeling2019,
archivePrefix = {arXiv},
arxivId = {stat.ML/1910.10685},
author = {Sanchez-Lengeling, Benjamin and Wei, Jennifer N and Lee, Brian K and Gerkin, Richard C and Aspuru-Guzik, Al{\'{a}}n and Wiltschko, Alexander B},
eprint = {1910.10685},
file = {:U$\backslash$:/Literature/Paper/Sanchez-Lengeling{\_}2019-Machine Learning for Scent{\_}Learning GeneralizablePerceptual Representations of Small Molecules.pdf:pdf},
mendeley-groups = {Machine Learning/Transfer Learning},
primaryClass = {stat.ML},
title = {{Machine Learning for Scent: Learning Generalizable Perceptual Representations of Small Molecules}},
year = {2019}
}

@article{Yoshimori2020,
abstract = {The goal of drug design is to discover molecular structures that have suitable pharmacological properties in vast chemical space. In recent years, the use of deep generative models (DGMs) is getting a lot of attention as an effective method of generating new molecules with desired properties. However, most of the properties do not have three-dimensional (3D) information, such as shape and pharmacophore. In drug discovery, pharmacophores are valuable clues in finding active compounds. In this study, we propose a computational strategy based on deep reinforcement learning for generating molecular structures with a desired pharmacophore. In addition, to extract selective molecules against a target protein, chemical genomics-based virtual screening (CGBVS) is used as post-processing method of deep reinforcement learning. As an example study, we have employed this strategy to generate molecular structures of selective TIE2 inhibitors. This strategy can be adopted into general use for generating selective molecules with a desired pharmacophore.},
author = {Yoshimori, Atsushi and Kawasaki, Enzo and Kanai, Chisato and Tasaka, Tomohiko},
doi = {10.1248/cpb.c19-00625},
file = {:U$\backslash$:/Literature/Paper/Yoshimoro{\_}2020-Strategies for Design of Molecular Structures with a Desired Pharmacophore Using Deep Reinforcement Learning.pdf:pdf},
issn = {13475223},
journal = {Chemical {\&} Pharmaceutical Bulletin},
keywords = {chemical genomics-based virtual screening,de novo design,deep reinforcement learning,pharmacophore model,selective kinase inhibitor},
mendeley-groups = {Machine Learning/Reinforcement Learning/Molecular RL},
number = {3},
pages = {227--233},
pmid = {32115529},
title = {{Strategies for Design of Molecular Structures with a Desired Pharmacophore Using Deep Reinforcement Learning}},
volume = {68},
year = {2020}
}

@misc{simm2020,
archivePrefix = {arXiv},
arxivId = {stat.ML/2002.07717},
author = {Simm, Gregor N C and Pinsler, Robert and Hern{\'{a}}ndez-Lobato, Jos{\'{e}} Miguel},
eprint = {2002.07717},
file = {:U$\backslash$:/Literature/Paper/Simm{\_}2020-Reinforcement Learning for Molecular Design Guided by Quantum Mechanics.pdf:pdf},
mendeley-groups = {Machine Learning/Reinforcement Learning/Molecular RL},
primaryClass = {stat.ML},
title = {{Reinforcement Learning for Molecular Design Guided by Quantum Mechanics}},
year = {2020}
}

@article{Samanta2020,
abstract = {Molecular similarity is an elusive but core “unsupervised” cheminformatics concept, yet different “fingerprint” encodings of molecular structures return very different similarity values, even when using the same similarity metric. Each encoding may be of value when applied to other problems with objective or target functions, implying that a priori none are “better” than the others, nor than encoding-free metrics such as maximum common substructure (MCSS). We here introduce a novel approach to molecular similarity, in the form of a variational autoencoder (VAE). This learns the joint distribution p(z|x) where z is a latent vector and x are the (same) input/output data. It takes the form of a “bowtie”-shaped artificial neural network. In the middle is a “bottleneck layer” or latent vector in which inputs are transformed into, and represented as, a vector of numbers (encoding), with a reverse process (decoding) seeking to return the SMILES string that was the input. We train a VAE on over six million druglike molecules and natural products (including over one million in the final holdout set). The VAE vector distances provide a rapid and novel metric for molecular similarity that is both easily and rapidly calculated. We describe the method and its application to a typical similarity problem in cheminformatics.},
author = {Samanta, Soumitra and O'Hagan, Steve and Swainston, Neil and Roberts, Timothy J. and Kell, Douglas B.},
doi = {10.3390/molecules25153446},
file = {:U$\backslash$:/Literature/Paper/Samanta{\_}2020-VAE-Sim{\_}A Novel Molecular Similarity Measure Based on a Variational Autoencoder.pdf:pdf},
issn = {14203049},
journal = {Molecules},
keywords = {Cheminformatics,Deep learning,Molecular similarity,SMILES,Variational autoencoder},
mendeley-groups = {Graph Neural Networks/Graph similarity},
number = {15},
pmid = {32751155},
title = {{VAE-Sim: A Novel Molecular Similarity Measure Based on a Variational Autoencoder}},
volume = {25},
year = {2020}
}

@article{Chen2018,
abstract = {Over the past decade, deep learning has achieved remarkable success in various artificial intelligence research areas. Evolved from the previous research on artificial neural networks, this technology has shown superior performance to other machine learning algorithms in areas such as image and voice recognition, natural language processing, among others. The first wave of applications of deep learning in pharmaceutical research has emerged in recent years, and its utility has gone beyond bioactivity predictions and has shown promise in addressing diverse problems in drug discovery. Examples will be discussed covering bioactivity prediction, de novo molecular design, synthesis prediction and biological image analysis.},
author = {Chen, Hongming and Engkvist, Ola and Wang, Yinhai and Olivecrona, Marcus and Blaschke, Thomas},
doi = {10.1016/j.drudis.2018.01.039},
file = {:U$\backslash$:/Literature/Paper/Chen{\_}2018-The rise of deep learning in drug discovery.pdf:pdf},
issn = {18785832},
journal = {Drug Discovery Today},
mendeley-groups = {Machine Learning/ML in PSE},
number = {6},
pages = {1241--1250},
pmid = {29366762},
publisher = {Elsevier Ltd},
title = {{The rise of deep learning in drug discovery}},
url = {https://doi.org/10.1016/j.drudis.2018.01.039},
volume = {23},
year = {2018}
}

@article{Elton2019,
abstract = {In the space of only a few years, deep generative modeling has revolutionized how we think of artificial creativity, yielding autonomous systems which produce original images, music, and text. Inspired by these successes, researchers are now applying deep generative modeling techniques to the generation and optimization of molecules - in our review we found 45 papers on the subject published in the past two years. These works point to a future where such systems will be used to generate lead molecules, greatly reducing resources spent downstream synthesizing and characterizing bad leads in the lab. In this review we survey the increasingly complex landscape of models and representation schemes that have been proposed. The four classes of techniques we describe are recursive neural networks, autoencoders, generative adversarial networks, and reinforcement learning. After first discussing some of the mathematical fundamentals of each technique, we draw high level connections and comparisons with other techniques and expose the pros and cons of each. Several important high level themes emerge as a result of this work, including the shift away from the SMILES string representation of molecules towards more sophisticated representations such as graph grammars and 3D representations, the importance of reward function design, the need for better standards for benchmarking and testing, and the benefits of adversarial training and reinforcement learning over maximum likelihood based training.},
archivePrefix = {arXiv},
arxivId = {1903.04388},
author = {Elton, Daniel C. and Boukouvalas, Zois and Fuge, Mark D. and Chung, Peter W.},
doi = {10.1039/c9me00039a},
eprint = {1903.04388},
file = {:U$\backslash$:/Literature/Paper/Elton{\_}2019-Deep learning for molecular design{\_}a review of the state of the art.pdf:pdf},
issn = {20589689},
journal = {Molecular Systems Design and Engineering},
mendeley-groups = {Machine Learning/ML in PSE},
number = {4},
pages = {828--849},
publisher = {Royal Society of Chemistry},
title = {{Deep learning for molecular design - A review of the state of the art}},
volume = {4},
year = {2019}
}

@article{Prykhodko2019,
abstract = {Deep learning methods applied to drug discovery have been used to generate novel structures. In this study, we propose a new deep learning architecture, LatentGAN, which combines an autoencoder and a generative adversarial neural network for de novo molecular design. We applied the method in two scenarios: One to generate random drug-like compounds and another to generate target-biased compounds. Our results show that the method works well in both cases. Sampled compounds from the trained model can largely occupy the same chemical space as the training set and also generate a substantial fraction of novel compounds. Moreover, the drug-likeness score of compounds sampled from LatentGAN is also similar to that of the training set. Lastly, generated compounds differ from those obtained with a Recurrent Neural Network-based generative model approach, indicating that both methods can be used complementarily.[Figure not available: See fulltext.]},
author = {Prykhodko, Oleksii and Johansson, Simon Viet and Kotsias, Panagiotis Christos and Ar{\'{u}}s-Pous, Josep and Bjerrum, Esben Jannik and Engkvist, Ola and Chen, Hongming},
doi = {10.1186/s13321-019-0397-9},
file = {:U$\backslash$:/Literature/Paper/Prykhodko{\_}2019-A de novo molecular generation method using latent vector based generative adversarial network .pdf:pdf},
issn = {17582946},
journal = {Journal of Cheminformatics},
keywords = {Autoencoder networks,Deep learning,Generative adversarial networks,Molecular design},
mendeley-groups = {Machine Learning/Autoencoder/Molecular VAEs},
number = {1},
pages = {1--13},
publisher = {Springer International Publishing},
title = {{A de novo molecular generation method using latent vector based generative adversarial network}},
url = {https://doi.org/10.1186/s13321-019-0397-9},
volume = {11},
year = {2019}
}

@article{Bjerrum2018,
abstract = {Chemical autoencoders are attractive models as they combine chemical space navigation with possibilities for de novo molecule generation in areas of interest. This enables them to produce focused chemical libraries around a single lead compound for employment early in a drug discovery project. Here, it is shown that the choice of chemical representation, such as strings from the simplified molecular-input line-entry system (SMILES), has a large influence on the properties of the latent space. It is further explored to what extent translating between different chemical representations influences the latent space similarity to the SMILES strings or circular fingerprints. By employing SMILES enumeration for either the encoder or decoder, it is found that the decoder has the largest influence on the properties of the latent space. Training a sequence to sequence heteroencoder based on recurrent neural networks (RNNs) with long short-term memory cells (LSTM) to predict different enumerated SMILES strings from the same canonical SMILES string gives the largest similarity between latent space distance and molecular similarity measured as circular fingerprints similarity. Using the output from the code layer in quantitative structure activity relationship (QSAR) of five molecular datasets shows that heteroencoder derived vectors markedly outperforms autoencoder derived vectors as well as models built using ECFP4 fingerprints, underlining the increased chemical relevance of the latent space. However, the use of enumeration during training of the decoder leads to a marked increase in the rate of decoding to different molecules than encoded, a tendency that can be counteracted with more complex network architectures.},
archivePrefix = {arXiv},
arxivId = {1806.09300},
author = {Bjerrum, Esben Jannik and Sattarov, Boris},
doi = {10.3390/biom8040131},
eprint = {1806.09300},
file = {:U$\backslash$:/Literature/Paper/Bjerrum{\_}2018-Improving Chemical Autoencoder Latent Space and Molecular De Novo Generation Diversity with Heteroencoders.pdf:pdf},
issn = {2218273X},
journal = {Biomolecules},
keywords = {De novo molecule design,Deep learning,LSTM,Molecular autoencoders,Molecular data augmentation,Molecular heteroencoders,RNN},
mendeley-groups = {Machine Learning/Autoencoder/Molecular VAEs},
number = {4},
pages = {1--17},
pmid = {30380783},
title = {{Improving chemical autoencoder latent space and molecular de novo generation diversity with heteroencoders}},
volume = {8},
year = {2018}
}

@article{Lim2018,
abstract = {We propose a molecular generative model based on the conditional variational autoencoder for de novo molecular design. It is specialized to control multiple molecular properties simultaneously by imposing them on a latent space. As a proof of concept, we demonstrate that it can be used to generate drug-like molecules with five target properties. We were also able to adjust a single property without changing the others and to manipulate it beyond the range of the dataset.},
author = {Lim, Jaechang and Ryu, Seongok and Kim, Jin Woo and Kim, Woo Youn},
doi = {10.1186/s13321-018-0286-7},
file = {:U$\backslash$:/Literature/Paper/Lim{\_}2018-Molecular generative model based on conditional variational autoencoder for de novo molecular design.pdf:pdf},
issn = {1758-2946},
journal = {Journal of Cheminformatics},
mendeley-groups = {Machine Learning/Autoencoder/Molecular VAEs},
number = {1},
pages = {31},
title = {{Molecular generative model based on conditional variational autoencoder for de novo molecular design}},
url = {https://doi.org/10.1186/s13321-018-0286-7},
volume = {10},
year = {2018}
}

@article{Griffiths2020,
abstract = {Automatic Chemical Design is a framework for generating novel molecules with optimized properties. The original scheme, featuring Bayesian optimization over the latent space of a variational autoencoder, suffers from the pathology that it tends to produce invalid molecular structures. First, we demonstrate empirically that this pathology arises when the Bayesian optimization scheme queries latent space points far away from the data on which the variational autoencoder has been trained. Secondly, by reformulating the search procedure as a constrained Bayesian optimization problem, we show that the effects of this pathology can be mitigated, yielding marked improvements in the validity of the generated molecules. We posit that constrained Bayesian optimization is a good approach for solving this kind of training set mismatch in many generative tasks involving Bayesian optimization over the latent space of a variational autoencoder.},
author = {Griffiths, Ryan Rhys and Hern{\'{a}}ndez-Lobato, Jos{\'{e}} Miguel},
doi = {10.1039/c9sc04026a},
file = {:U$\backslash$:/Literature/Paper/Griffiths{\_}2019-Constrained Bayesian optimization for automaticchemical design using variational autoencoders.pdf:pdf},
issn = {20416539},
journal = {Chemical Science},
mendeley-groups = {Machine Learning/Autoencoder/Molecular VAEs},
number = {2},
pages = {577--586},
title = {{Constrained Bayesian optimization for automatic chemical design using variational autoencoders}},
volume = {11},
year = {2020}
}

@article{Scarselli2009,
abstract = {In this paper, we will consider the approximation properties of a recently introduced neural network model called graph neural network (GNN), which can be used to process-structured data inputs, e.g., acyclic graphs, cyclic graphs, and directed or undirected graphs. This class of neural networks implements a function $\tau$(G,n) ∈ Rm that maps a graph G and one of its nodes n onto an m-dimensional Euclidean space. We characterize the functions that can be approximated by GNNs, in probability, up to any prescribed degree of precision. This set contains the maps that satisfy a property called preservation of the unfolding equivalence, and includes most of the practically useful functions on graphs; the only known exception is when the input graph contains particular patterns of symmetries when unfolding equivalence may not be preserved. The result can be considered an extension of the universal approximation property established for the classic feedforward neural networks (FNNs). Some experimental examples are used to show the computational capabilities of the proposed model. {\textcopyright} 2008 IEEE.},
author = {Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele},
doi = {10.1109/TNN.2008.2005141},
file = {:U$\backslash$:/Literature/Paper/Scarselli{\_}2009-Computational Capabilities of GraphNeural Networks.pdf:pdf},
issn = {10459227},
journal = {IEEE Transactions on Neural Networks},
keywords = {Approximation theory,Graph neural networks (GNNs),Graphical domains,Universal approximators},
mendeley-groups = {Graph Neural Networks/Basics,Graph Neural Networks},
number = {1},
pages = {81--102},
pmid = {19129034},
title = {{Computational capabilities of graph neural networks}},
volume = {20},
year = {2009}
}

@article{Gori2005,
abstract = {In several applications the information is naturally represented by graphs. Traditinal approaches cope with graphical data structures using a preprocessing phase which transforms the graphs into a set of flat vectors. However, in the way, important topological information may be lost and the achieved results may heavily depend on the preprocessing stage. This paper presents a new neural model, called graph neural network (GNN), capable of directly processing graphs. GNNs extends recursive neural networks and can be applied on most of the practically useful kinds of graphs, including directed, undirected, labelled and cyclic graphs. A learning algorithm for GNNs is proposed and some experiments are discussed which assess the properties of the model. {\textcopyright} 2005 IEEE.},
author = {Gori, Marco and Monfardini, Gabriele and Scarselli, Franco},
doi = {10.1109/IJCNN.2005.1555942},
file = {:U$\backslash$:/Literature/Paper/Gori{\_}2005-A new model for learning in graph domains.pdf:pdf},
isbn = {0780390482},
journal = {Proceedings of the International Joint Conference on Neural Networks},
mendeley-groups = {Graph Neural Networks/Basics},
pages = {729--734},
publisher = {IEEE},
title = {{A new model for earning in graph domains}},
volume = {2},
year = {2005}
}

@article{Sperduti1997,
abstract = {Standard neural networks and statistical methods are usually believed to be inadequate when dealing with complex structures because of their feature-based approach. In fact, feature-based approaches usually fail to give satisfactory solutions because of the sensitivity of the approach to the a priori selection of the features, and the incapacity to represent any specific information on the relationships among the components of the structures. However, we show that neural networks can, in fact, represent and classify structured patterns. The key idea underpinning our approach is the use of the so called "generalized recursive neuron", which is essentially a generalization to structures of a recurrent neuron. By using generalized recursive neurons, all the supervised networks developed for the classification of sequences, such as backpropagation through time networks, real-time recurrent networks, simple recurrent networks, recurrent cascade correlation networks, and neural trees can, on the whole, be generalized to structures. The results obtained by some of the above networks (with generalized recursive neurons) on the classification of logic terms are presented.},
author = {Sperduti, A and Starita, A},
doi = {10.1109/72.572108},
file = {:U$\backslash$:/Literature/Paper/Spertudi{\_}1997-Supervised neural networks for the classifcation of.pdf:pdf},
issn = {1941-0093 VO - 8},
journal = {IEEE Transactions on Neural Networks},
keywords = {Application software,Backpropagation,Medical diagnostic imaging,Neural networks,Neurons,Robustness,Sequences,Speech analysis,Speech processing,Tree graphs,backpropagation,cascade correlation,correlation methods,encoding,generalization,gradient methods,graph theory,learning (artificial intelligence),learning systems,neural trees,pattern classification,recurrent neural nets,recurrent neural networks,recursive neurons,structured pattern classification,supervised neural networks,trees (mathematics)},
mendeley-groups = {Graph Neural Networks/Basics},
number = {3},
pages = {714--735},
title = {{Supervised neural networks for the classification of structures}},
volume = {8},
year = {1997}
}

@article{Schutt2018,
abstract = {Deep learning has led to a paradigm shift in artificial intelligence, including web, text, and image search, speech recognition, as well as bioinformatics, with growing impact in chemical physics. Machine learning, in general, and deep learning, in particular, are ideally suitable for representing quantum-mechanical interactions, enabling us to model nonlinear potential-energy surfaces or enhancing the exploration of chemical compound space. Here we present the deep learning architecture SchNet that is specifically designed to model atomistic systems by making use of continuous-filter convolutional layers. We demonstrate the capabilities of SchNet by accurately predicting a range of properties across chemical space for molecules and materials, where our model learns chemically plausible embeddings of atom types across the periodic table. Finally, we employ SchNet to predict potential-energy surfaces and energy-conserving force fields for molecular dynamics simulations of small molecules and perform an exemplary study on the quantum-mechanical properties of C20-fullerene that would have been infeasible with regular ab initio molecular dynamics.},
archivePrefix = {arXiv},
arxivId = {1712.06113},
author = {Sch{\"{u}}tt, K. T. and Sauceda, H. E. and Kindermans, P. J. and Tkatchenko, A. and M{\"{u}}ller, K. R.},
doi = {10.1063/1.5019779},
eprint = {1712.06113},
file = {:U$\backslash$:/Literature/Paper/Sch{\"{u}}tt{\_}2018-SchNet – a deep learning architecture for molecules and materials.pdf:pdf},
issn = {00219606},
journal = {Journal of Chemical Physics},
mendeley-groups = {Graph Neural Networks/Readout,Graph Neural Networks/Property prediction},
number = {24},
pages = {1--11},
pmid = {29960322},
title = {{SchNet - A deep learning architecture for molecules and materials}},
volume = {148},
year = {2018}
}

@article{Ramakrishnan2014,
abstract = {Computational de novo design of new drugs and materials requires rigorous and unbiased exploration of chemical compound space. However, large uncharted territories persist due to its size scaling combinatorially with molecular size. We report computed geometric, energetic, electronic, and thermodynamic properties for 134k stable small organic molecules made up of CHONF. These molecules correspond to the subset of all 133,885 species with up to nine heavy atoms (CONF) out of the GDB-17 chemical universe of 166 billion organic molecules. We report geometries minimal in energy, corresponding harmonic frequencies, dipole moments, polarizabilities, along with energies, enthalpies, and free energies of atomization. All properties were calculated at the B3LYP/6-31G(2df,p) level of quantum chemistry. Furthermore, for the predominant stoichiometry, C7H10O2, there are 6,095 constitutional isomers among the 134k molecules. We report energies, enthalpies, and free energies of atomization at the more accurate G4MP2 level of theory for all of them. As such, this data set provides quantum chemical properties for a relevant, consistent, and comprehensive chemical space of small organic molecules. This database may serve the benchmarking of existing methods, development of new methods, such as hybrid quantum mechanics/machine learning, and systematic identification of structure-property relationships.},
author = {Ramakrishnan, Raghunathan and Dral, Pavlo O and Rupp, Matthias and von Lilienfeld, O Anatole},
doi = {10.1038/sdata.2014.22},
file = {:U$\backslash$:/Literature/Paper/Ramakrishnan{\_}2014-Quantum chemistry structures and properties of 134 kilo molecules.pdf:pdf},
issn = {2052-4463},
journal = {Scientific Data},
mendeley-groups = {Datasets},
number = {1},
pages = {140022},
title = {{Quantum chemistry structures and properties of 134 kilo molecules}},
url = {https://doi.org/10.1038/sdata.2014.22},
volume = {1},
year = {2014}
}

@article{Ruddigkeit2012,
annote = {doi: 10.1021/ci300415d},
author = {Ruddigkeit, Lars and van Deursen, Ruud and Blum, Lorenz C and Reymond, Jean-Louis},
doi = {10.1021/ci300415d},
file = {:U$\backslash$:/Literature/Paper/Ruedigkeit{\_}2012-Enumeration of 166 Billion Organic Small Molecules in the Chemical Universe Database GDB17.pdf:pdf},
issn = {1549-9596},
journal = {Journal of Chemical Information and Modeling},
mendeley-groups = {Datasets},
month = {Nov.},
number = {11},
pages = {2864--2875},
publisher = {American Chemical Society},
title = {{Enumeration of 166 Billion Organic Small Molecules in the Chemical Universe Database GDB-17}},
url = {https://doi.org/10.1021/ci300415d},
volume = {52},
year = {2012}
}

@article{Cozad2018,
abstract = {Symbolic regression methods generate expression trees that simultaneously define the functional form of a regression model and the regression parameter values. As a result, the regression problem can search many nonlinear functional forms using only the specification of simple mathematical operators such as addition, subtraction, multiplication, and division, among others. Currently, state-of-the-art symbolic regression methods leverage genetic algorithms and adaptive programming techniques. Genetic algorithms lack optimality certifications and are typically stochastic in nature. In contrast, we propose an optimization formulation for the rigorous deterministic optimization of the symbolic regression problem. We present a mixed-integer nonlinear programming (MINLP) formulation to solve the symbolic regression problem as well as several alternative models to eliminate redundancies and symmetries. We demonstrate this symbolic regression technique using an array of experiments based upon literature instances. We then use a set of 24 MINLPs from symbolic regression to compare the performance of five local and five global MINLP solvers. Finally, we use larger instances to demonstrate that a portfolio of models provides an effective solution mechanism for problems of the size typically addressed in the symbolic regression literature.},
author = {Cozad, Alison and Sahinidis, Nikolaos V.},
doi = {10.1007/s10107-018-1289-x},
file = {:U$\backslash$:/Literature/Paper/Cozad{\_}Sahinidis{\_}2018{\_}{\_}A Global MINLP Approach To Symbolic Regression.pdf:pdf},
issn = {14364646},
journal = {Mathematical Programming},
keywords = {Global optimization,Integer nonlinear optimization,Machine learning,Symbolic regression},
mendeley-groups = {Machine Learning/Symbolic regression},
number = {1},
pages = {97--119},
publisher = {Springer Berlin Heidelberg},
title = {{A global MINLP approach to symbolic regression}},
url = {https://doi.org/10.1007/s10107-018-1289-x},
volume = {170},
year = {2018}
}

@article{Wilson2017,
abstract = {ALAMO is a computational methodology for learning algebraic functions from data. Given a data set, the approach begins by building a low-complexity, linear model composed of explicit non-linear transformations of the independent variables. Linear combinations of these non-linear transformations allow a linear model to better approximate complex behavior observed in real processes. The model is refined, as additional data are obtained in an adaptive fashion through error maximization sampling using derivative-free optimization. Models built using ALAMO can enforce constraints on the response variables to incorporate first-principles knowledge. The ability of ALAMO to generate simple and accurate models for a number of reaction problems is demonstrated. The error maximization sampling is compared with Latin hypercube designs to demonstrate its sampling efficiency. ALAMO's constrained regression methodology is used to further refine concentration models, resulting in models that perform better on validation data and satisfy upper and lower bounds placed on model outputs.},
archivePrefix = {arXiv},
arxivId = {1705.10918},
author = {Wilson, Zachary T. and Sahinidis, Nikolaos V.},
doi = {10.1016/j.compchemeng.2017.02.010},
eprint = {1705.10918},
file = {:U$\backslash$:/Literature/Paper/Wilson{\_}2017-The ALAMO approach to machine learning.pdf:pdf},
issn = {00981354},
journal = {Computers and Chemical Engineering},
keywords = {Feature selection,Mixed-integer optimization,Model selection,Parametric regression},
mendeley-groups = {Machine Learning/Symbolic regression},
pages = {785--795},
publisher = {Elsevier Ltd},
title = {{The ALAMO approach to machine learning}},
url = {http://dx.doi.org/10.1016/j.compchemeng.2017.02.010},
volume = {106},
year = {2017}
}

@article{Schmidt2009,
abstract = {For centuries, scientists have attempted to identify and document analytical laws that underlie physical phenomena in nature. Despite the prevalence of computing power, the process of finding natural laws and their corresponding equations has resisted automation. A key challenge to finding analytic relations automatically is defining algorithmically what makes a correlation in observed data important and insightful. We propose a principle for the identification of nontriviality. We demonstrated this approach by automatically searching motion-tracking data captured from various physical systems, ranging from simple harmonic oscillators to chaotic double-pendula. Without any prior knowledge about physics, kinematics, or geometry, the algorithm discovered Hamiltonians, Lagrangians, and other laws of geometric and momentum conservation. The discovery rate accelerated as laws found for simpler systems were used to bootstrap explanations for more complex systems, gradually uncovering the -alphabet- used to describe those systems.},
author = {Schmidt, Michael and Lipson, Hod},
doi = {10.1126/science.1165893},
file = {:U$\backslash$:/Literature/Paper/Schmidt{\_}2009-Distilling Free-Form Natural Laws from Experimental Data.pdf:pdf},
issn = {00368075},
journal = {Science},
mendeley-groups = {Machine Learning/Symbolic regression},
number = {5923},
pages = {81--85},
pmid = {19342586},
title = {{Distilling free-form natural laws from experimental data}},
volume = {324},
year = {2009}
}

@article{Vinyals2016,
abstract = {Sequences have become first class citizens in supervised learning thanks to the resurgence of recurrent neural networks. Many complex tasks that require mapping from or to a sequence of observations can now be formulated with the sequence-to-sequence (seq2seq) framework which employs the chain rule to efficiently represent the joint probability of sequences. In many cases, however, variable sized inputs and/or outputs might not be naturally expressed as sequences. For instance, it is not clear how to input a set of numbers into a model where the task is to sort them; similarly, we do not know how to organize outputs when they correspond to random variables and the task is to model their unknown joint probability. In this paper, we first show using various examples that the order in which we organize input and/or output data matters significantly when learning an underlying model. We then discuss an extension of the seq2seq framework that goes beyond sequences and handles input sets in a principled way. In addition, we propose a loss which, by searching over possible orders during training, deals with the lack of structure of output sets. We show empirical evidence of our claims regarding ordering, and on the modifications to the seq2seq framework on benchmark language modeling and parsing tasks, as well as two artificial tasks – sorting numbers and estimating the joint probability of unknown graphical models.},
archivePrefix = {arXiv},
arxivId = {1511.06391},
author = {Vinyals, Oriol and Bengio, Samy and Kudlur, Manjunath},
eprint = {1511.06391},
file = {:U$\backslash$:/Literature/Paper/Vinyals{\_}2016-Order Matters{\_}Sequence to sequence for sets.pdf:pdf},
journal = {4th International Conference on Learning Representations, ICLR 2016 - Conference Track Proceedings},
mendeley-groups = {Graph Neural Networks/Readout},
pages = {1--11},
title = {{Order matters: Sequence to sequence for sets}},
year = {2016}
}

@article{Cranmer2019,
abstract = {We introduce an approach for imposing physically motivated inductive biases on graph networks to learn interpretable representations and improved zero-shot generalization. Our experiments show that our graph network models, which implement this inductive bias, can learn message representations equivalent to the true force vector when trained on n-body gravitational and spring-like simulations. We use symbolic regression to fit explicit algebraic equations to our trained model's message function and recover the symbolic form of Newton's law of gravitation without prior knowledge. We also show that our model generalizes better at inference time to systems with more bodies than had been experienced during training. Our approach is extensible, in principle, to any unknown interaction law learned by a graph network, and offers a valuable technique for interpreting and inferring explicit causal theories about the world from implicit knowledge captured by deep learning.},
archivePrefix = {arXiv},
arxivId = {1909.05862},
author = {Cranmer, Miles D. and Xu, Rui and Battaglia, Peter and Ho, Shirley},
eprint = {1909.05862},
file = {:U$\backslash$:/Literature/Paper/Cramner{\_}2019-Learning Symbolic Physics with Graph Networks.pdf:pdf},
journal = {arXiv},
mendeley-groups = {Machine Learning/Symbolic regression},
number = {NeurIPS},
title = {{Learning Symbolic Physics with Graph Networks}},
year = {2019}
}

@article{Reymond2010,
abstract = {The chemical space is the ensemble of all possible molecules, which is believed to contain at least 1060 organic molecules below 500 Da of possible interest for drug discovery. This review summarizes the development of the chemical space concept from enumerating acyclic hydrocarbons in the 1800's to the recent assembly of the chemical universe database GDB. Chemical space travel algorithms can be used to explore defined regions of chemical space by generating focused virtual libraries. Maps of the chemical space are produced from property spaces visualized by principal component analysis or by self-organizing maps, and from structural analyses such as the scaffold-tree or the MQN-system. Virtual screening of virtual chemical space followed by synthesis and testing of the best hits leads to the discovery of new drug molecules. {\textcopyright} 2011 The Royal Society of Chemistry.},
author = {Reymond, Jean Louis and {Van Deursen}, Ruud and Blum, Lorenz C. and Ruddigkeit, Lars},
doi = {10.1039/c0md00020e},
file = {:U$\backslash$:/Literature/Paper/Reymond{\_}2010-Chemical space as a source for new drugs.pdf:pdf},
issn = {20402503},
journal = {MedChemComm},
mendeley-groups = {Machine Learning/ML in PSE/General},
number = {1},
pages = {30--38},
title = {{Chemical space as a source for new drugs}},
volume = {1},
year = {2010}
}

@article{Coley2019b,
abstract = {Abstract This two-part Review examines how automation has contributed to different aspects of discovery in the chemical sciences. In this second part, we reflect on a selection of exemplary studies. It is increasingly important to articulate what the role of automation and computation has been in the scientific process and how that has or has not accelerated discovery. One can argue that even the best automated systems have yet to ?discover? despite being incredibly useful as laboratory assistants. We must carefully consider how they have been and can be applied to future problems of chemical discovery in order to effectively design and interact with future autonomous platforms. The majority of this Review defines a large set of open research directions, including improving our ability to work with complex data, build empirical models, automate both physical and computational experiments for validation, select experiments, and evaluate whether we are making progress towards the ultimate goal of autonomous discovery. Addressing these practical and methodological challenges will greatly advance the extent to which autonomous systems can make meaningful discoveries.},
annote = {https://doi.org/10.1002/anie.201909989},
author = {Coley, Connor W and Eyke, Natalie S and Jensen, Klavs F},
doi = {https://doi.org/10.1002/anie.201909989},
file = {:U$\backslash$:/Literature/Paper/Coley{\_}2019-Autonomous Discovery in the Chemical Sciences Part I{\_}Progress.pdf:pdf},
issn = {1433-7851},
journal = {Angewandte Chemie International Edition},
keywords = {automation,chemoinformatics,drug discovery,machine learning,materials science},
mendeley-groups = {Machine Learning/ML in PSE},
month = {Sept.},
number = {n/a},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{Autonomous Discovery in the Chemical Sciences Part II: Outlook}},
url = {https://doi.org/10.1002/anie.201909989},
volume = {n/a},
year = {2019}
}

@article{Coley2019a,
abstract = {Abstract This two-part Review examines how automation has contributed to different aspects of discovery in the chemical sciences. In this first part, we describe a classification for discoveries of physical matter (molecules, materials, devices), processes, and models and how they are unified as search problems. We then introduce a set of questions and considerations relevant to assessing the extent of autonomy. Finally, we describe many case studies of discoveries accelerated by or resulting from computer assistance and automation from the domains of synthetic chemistry, drug discovery, inorganic chemistry, and materials science. These illustrate how rapid advancements in hardware automation and machine learning continue to transform the nature of experimentation and modeling. Part two reflects on these case studies and identifies a set of open challenges for the field.},
author = {Coley, Connor W and Eyke, Natalie S and Jensen, Klavs F},
doi = {https://doi.org/10.1002/anie.201909987},
journal = {Angewandte Chemie International Edition},
keywords = {automation,chemoinformatics,drug discovery,machine learning,materials science},
number = {51},
pages = {22858--22893},
title = {{Autonomous Discovery in the Chemical Sciences Part I: Progress}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/anie.201909987},
volume = {59},
year = {2020}
}


@article{LeCun2015,
abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
doi = {10.1038/nature14539},
issn = {1476-4687},
journal = {Nature},
mendeley-groups = {Machine Learning/Basics},
number = {7553},
pages = {436--444},
title = {{Deep learning}},
url = {https://doi.org/10.1038/nature14539},
volume = {521},
year = {2015}
}

@article{Jaworska2005,
abstract = {As the use of Quantitative Structure Activity Relationship (QSAR) models for chemical management increases, the reliability of the predictions from such models is a matter of growing concern. The OECD QSAR Validation Principles recommend that a model should be used within its applicability domain (AD). The Setubal Workshop report provided conceptual guidance on defining a (Q)SAR AD, but it is difficult to use directly. The practical application of the AD concept requires an operational definition that permits the design of an automatic (computerised), quantitative procedure to determine a model's AD. An attempt is made to address this need, and methods and criteria for estimating AD through training set interpolation in descriptor space are reviewed. It is proposed that response space should be included in the training set representation. Thus, training set chemicals are points in n-dimensional descriptor space and m-dimensional model response space. Four major approaches for estimating interpolation regions in a multivariate space are reviewed and compared: range, distance, geometrical, and probability density distribution.},
annote = {doi: 10.1177/026119290503300508},
author = {Jaworska, Joanna and Nikolova-Jeliazkova, Nina and Aldenberg, Tom},
doi = {10.1177/026119290503300508},
issn = {0261-1929},
journal = {Alternatives to Laboratory Animals},
mendeley-groups = {QSPR/Basics},
month = {Oct.},
number = {5},
pages = {445--459},
publisher = {SAGE Publications Ltd STM},
title = {{QSAR Applicability Domain Estimation by Projection of the Training Set in Descriptor Space: A Review}},
url = {https://doi.org/10.1177/026119290503300508},
volume = {33},
year = {2005}
}

@article{Sheridan2004,
annote = {doi: 10.1021/ci049782w},
author = {Sheridan, Robert P and Feuston, Bradley P and Maiorov, Vladimir N and Kearsley, Simon K},
doi = {10.1021/ci049782w},
issn = {0095-2338},
journal = {Journal of Chemical Information and Computer Sciences},
month = {Nov.},
number = {6},
pages = {1912--1928},
publisher = {American Chemical Society},
title = {{Similarity to Molecules in the Training Set Is a Good Discriminator for Prediction Accuracy in QSAR}},
url = {https://doi.org/10.1021/ci049782w},
volume = {44},
year = {2004}
}

@article{Koenig_2020,
author = {K{\"{o}}nig, Andrea and Neidhardt, Lisa and Viell, J{\"{o}}rn and Mitsos, Alexander and Dahmen, Manuel},
doi = {https://doi.org/10.1016/j.compchemeng.2019.106712},
issn = {0098-1354},
journal = {Computers {\&} Chemical Engineering},
keywords = { Computer-aided mixture design, Fuel design, Integrated product and process design, Process network flux analysis,Tailor-made fuels},
mendeley-groups = {SVT publications},
pages = {106712},
title = {{Integrated design of processes and products: Optimal renewable fuels}},
url = {http://www.sciencedirect.com/science/article/pii/S0098135419306416},
volume = {134},
year = {2020}
}

@Article{venkatasubramanian2019,
  author    = {Venkatasubramanian, Venkat},
  title     = {{The promise of artificial intelligence in chemical engineering: Is it here, finally?}},
  journal   = {AIChE Journal},
  year      = {2019},
  volume    = {65},
  number    = {2},
  pages     = {466--478},
  publisher = {Wiley Online Library},
}

@article{Jirasek2020,
annote = {doi: 10.1021/acs.jpclett.9b03657},
author = {Jirasek, Fabian and Alves, Rodrigo A S and Damay, Julie and Vandermeulen, Robert A and Bamler, Robert and Bortz, Michael and Mandt, Stephan and Kloft, Marius and Hasse, Hans},
doi = {10.1021/acs.jpclett.9b03657},
journal = {The Journal of Physical Chemistry Letters},
month = {Feb.},
number = {3},
pages = {981--985},
publisher = {American Chemical Society},
title = {{Machine Learning in Thermodynamics: Prediction of Activity Coefficients by Matrix Completion}},
url = {https://doi.org/10.1021/acs.jpclett.9b03657},
volume = {11},
year = {2020}
}

@article{Gaertner2018,
abstract = {Abstract We consider lead discovery as active search in a space of labelled graphs. In particular, we extend our recent data-driven adaptive Markov chain approach, and evaluate it on a focused drug design problem, where we search for an antagonist of an integrin, the target protein that belongs to a group of Arg−Gly−Asp integrin receptors. This group of integrin receptors is thought to play a key role in idiopathic pulmonary fibrosis, a chronic lung disease of significant pharmaceutical interest. As an in silico proxy of the binding affinity, we use a molecular docking score to an experimentally determined protein structure. The search is driven by a probabilistic surrogate of the activity of all molecules from that space. As the process evolves and the algorithm observes the activity scores of the previously designed molecules, the hypothesis of the activity is refined. The algorithm is guaranteed to converge in probability to the best hypothesis from an a priori specified hypothesis space. In our empirical evaluations, the approach achieves a large structural variety of designed molecular structures for which the docking score is better than the desired threshold. Some novel molecules, suggested to be active by the surrogate model, provoke a significant interest from the perspective of medicinal chemistry and warrant prioritization for synthesis. Moreover, the approach discovered 19 out of the 24 active compounds which are known to be active from previous biological assays.},
author = {Oglic, Dino and Oatley, Steven A and Macdonald, Simon J F and Mcinally, Thomas and Garnett, Roman and Hirst, Jonathan D and G{\"{a}}rtner, Thomas},
doi = {https://doi.org/10.1002/minf.201700130},
journal = {Molecular Informatics},
keywords = { antagonist, cheminformatics, drug design, integrin,active search},
number = {1-2},
pages = {1700130},
title = {{Active Search for Computer-aided Drug Design}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/minf.201700130},
volume = {37},
year = {2018}
}

@article{Asprion2018,
abstract = {Abstract Besides experimentation process simulation is a key technology in process development. Process simulation supports design, analysis and operation of chemical processes and plants. A systematic use of process simulation and optimization in the process development workflow is beneficial for both the process model and experiments and enables to be more efficient and effective in process design. In the following it will be discussed how the application of process simulation and optimization has to be broadened to provide decision support for process development.},
author = {Asprion, Norbert and Bortz, Michael},
doi = {https://doi.org/10.1002/cite.201800051},
journal = {Chemie Ingenieur Technik},
keywords = { Design of experiments, Model validation, Multicriteria optimization, Sensitivity analysis,Decision support},
number = {11},
pages = {1727--1738},
title = {{Process Modeling, Simulation and Optimization: From Single Solutions to a Multitude of Solutions to Support Decision Making}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cite.201800051},
volume = {90},
year = {2018}
}


@article{sandfort2020structure,
  title={A structure-based platform for predicting chemical reactivity},
  author={Sandfort, Frederik and Strieth-Kalthoff, Felix and K{\"u}hnemund, Marius and Beecks, Christian and Glorius, Frank},
  journal={Chem},
  year={2020},
  publisher={Elsevier}
}

@article{karim2020deep,
  title={Deep learning-based clustering approaches for bioinformatics},
  author={Karim, Md Rezaul and Beyan, Oya and Zappa, Achille and Costa, Ivan G and Rebholz-Schuhmann, Dietrich and Cochez, Michael and Decker, Stefan},
  journal={Briefings in Bioinformatics},
  year={2020}
}
@article{gleim2020enabling,
  title={Enabling ad-hoc reuse of private data repositories through schema extraction},
  author={Gleim, Lars Christoph and Karim, Md Rezaul and Zimmermann, Lukas and Kohlbacher, Oliver and Stenzhorn, Holger and Decker, Stefan and Beyan, Oya},
  journal={Journal of Biomedical Semantics},
  volume={11},
  number={1},
  pages={1--15},
  year={2020},
  publisher={BioMed Central}
}
@article{hasan2020knowledge,
  title={Knowledge graph-enabled cancer data analytics},
  author={Hasan, SM Shamimul and Rivera, Donna and Wu, Xiao-Cheng and Durbin, Eric B and Christian, J Blair and Tourassi, Georgia},
  journal={IEEE journal of biomedical and health informatics},
  volume={24},
  number={7},
  pages={1952--1967},
  year={2020},
  publisher={IEEE}
}
@article{hu2015semantic,
  title={Semantic representation of evidence-based medical guidelines and its use cases},
  author={Hu, Qing and Huang, Zhisheng and Gu, Jinguang},
  journal={Wuhan University Journal of Natural Sciences},
  volume={20},
  number={5},
  pages={397--404},
  year={2015},
  publisher={Springer}
}
@article{xu2020building,
  title={Building a PubMed knowledge graph},
  author={Xu, Jian and Kim, Sunkyu and Song, Min and Jeong, Minbyul and Kim, Donghyeon and Kang, Jaewoo and Rousseau, Justin F and Li, Xin and Xu, Weijia and Torvik, Vetle I and others},
  journal={Scientific data},
  volume={7},
  number={1},
  pages={1--15},
  year={2020},
  publisher={Nature Publishing Group}
}
@article{karim2020classification,
  title={Classification Benchmarks for Under-resourced Bengali Language based on Multichannel Convolutional-LSTM Network},
  author={Karim, Md and Chakravarthi, Bharathi Raja and Arcan, Mihael and McCrae, John P and Cochez, Michael and others},
  journal={arXiv preprint arXiv:2004.07807},
  year={2020}
}

@article{schweidtmann2018machine,
  title={Machine learning meets continuous flow chemistry: Automated optimization towards the Pareto front of multiple objectives},
  author={Schweidtmann, Artur M and Clayton, Adam D and Holmes, Nicholas and Bradford, Eric and Bourne, Richard A and Lapkin, Alexei A},
  journal={Chemical Engineering Journal},
  volume={352},
  pages={277--282},
  year={2018},
  publisher={Elsevier}
}

@article{schweidtmann2020graph,
  title={Graph Neural Networks for Prediction of Fuel Ignition Quality},
  author={Schweidtmann, Artur M and Rittig, Jan G and K{\"o}nig, Andrea and Grohe, Martin and Mitsos, Alexander and Dahmen, Manuel},
  year={2020},
  publisher={ChemRxiv}
}

@article{schweidtmann2019deterministic,
  title={Deterministic global optimization with artificial neural networks embedded},
  author={Schweidtmann, Artur M and Mitsos, Alexander},
  journal={Journal of Optimization Theory and Applications},
  volume={180},
  number={3},
  pages={925--948},
  year={2019},
  publisher={Springer}
}

@article{schweidtmann2019deterministic,
  title={Deterministic global process optimization: Accurate (single-species) properties via artificial neural networks},
  author={Schweidtmann, Artur M and Huster, Wolfgang R and L{\"u}thje, Jannik T and Mitsos, Alexander},
  journal={Computers \& Chemical Engineering},
  volume={121},
  pages={67--74},
  year={2019},
  publisher={Elsevier}
}
@book{hitzler2009foundations,
  title={Foundations of semantic web technologies},
  author={Hitzler, Pascal and Kr{\"o}tzsch, Markus and Rudolph, Sebastian},
  year={2009},
  publisher={CRC press}
}
@article{zhang2020interstellar,
  title={Interstellar: Searching Recurrent Architecture for Knowledge Graph Embedding},
  author={Zhang, Yongqi and Yao, Quanming and Chen, Lei},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}
@article{ren2020beta,
  title={Beta Embeddings for Multi-Hop Logical Reasoning in Knowledge Graphs},
  author={Ren, Hongyu and Leskovec, Jure},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}
@article{ren2020query2box,
  title={Query2box: Reasoning over knowledge graphs in vector space using box embeddings},
  author={Ren, Hongyu and Hu, Weihua and Leskovec, Jure},
  journal={arXiv preprint arXiv:2002.05969},
  year={2020}
}
@article{wilcke2017knowledge,
  title={The knowledge graph as the default data model for learning on heterogeneous knowledge},
  author={Wilcke, Xander and Bloem, Peter and De Boer, Victor},
  journal={Data Science},
  volume={1},
  number={1-2},
  pages={39--57},
  year={2017},
  publisher={IOS Press}
}

@article{amar2019machine,
  title={Machine learning and molecular descriptors enable rational solvent selection in asymmetric catalysis},
  author={Amar, Yehia and Schweidtmann, Artur M and Deutsch, Paul and Cao, Liwei and Lapkin, Alexei},
  journal={Chemical science},
  volume={10},
  number={27},
  pages={6697--6706},
  year={2019},
  publisher={Royal Society of Chemistry}
}

@article{morbach2007ontocape,
  title={OntoCAPE—A large-scale ontology for chemical process engineering},
  author={Morbach, Jan and Yang, Aidong and Marquardt, Wolfgang},
  journal={Engineering applications of artificial intelligence},
  volume={20},
  number={2},
  pages={147--161},
  year={2007},
  publisher={Elsevier}
}

@article{krallinger2017information,
  title={Information retrieval and text mining technologies for chemistry},
  author={Krallinger, Martin and Rabal, Obdulia and Lourenco, Analia and Oyarzabal, Julen and Valencia, Alfonso},
  journal={Chemical reviews},
  volume={117},
  number={12},
  pages={7673--7761},
  year={2017},
  publisher={ACS Publications}
}

@book{smith1995chemical,
  title={Chemical process design},
  author={Smith, Robin and Smith, R},
  year={1995},
  publisher={McGraw-Hill New York}
}

@article{lee2018machine,
  title={Machine learning: Overview of the recent progresses and implications for the process systems engineering field},
  author={Lee, Jay H and Shin, Joohyun and Realff, Matthew J},
  journal={Computers \& Chemical Engineering},
  volume={114},
  pages={111--121},
  year={2018},
  publisher={Elsevier}
}

@book{green2019perry,
  title={Perry's chemical engineers' handbook},
  author={Green, Don W and Southard, Marylee Z},
  year={2019},
  publisher={McGraw-Hill Education}
}


@article{Gruber1995,
  title={Toward principles for the design of ontologies used for knowledge sharing},
  author={T. Gruber},
  journal={Int. J. Hum. Comput. Stud.},
  year={1995},
  volume={43},
  pages={907-928}
}

@article{Morbach2009,
  title={OntoCAPE—A (re) usable ontology for computer-aided process engineering},
  author={Morbach, Jan and Wiesner, Andreas and Marquardt, Wolfgang},
  journal={Computers \& Chemical Engineering},
  volume={33},
  number={10},
  pages={1546--1556},
  year={2009},
  publisher={Elsevier}
}

@book{Marquardt2010,
    author = {Marquardt, Wolfgang and Morbach, Jan and Wiesner, Andreas and Yang, Aidong},
    title = {OntoCAPE: A Re-Usable Ontology for Chemical Process Engineering},
    year = {2010},
    isbn = {3642046541},
    publisher = {Springer Publishing Company},
}

@misc{Whitehead_2016, 
    title={Whitehead-An overview of semantic models in the geosciences: what do we have, and where are we going?},     url={https://figshare.com/articles/presentation/Whitehead-Geoscience_Semantic_Models_review-Ontology_Summit_2016_odp/3501935/2}, DOI={10.6084/m9.figshare.3501935.v2},
    publisher={figshare}, 
    author={Whitehead, Brandon}, 
    year={2016}, 
    month={Jul} 
} 

@article{nieto2003,
  title={An overview of ontologies},
  author={Nieto, Mar{\'\i}a Auxilio Medina},
  journal={Universidad De Las Am{\'e}ricas Puebla, Interactive and Cooperative Technologies Lab},
  year={2003},
  publisher={Citeseer}
}


@misc{Singhal2012,
  title={Introducing the Knowledge Graph: things, not strings},
  author={Singhal, Amit},
  url={https://blog.google/products/search/introducing-knowledge-graph-things-not/},
  year={2012},
  journal={Google: The Keyword}
}

@inproceedings{Ehrlinger2016,
  title={Towards a Definition of Knowledge Graphs},
  author={Lisa Ehrlinger and W. W{\"o}{\ss}},
  booktitle={SEMANTiCS},
  year={2016}
}

@misc{pachl2020,
      title={Overview of chemical ontologies}, 
      author={Christian Pachl and Nils Frank and Jan Breitbart and Stefan Bräse},
      year={2020},
      eprint={2002.03842},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@article{Bodenreider2004,
    author = {Bodenreider, Olivier},
    title = "{The Unified Medical Language System (UMLS): integrating biomedical terminology}",
    journal = {Nucleic Acids Research},
    volume = {32},
    number = {suppl_1},
    pages = {D267-D270},
    year = {2004},
    month = {01},
    doi = {10.1093/nar/gkh061},
    url = {https://doi.org/10.1093/nar/gkh061},
}

@article{Bock2010,
    title = "Ontological product modeling for collaborative design",
    journal = "Advanced Engineering Informatics",
    volume = "24",
    number = "4",
    pages = "510 - 524",
    year = "2010",
    note = "Construction Informatics",
    doi = "https://doi.org/10.1016/j.aei.2010.06.011",
    url = "http://www.sciencedirect.com/science/article/pii/S1474034610000558",
    author = "Conrad Bock and XuanFang Zha and Hyo-won Suh and Jae-Hyun Lee",
}

@article{Rodriguez2019.v1, 
    title={An Ontology for Process Safety}, 
    volume={77}, 
    url={https://www.cetjournal.it/index.php/cet/article/view/CET1977012}, 
    DOI={10.3303/CET1977012}, 
    journal={Chemical Engineering Transactions}, 
    author={Rodriguez, Manuel and Laguia, Jorge}, 
    year={2019}, 
    month={Sep.}, 
    pages={67-72},
}

@article{Rodriguez2019,
  title={An Ontology for Process Safety},
  author={Rodriguez, Manuel and Laguia, Jorge},
  journal={Chemical Engineering Transactions},
  volume={77},
  pages={67--72},
  year={2019}
}

@article{Natarajan2012,
    title = "An ontology for distributed process supervision of large-scale chemical plants",
    journal = "Computers \& Chemical Engineering",
    volume = "46",
    pages = "124 - 140",
    year = "2012",
    doi = "https://doi.org/10.1016/j.compchemeng.2012.06.009",
    url = "http://www.sciencedirect.com/science/article/pii/S0098135412001858",
    author = "Sathish Natarajan and Kaushik Ghosh and Rajagopalan Srinivasan",
}

@inproceedings{Batres2000-1,
  title={Process plant ontologies based on a multi-dimensional framework},
  author={Batres, Rafael and Naka, Yuji},
  booktitle={AIChE symposium series},
  pages={433--437},
  year={2000},
  organization={New York; American Institute of Chemical Engineers; 1998}
}

@article{Batres2002,
    title = "A life-cycle approach for model reuse and exchange",
    journal = "Computers \& Chemical Engineering",
    volume = "26",
    number = "4",
    pages = "487 - 498",
    year = "2002",
    doi = "https://doi.org/10.1016/S0098-1354(01)00794-3",
    url = "http://www.sciencedirect.com/science/article/pii/S0098135401007943",
    author = "Rafael Batres and Atsushi Aoyama and Yuji Naka",
}

@article{Munoz2010,
    title = "Towards an ontological infrastructure for chemical batch process management",
    journal = "Computers \& Chemical Engineering",
    volume = "34",
    number = "5",
    pages = "668 - 682",
    year = "2010",
    doi = "https://doi.org/10.1016/j.compchemeng.2009.12.009",
    url = "http://www.sciencedirect.com/science/article/pii/S0098135409003160",
    author = "E. Muñoz and A. Espuña and L. Puigjaner",
}

@article{Bai2020,
  title={Automated calibration of a poly(oxymethylene) dimethyl ether oxidation mechanism using knowledge-graph technology},
  author={Jiaru Bai and Rory Geeson and Feroz Farazi and Sebastian Mosbach and Jethro Akroyd and E. Bringley and M. Kraft},
  journal={Cambridge Centre for Computational Chemical Engineering},
  year={2020},
  publisher={Technical Report Cambridge}
}

@article{Eibeck2019,
    title = "J-Park Simulator: An ontology-based platform for cross-domain scenarios in process industry",
    journal = "Computers \& Chemical Engineering",
    volume = "131",
    pages = "106586",
    year = "2019",
    doi = "https://doi.org/10.1016/j.compchemeng.2019.106586",
    url = "http://www.sciencedirect.com/science/article/pii/S0098135419301589",
    author = "Andreas Eibeck and Mei Qi Lim and Markus Kraft",
}

@article{farazi2019ontokin,
  title={OntoKin: An ontology for chemical kinetic reaction mechanisms},
  author={Farazi, Feroz and Akroyd, Jethro and Mosbach, Sebastian and Buerger, Philipp and Nurkowski, Daniel and Salamanca, Maurin and Kraft, Markus},
  journal={Journal of Chemical Information and Modeling},
  volume={60},
  number={1},
  pages={108--120},
  year={2019},
  publisher={ACS Publications}
}


@article{Liddy.2001,
 author = {Liddy, Elizabeth D.},
 year = {2001},
 title = {Natural language processing},
 url = {http://surface.syr.edu/cgi/viewcontent.cgi?article=1019&context=cnlp},
 address = {New York},
 journal = {Encyclopedia of Library and Information Science, 2nd Ed},
 editor = {Marcel Decker, Inc.},
 publisher = {Syracuse University},
 file = {adc050db-ca0e-4fd3-a100-402620deda8d:C\:\\Users\\Mathis Heyer\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\kim8g6iyaxsxjewxavdjdko3c9vp47oz9vlg48f169bztlz\\Citavi Attachments\\adc050db-ca0e-4fd3-a100-402620deda8d.pdf:pdf}
}


@book{Jurafsky.2014,
 author = {Jurafsky, Dan and Martin, James H.},
 year = {2014},
 title = {Speech and language processing, second edition},
 address = {Harlow},
 edition = {Pearson new international edition},
 publisher = {{Pearson Education}},
 isbn = {1292025433},
 series = {Always learning},
 file = {https://external.dandelon.com/download/attachments/dandelon/ids/DE002029B4B78DCDBF46AC1257C1A004648DB.pdf}
}

% This file was created with Citavi 6.7.0.0

@book{.,
 title = {Couper, Penney et al. (Ed.) 2010 -- Chemical process equipment}
}


@book{.2007,
 year = {2007},
 title = {An overview on OntoCAPE and its latest applications},
 url = {https://aiche.confex.com/aiche/2007/techprogram/p84380.htm}
}


@proceedings{.2009,
 year = {2009},
 title = {2009 Seventh International Conference on Advances in Pattern Recognition}
}


@proceedings{.2015,
 year = {2015}
}


@proceedings{.2020,
 year = {2020},
 title = {2020 International Conference on Systems, Signals and Image Processing (IWSSIP)},
 isbn = {2157-8702}
}


@misc{.25.11.2020,
 year = {25.11.2020},
 title = {Flowsheets},
 url = {https://www.sciencedirect.com/science/article/pii/B9780123969590000021},
 urldate = {25.11.2020}
}


@misc{AmericanInstituteofChemicalEngineers.13.01.2021,
 abstract = {Click on the article title to read more.},
 author = {{American Institute of Chemical Engineers}},
 year = {13.01.2021},
 title = {The promise of artificial intelligence in chemical engineering: Is it here, finally?},
 url = {https://aiche.onlinelibrary.wiley.com/doi/full/10.1002/aic.16489},
 urldate = {13.01.2021}
}


@article{Artz.2018,
 abstract = {CO2 conversion covers a wide range of possible application areas from fuels to bulk and commodity chemicals and even to specialty products with biological activity such as pharmaceuticals. In the present review, we discuss selected examples in these areas in a combined analysis of the state-of-the-art of synthetic methodologies and processes with their life cycle assessment. Thereby, we attempted to assess the potential to reduce the environmental footprint in these application fields relative to the current petrochemical value chain. This analysis and discussion differs significantly from a viewpoint on CO2 utilization as a measure for global CO2 mitigation. Whereas the latter focuses on reducing the end-of-pipe problem {\textquotedbl}CO2 emissions{\textquotedbl} from todays' industries, the approach taken here tries to identify opportunities by exploiting a novel feedstock that avoids the utilization of fossil resource in transition toward more sustainable future production. Thus, the motivation to develop CO2-based chemistry does not depend primarily on the absolute amount of CO2 emissions that can be remediated by a single technology. Rather, CO2-based chemistry is stimulated by the significance of the relative improvement in carbon balance and other critical factors defining the environmental impact of chemical production in all relevant sectors in accord with the principles of green chemistry.},
 author = {Artz, Jens and M{\"u}ller, Thomas E. and Thenert, Katharina and Kleinekorte, Johanna and Meys, Raoul and Sternberg, Andr{\'e} and Bardow, Andr{\'e} and Leitner, Walter},
 year = {2018},
 title = {Sustainable Conversion of Carbon Dioxide: An Integrated Review of Catalysis and Life Cycle Assessment},
 url = {https://pubmed.ncbi.nlm.nih.gov/29220170/},
 pages = {434--504},
 volume = {118},
 number = {2},
 issn = {1520-6890},
 journal = {Chemical reviews},
 doi = {10.1021/acs.chemrev.7b00435},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/29220170}
}


@inproceedings{Auer.2013,
 abstract = {Optical graph recognition (OGR) reverses graph drawing. A drawing transforms the topological structure of a graph into a graphical representation. Primarily, it maps vertices to points and displays them by icons and it maps edges to Jordan curves connecting the endpoints. OGR transforms the digital image of a drawn graph into its topological structure. It consists of four phases, preprocessing, segmentation, topology recognition, and postprocessing. OGR is based on established digital image processing techniques. Its novelty is the topology recognition where the edges are recognized with emphasis on the attachment to their vertices and on edge crossings.},
 author = {Auer, Christopher and Bachmaier, Christian and Brandenburg, Franz J. and Glei{\ss}ner, Andreas and Reislhuber, Josef},
 title = {Optical Graph Recognition},
 pages = {529--540},
 publisher = {{Springer Berlin Heidelberg}},
 isbn = {978-3-642-36763-2},
 series = {Lecture Notes in Computer Science},
 editor = {Didimo, Walter and Patrignani, Maurizio},
 booktitle = {Graph Drawing},
 year = {2013},
 address = {Berlin, Heidelberg},
 file = {897bc260-044b-418b-b40f-b6b4d1049cb4:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\897bc260-044b-418b-b40f-b6b4d1049cb4.pdf:pdf}
}


@article{Auer.2013b,
 abstract = {PDF | Optical graph recognition (OGR) reverses graph drawing. A drawing transforms the topological structure of a graph into a graphical representation.... | Find, read and cite all the research you need on ResearchGate},
 author = {Auer, Christopher and Bachmaier, Christian and Brandenburg, Franz J. and Glei{\ss}ner, Andreas and Reislhuber, Josef},
 year = {2013},
 title = {Optical Graph Recognition},
 url = {https://www.researchgate.net/publication/304417724_Optical_Graph_Recognition},
 pages = {541--565},
 volume = {17},
 number = {4},
 issn = {1526-1719},
 journal = {Journal of Graph Algorithms and Applications},
 doi = {10.7155/jgaa.00303},
 file = {58cf89a1-f6ec-45a9-bdd2-170920c0b56f:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\58cf89a1-f6ec-45a9-bdd2-170920c0b56f.pdf:pdf}
}


@inproceedings{Auer.2013c,
 abstract = {Optical graph recognition (OGR) reverses graph drawing. A drawing transforms the topological structure of a graph into a graphical representation. Primarily, it maps vertices to points and displays them by icons and it maps edges to Jordan curves connecting the endpoints. OGR transforms the digital image of a drawn graph into its topological structure. It consists of four phases, preprocessing, segmentation, topology recognition, and postprocessing. OGR is based on established digital image processing techniques. Its novelty is the topology recognition where the edges are recognized with emphasis on the attachment to their vertices and on edge crossings.},
 author = {Auer, Christopher and Bachmaier, Christian and Brandenburg, Franz J. and Glei{\ss}ner, Andreas and Reislhuber, Josef},
 title = {Optical Graph Recognition},
 pages = {529--540},
 publisher = {{Springer Berlin Heidelberg}},
 isbn = {978-3-642-36763-2},
 series = {Lecture Notes in Computer Science},
 editor = {Didimo, Walter and Patrignani, Maurizio},
 booktitle = {Graph Drawing},
 year = {2013},
 address = {Berlin, Heidelberg},
 file = {7919c23d-9b2f-4530-9570-6e8dcca16818:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\7919c23d-9b2f-4530-9570-6e8dcca16818.pdf:pdf}
}


@article{B.Yu.1995,
 abstract = {A symbol-connected diagram is mainly composed of symbols and their connections. All symbols can be categorized into two groups: shape symbols and structure symbols. This paper proposes a system for automatic understanding of symbol-connected diagrams based on a graph, called the consistent attributed graph (CAG), which represents the diagram in a bottom-up fashion. The shape symbol processing is carried out by means of shape processing, followed by shape symbol identification with the use of two symbol windows in the CAG. Some experimental results for understanding logic circuit diagrams are given.},
 author = {{B. Yu}},
 year = {1995},
 title = {Automatic understanding of symbol-connected diagrams},
 url = {https://www.semanticscholar.org/paper/Automatic-understanding-of-symbol-connected-Yu/f6eaca354660e70df0b0756d4270ea4284c853ca},
 journal = {undefined}
}


@book{BerkaySezen.2019,
 abstract = {PDF | The need for digitization of complex engineering drawings has come into prominence for the industrial applications in order to reconstruct these... | Find, read and cite all the research you need on ResearchGate},
 author = {Berkay Sezen},
 year = {2019},
 title = {Evaluation of Machine Learning Algorithms for Object Detection in Technical Drawings like P{\&}IDs and Circuit Diagrams},
 url = {https://www.researchgate.net/publication/340307540_Evaluation_of_Machine_Learning_Algorithms_for_Object_Detection_in_Technical_Drawings_like_PIDs_and_Circuit_Diagrams},
 publisher={Technical University of Munich Press}
}


@misc{Bochkovskiy.23.04.2020b,
 abstract = {There are a huge number of features which are said to improve Convolutional Neural Network (CNN) accuracy. Practical testing of combinations of such features on large datasets, and theoretical justification of the result, is required. Some features operate on certain models exclusively and for certain problems exclusively, or only for small-scale datasets; while some features, such as batch-normalization and residual-connections, are applicable to the majority of models, tasks, and datasets. We assume that such universal features include Weighted-Residual-Connections (WRC), Cross-Stage-Partial-connections (CSP), Cross mini-Batch Normalization (CmBN), Self-adversarial-training (SAT) and Mish-activation. We use new features: WRC, CSP, CmBN, SAT, Mish activation, Mosaic data augmentation, CmBN, DropBlock regularization, and CIoU loss, and combine some of them to achieve state-of-the-art results: 43.5{\%} AP (65.7{\%} AP50) for the MS COCO dataset at a realtime speed of {\~{}}65 FPS on Tesla V100. Source code is at https://github.com/AlexeyAB/darknet},
 author = {Bochkovskiy, Alexey and Wang, Chien-Yao and Liao, Hong-Yuan Mark},
 date = {23.04.2020},
 title = {YOLOv4: Optimal Speed and Accuracy of Object Detection},
 url = {https://arxiv.org/pdf/2004.10934},
 file = {2c9e54b3-7074-492c-89e7-746bf84ff7c5:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\2c9e54b3-7074-492c-89e7-746bf84ff7c5.pdf:pdf}
}


@inproceedings{Bunke.1982,
 abstract = {Circuit diagrams are characterised by symbols, connections and text. The task considered in this paper is the automatic extraction of a description from a circuit diagram. The system presented in this paper consists of two major parts, one for the line interpretation and one for the text interpretation. A decision tree containing the a priori knowledge about the form of symbols controls the interpretation of lines while the text interpretation is controlled by both the results of the line interpretation and a set of finite state automata defining the denotations.},
 author = {Bunke, Horst},
 title = {Automatic Interpretation of Lines and Text in Circuit Diagrams},
 pages = {297--310},
 publisher = {{Springer Netherlands}},
 isbn = {978-94-009-7772-3},
 series = {NATO ASI Series},
 editor = {Devijver, Pierre A.},
 booktitle = {Pattern Recognition Theory and Applications},
 year = {1982},
 address = {Dordrecht}
}


@incollection{Couper.,
 author = {Couper, James R. and Penney, W. Roy and Fair, James R. and Walas, Stanley M.},
 title = {2 - Flowsheets},
 url = {http://www.sciencedirect.com/science/article/pii/B9780123969590000021},
 pages = {17--29},
 booktitle = {Couper, Penney et al. (Ed.) 2010 -- Chemical process equipment},
 doi = {10.1016/B978-0-12-396959-0.00002-1}
}


@book{Couper.2010,
 year = {2010},
 title = {Chemical process equipment: Selection and design},
 address = {Amsterdam and Boston and Heidelberg [etc]},
 edition = {3e {\'e}dition},
 publisher = {Elsevier and Butterworth-Heinemann},
 isbn = {978-0-12-396959-0},
 editor = {Couper, James R. and Penney, W. Roy and Fair, James R. and Walas, Stanley M.}
}


@proceedings{Devijver.1982,
 year = {1982},
 title = {Pattern Recognition Theory and Applications: Proceedings of the NATO Advanced Study Institute held at St. Anne's College, Oxford, March 29-April 10, 1981},
 address = {Dordrecht},
 publisher = {{Springer Netherlands}},
 isbn = {978-94-009-7772-3},
 series = {NATO ASI Series},
 editor = {Devijver, Pierre A.},
 institution = {{Advanced Study Institute on Pattern Recognition Theory and Applications}}
}


@proceedings{Didimo.2013,
 abstract = {This book constitutes the thoroughly refereed post-conference proceedings of the 20th International Symposium on Graph Drawing, GD 2012, held in Redmond, WA, USA, in September 2012. The 42 revised full papers presented together with 4 revised short papers and 8 poster descriptions were carefully reviewed and selected from 92 submissions. They cover a wide range of topics in two main tracks: combinatorial and algorithmic aspects, and visualization systems and interfaces. In addition, reports of the 19th Annual Graph Drawing Contest, which was held during the conference, and of a workshop on theory and practice of graph drawing to celebrate Professor Peter Eades' 60th birthday are included in the volume.},
 year = {2013},
 title = {Graph Drawing: 20th International Symposium, GD 2012, Redmond, WA, USA, September 19-21, 2012, Revised Selected Papers},
 address = {Berlin, Heidelberg},
 volume = {7704},
 publisher = {{Springer Berlin Heidelberg}},
 isbn = {978-3-642-36763-2},
 series = {Lecture Notes in Computer Science},
 editor = {Didimo, Walter and Patrignani, Maurizio},
 institution = {GD}
}


@article{Elyan.2020,
 abstract = {Engineering drawings are commonly used in different industries such as Oil and Gas, construction, and other types of engineering. Digitising these drawings is becoming increasingly important. This is mainly due to the need to improve business practices such as inventory, assets management, risk analysis, and other types of applications. However, processing and analysing these drawings is a challenging task. A typical diagram often contains a large number of different types of symbols belonging to various classes and with very little variation among them. Another key challenge is the class-imbalance problem, where some types of symbols largely dominate the data while others are hardly represented in the dataset. In this paper, we propose methods to handle these two challenges. First, we propose an advanced bounding-box detection method for localising and recognising symbols in engineering diagrams. Our method is end-to-end with no user interaction. Thorough experiments on a large collection of diagrams from an industrial partner proved that our methods accurately recognise more than 94{\%} of the symbols. Secondly, we present a method based on Deep Generative Adversarial Neural Network for handling class-imbalance. The proposed GAN model proved to be capable of learning from a small number of training examples. Experiment results showed that the proposed method greatly improved the classification of symbols in engineering drawings.},
 author = {Elyan, Eyad and Jamieson, Laura and Ali-Gombe, Adamu},
 year = {2020},
 title = {Deep learning for symbols detection and classification in engineering drawings},
 url = {http://www.sciencedirect.com/science/article/pii/S0893608020301957},
 pages = {91--102},
 volume = {129},
 journal = {Neural networks : the official journal of the International Neural Network Society},
 doi = {10.1016/j.neunet.2020.05.025},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/32502800}
}


@article{FabianPedregosa.2011,
 author = {{Fabian Pedregosa} and {Ga{\"e}l Varoquaux} and {Alexandre Gramfort} and {Vincent Michel} and {Bertrand Thirion} and {Olivier Grisel} and {Mathieu Blondel} and {Peter Prettenhofer} and {Ron Weiss} and {Vincent Dubourg} and {Jake Vanderplas} and {Alexandre Passos} and {David Cournapeau} and {Matthieu Brucher} and {Matthieu Perrot} and {{\'E}douard Duchesnay}},
 year = {2011},
 title = {Scikit-learn: Machine Learning in Python},
 pages = {2825--2830},
 volume = {12},
 number = {85},
 issn = {1533-7928},
 journal = {Journal of Machine Learning Research},
 file = {c8455204-5866-4b80-b4d1-eb24bf22126c:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\c8455204-5866-4b80-b4d1-eb24bf22126c.pdf:pdf}
}


@article{Fahn.1988,
 abstract = {An automatic understanding system using the techniques of image processing, pattern recognition, and artificial intelligence has been developed for electronic circuit diagrams. Part of the system is presented to extract three categories of essential components: circuit symbols, characters, and connection lines. Each essential component consists of a set of picture segments which are appropriately detected by a segment tracking algorithm. A heuristic piecewise linear approximation algorithm is proposed to approximate picture segments for primitive recognition. On the basis of topological context, a one-pass manner called the relational best search method applies a depth first search technique uniting a set of specified rules during the traversal of a circuit diagram. This method combines the constituents of each circuit symbol or character into a cluster. All the clusters together with the remaining components are extracted and grouped into the three categories as soon as the traversal is finished. A variety of electronic circuit diagrams have been used for testing the component extractor. So far, the present extractor has shown favorable results.},
 author = {Fahn, Chin-Shyurng and Wang, Jhing-Fa and Lee, Jau-Yien},
 year = {1988},
 title = {A topology-based component extractor for understanding electronic circuit diagrams},
 url = {http://www.sciencedirect.com/science/article/pii/S0734189X8880001X},
 pages = {119--138},
 volume = {44},
 number = {2},
 issn = {0734-189X},
 journal = {Computer Vision, Graphics, and Image Processing},
 doi = {10.1016/S0734-189X(88)80001-X}
}


@misc{Funke.20.04.2020,
 abstract = {With the rise of machines to human-level performance in complex recognition tasks, a growing amount of work is directed towards comparing information processing in humans and machines. These studies are an exciting chance to learn about one system by studying the other. Here, we propose ideas on how to design, conduct and interpret experiments such that they adequately support the investigation of mechanisms when comparing human and machine perception. We demonstrate and apply these ideas through three case studies. The first case study shows how human bias can affect how we interpret results, and that several analytic tools can help to overcome this human reference point. In the second case study, we highlight the difference between necessary and sufficient mechanisms in visual reasoning tasks. Thereby, we show that contrary to previous suggestions, feedback mechanisms might not be necessary for the tasks in question. The third case study highlights the importance of aligning experimental conditions. We find that a previously-observed difference in object recognition does not hold when adapting the experiment to make conditions more equitable between humans and machines. In presenting a checklist for comparative studies of visual reasoning in humans and machines, we hope to highlight how to overcome potential pitfalls in design or inference.},
 author = {Funke, Christina M. and Borowski, Judy and Stosio, Karolina and Brendel, Wieland and Wallis, Thomas S. A. and Bethge, Matthias},
 date = {20.04.2020},
 title = {Five Points to Check when Comparing Visual Perception in Humans and  Machines},
 url = {https://arxiv.org/pdf/2004.09406},
 file = {f498f4b3-c57b-4736-9de9-aa16eb7fdf52:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\f498f4b3-c57b-4736-9de9-aa16eb7fdf52.pdf:pdf}
}


@article{Gao.2020,
 abstract = {Piping and Instrumentation Diagrams (P{\&}IDs) are the most commonly used engineering drawings to describe components and their relationships, and they are one of the most important inputs for data analysis in Nuclear Power Plants (NPP). In traditional analysis, the information related to the components is extracted manually from the P{\&}IDs. This usually takes large amounts of effort and is error-prone. With the rapid development in the area of computer vision and deep learning, automatically detecting components and their relationships becomes possible. In this paper, we aim to use the latest neural network models to automatically extract information on components and their identifications, from the P{\&}IDs in NPPs. We use a Faster Regional Convolutional Neural Networks (Faster RCNN) architecture called ResNet-50, to detect the components in the P{\&}IDs. Compared to common object detection, object detection for P{\&}IDs poses unique challenges to these methods. For example, the P{\&}IDs symbols are much smaller than the background, and detecting such small objects remains a challenging task for modern neural networks. To address these challenges, we 1) propose several techniques for data augmentation that effectively solve the problem of training data shortage, and 2) propose a feature grouping strategy for detecting components with distinct features. Besides, we introduce a SegLink model for text detection, which can automatically extract components' identifications from P{\&}IDs. We also develop a method for building a data structure to reflect the relationships between components (e.g., to which pipe a component is connected, or what are the downstream or upstream components of one specific component) based on the extracted information. This data structure can be further used for plant safety analysis, and operation and maintenance cost optimization. Sensitivity analysis and comparison with other Convolutional Neural Networks (CNNs) are performed. The results of these analyses are also discussed in this paper.

This analysis framework has been tested on the P{\&}IDs from a commercial NPP. The Average Precision for components, which is used to measure the performance of the proposed method, is about 98{\%}. The success rates of component-text mapping and component-pipe mapping are 270/275 and 319/319, respectively. It is worth noting that this framework is generic and can also be applied to P{\&}IDs of non-nuclear industries.},
 author = {Gao, Wei and Zhao, Yunfei and Smidts, Carol},
 year = {2020},
 title = {Component detection in piping and instrumentation diagrams of nuclear power plants based on neural networks},
 url = {http://www.sciencedirect.com/science/article/pii/S0149197020302419},
 pages = {103491},
 volume = {128},
 issn = {0149-1970},
 journal = {Progress in Nuclear Energy},
 doi = {10.1016/j.pnucene.2020.103491}
}


@misc{Girshick.11.11.2013,
 abstract = {Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30{\%} relative to the previous best result on VOC 2012---achieving a mAP of 53.3{\%}. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also compare R-CNN to OverFeat, a recently proposed sliding-window detector based on a similar CNN architecture. We find that R-CNN outperforms OverFeat by a large margin on the 200-class ILSVRC2013 detection dataset. Source code for the complete system is available at http://www.cs.berkeley.edu/{\~{}}rbg/rcnn.},
 author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
 date = {11.11.2013},
 title = {Rich feature hierarchies for accurate object detection and semantic  segmentation},
 url = {https://arxiv.org/pdf/1311.2524},
 file = {fc41a3ba-6755-4181-919a-9a78f29b82b0:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\fc41a3ba-6755-4181-919a-9a78f29b82b0.pdf:pdf}
}


@misc{Girshick.30.04.2015,
 abstract = {This paper proposes a Fast Region-based Convolutional Network method (Fast R-CNN) for object detection. Fast R-CNN builds on previous work to efficiently classify object proposals using deep convolutional networks. Compared to previous work, Fast R-CNN employs several innovations to improve training and testing speed while also increasing detection accuracy. Fast R-CNN trains the very deep VGG16 network 9x faster than R-CNN, is 213x faster at test-time, and achieves a higher mAP on PASCAL VOC 2012. Compared to SPPnet, Fast R-CNN trains VGG16 3x faster, tests 10x faster, and is more accurate. Fast R-CNN is implemented in Python and C++ (using Caffe) and is available under the open-source MIT License at https://github.com/rbgirshick/fast-rcnn.},
 author = {Girshick, Ross},
 date = {30.04.2015},
 title = {Fast R-CNN},
 url = {https://arxiv.org/pdf/1504.08083},
 file = {b0c22ff1-e00d-466a-8415-69e0c2fa75e6:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\b0c22ff1-e00d-466a-8415-69e0c2fa75e6.pdf:pdf}
}


@article{Groen.1985,
 abstract = {In this paper a method is proposed to recognize symbols in electrical diagrams based on probabilistic matching. The skeletons of the symbols are represented by graphs. After finding the pose of the graph (orientation, translation, scale) by a bounded search for a minimum error transformation, the observed graph is matched to the class models and the likelihood of the match is calculated. Results are given for computer-generated symbols and hand drawn symbols with and without a template. Error rates range from {\textless}1{\%} to 8{\%}.},
 author = {Groen, Frans C.A and Sanderson, Arthur C. and Schlag, John F.},
 year = {1985},
 title = {Symbol recognition in electrical diagrams using probabilistic graph matching},
 url = {http://www.sciencedirect.com/science/article/pii/0167865585900662},
 pages = {343--350},
 volume = {3},
 number = {5},
 issn = {0167-8655},
 journal = {Pattern Recognition Letters},
 doi = {10.1016/0167-8655(85)90066-2}
}


@misc{He.10.12.2015,
 abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57{\%} error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers.  The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28{\%} relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC {\&} COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
 author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
 date = {10.12.2015},
 title = {Deep Residual Learning for Image Recognition},
 url = {https://arxiv.org/pdf/1512.03385},
 file = {239623dc-ca5c-46ab-ab20-b2a5c6480106:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\239623dc-ca5c-46ab-ab20-b2a5c6480106.pdf:pdf}
}


@inproceedings{Holcomb.2018,
 author = {Holcomb, Sean D. and Porter, William K. and Ault, Shaun V. and Mao, Guifen and Wang, Jin},
 title = {Overview on DeepMind and Its AlphaGo Zero AI},
 pages = {67--71},
 publisher = {ACM},
 isbn = {9781450363587},
 editor = {Unknown},
 booktitle = {Proceedings of the 2018 International Conference on Big Data and Education},
 year = {2018},
 address = {[Place of publication not identified]},
 doi = {10.1145/3206157.3206174},
 file = {http://dl.acm.org/citation.cfm?doid=3206157}
}


@article{Howie.1998,
 abstract = {This paper describes a proof-of-concept computer system capable of interpreting graphical component connectivity in Process and Instrumentation Drawings (P{\&}IDs). The input drawing is a CAD file in DXF format (AutoCAD Release 12, Advanced Tools Manual, Autodesk Inc., 1993, Chapter 6). Drawing features are considered to be pipes or symbolic entities with geometrically constrained attachment ports. A low-level image processing front-end is currently being developed to support the interpretation of drawings in vector format from scanned paper P{\&}IDs. A hierarchical data structure is used to enable recognition of components in collinear and circuit complexes.},
 author = {Howie, C. and Kunz, J. and Binford, T. and Chen, T. and Law, K.H},
 year = {1998},
 title = {Computer interpretation of process and instrumentation drawings},
 url = {http://www.sciencedirect.com/science/article/pii/S0965997898000222},
 pages = {563--570},
 volume = {29},
 number = {7-9},
 issn = {0965-9978},
 journal = {Advances in Engineering Software},
 doi = {10.1016/S0965-9978(98)00022-2}
}


@article{Katelhon.2019,
 abstract = {Chemical production is set to become the single largest driver of global oil consumption by 2030. To reduce oil consumption and resulting greenhouse gas (GHG) emissions, carbon dioxide can be captured from stacks or air and utilized as alternative carbon source for chemicals. Here, we show that carbon capture and utilization (CCU) has the technical potential to decouple chemical production from fossil resources, reducing annual GHG emissions by up to 3.5 Gt CO2-eq in 2030. Exploiting this potential, however, requires more than 18.1 PWh of low-carbon electricity, corresponding to 55{\%} of the projected global electricity production in 2030. Most large-scale CCU technologies are found to be less efficient in reducing GHG emissions per unit low-carbon electricity when benchmarked to power-to-X efficiencies reported for other large-scale applications including electro-mobility (e-mobility) and heat pumps. Once and where these other demands are satisfied, CCU in the chemical industry could efficiently contribute to climate change mitigation.},
 author = {K{\"a}telh{\"o}n, Arne and Meys, Raoul and Deutz, Sarah and Suh, Sangwon and Bardow, Andr{\'e}},
 year = {2019},
 title = {Climate change mitigation potential of carbon capture and utilization in the chemical industry},
 url = {https://www.pnas.org/content/116/23/11187},
 pages = {11187--11194},
 volume = {116},
 number = {23},
 issn = {1091-6490},
 journal = {Proceedings of the National Academy of Sciences},
 doi = {10.1073/pnas.1821029116},
 file = {68373e19-c0c1-4d4b-b149-b9c79e6cdfbb:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\68373e19-c0c1-4d4b-b149-b9c79e6cdfbb.pdf:pdf}
}


@article{LeCun.2015,
 abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
 author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
 year = {2015},
 title = {Deep learning},
 pages = {436--444},
 volume = {521},
 number = {7553},
 issn = {1476-4687},
 journal = {Nature},
 doi = {10.1038/nature14539},
 file = {080e2404-0970-4e84-aa99-64ad63367d57:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\080e2404-0970-4e84-aa99-64ad63367d57.pdf:pdf}
}


@article{Lee.1994,
 abstract = {In this paper, we present an efficient three-dimensional (3-D) parallel thinning algorithm for extracting both the medial surfaces and the medial axes of a 3-D object (given as a 3-D binary image). A new Euler table is derived to ensure the invariance of the Euler characteristic of the object, during thinning. An octree data structure of 3 $\times$ 3 $\times$ 3 lattice points is built to examine the local connectivity. The sets of {\textquotedbl}simple{\textquotedbl} points found by different researchers are compared with the constructed set. Different definitions of {\textquotedbl}surface{\textquotedbl} points including ours are given. By preserving the topological and the geometrical conditions, our algorithm produces desirable skeletons and performs better than others in terms of noise sensitivity and speed. Pre- and postprocessors can be used to remove additional noise spurs. Its use in defect analysis of objects produced by casting and forging is discussed.},
 author = {Lee, T. C. and Kashyap, R. L. and Chu, C. N.},
 year = {1994},
 title = {Building Skeleton Models via 3-D Medial Surface Axis Thinning Algorithms},
 url = {http://www.sciencedirect.com/science/article/pii/S104996528471042X},
 pages = {462--478},
 volume = {56},
 number = {6},
 issn = {1049-9652},
 journal = {CVGIP: Graphical Models and Image Processing},
 doi = {10.1006/cgip.1994.1042}
}


@misc{Lin.01.05.2014,
 abstract = {We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.},
 author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Bourdev, Lubomir and Girshick, Ross and Hays, James and Perona, Pietro and Ramanan, Deva and Zitnick, C. Lawrence and Doll{\'a}r, Piotr},
 date = {01.05.2014},
 title = {Microsoft COCO: Common Objects in Context},
 url = {https://arxiv.org/pdf/1405.0312},
 file = {b3728775-0e6a-46cc-a383-0e3d853d3d9b:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\b3728775-0e6a-46cc-a383-0e3d853d3d9b.pdf:pdf}
}


@misc{Lin.01.05.2014b,
 abstract = {We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.},
 author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Bourdev, Lubomir and Girshick, Ross and Hays, James and Perona, Pietro and Ramanan, Deva and Zitnick, C. Lawrence and Doll{\'a}r, Piotr},
 date = {01.05.2014},
 title = {Microsoft COCO: Common Objects in Context},
 url = {https://arxiv.org/pdf/1405.0312},
 file = {1fc0f66b-5191-48c0-af4d-789fbf3908b5:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\1fc0f66b-5191-48c0-af4d-789fbf3908b5.pdf:pdf}
}

@inproceedings{Lin.07.08.2017,
  title={Focal loss for dense object detection},
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  abstract = {The highest accuracy object detectors to date are based on a two-stage approach popularized by R-CNN, where a classifier is applied to a sparse set of candidate object locations. In contrast, one-stage detectors that are applied over a regular, dense sampling of possible object locations have the potential to be faster and simpler, but have trailed the accuracy of two-stage detectors thus far. In this paper, we investigate why this is the case. We discover that the extreme foreground-background class imbalance encountered during training of dense detectors is the central cause. We propose to address this class imbalance by reshaping the standard cross entropy loss such that it down-weights the loss assigned to well-classified examples. Our novel Focal Loss focuses training on a sparse set of hard examples and prevents the vast number of easy negatives from overwhelming the detector during training. To evaluate the effectiveness of our loss, we design and train a simple dense detector we call RetinaNet. Our results show that when trained with the focal loss, RetinaNet is able to match the speed of previous one-stage detectors while surpassing the accuracy of all existing state-of-the-art two-stage detectors.},
  pages={2980--2988},
  year={2017}
}

@misc{Lin.09.12.2016,
 abstract = {Feature pyramids are a basic component in recognition systems for detecting objects at different scales. But recent deep learning object detectors have avoided pyramid representations, in part because they are compute and memory intensive. In this paper, we exploit the inherent multi-scale, pyramidal hierarchy of deep convolutional networks to construct feature pyramids with marginal extra cost. A top-down architecture with lateral connections is developed for building high-level semantic feature maps at all scales. This architecture, called a Feature Pyramid Network (FPN), shows significant improvement as a generic feature extractor in several applications. Using FPN in a basic Faster R-CNN system, our method achieves state-of-the-art single-model results on the COCO detection benchmark without bells and whistles, surpassing all existing single-model entries including those from the COCO 2016 challenge winners. In addition, our method can run at 5 FPS on a GPU and thus is a practical and accurate solution to multi-scale object detection. Code will be made publicly available.},
 author = {Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
 date = {09.12.2016},
 title = {Feature Pyramid Networks for Object Detection},
 url = {https://arxiv.org/pdf/1612.03144},
 file = {https://arxiv.org/pdf/1612.03144v2.pdf},
 file = {bc450922-b927-4099-b56f-f525e283dfd0:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\bc450922-b927-4099-b56f-f525e283dfd0.pdf:pdf}
}


@misc{Lin.09.12.2016b,
 abstract = {Feature pyramids are a basic component in recognition systems for detecting objects at different scales. But recent deep learning object detectors have avoided pyramid representations, in part because they are compute and memory intensive. In this paper, we exploit the inherent multi-scale, pyramidal hierarchy of deep convolutional networks to construct feature pyramids with marginal extra cost. A top-down architecture with lateral connections is developed for building high-level semantic feature maps at all scales. This architecture, called a Feature Pyramid Network (FPN), shows significant improvement as a generic feature extractor in several applications. Using FPN in a basic Faster R-CNN system, our method achieves state-of-the-art single-model results on the COCO detection benchmark without bells and whistles, surpassing all existing single-model entries including those from the COCO 2016 challenge winners. In addition, our method can run at 5 FPS on a GPU and thus is a practical and accurate solution to multi-scale object detection. Code will be made publicly available.},
 author = {Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
 date = {09.12.2016},
 title = {Feature Pyramid Networks for Object Detection},
 url = {https://arxiv.org/pdf/1612.03144},
 file = {48bc8dd6-b4dd-48d6-bd9a-0b101631d96a:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\48bc8dd6-b4dd-48d6-bd9a-0b101631d96a.pdf:pdf}
}


@misc{Lin.09.12.2016c,
 abstract = {Feature pyramids are a basic component in recognition systems for detecting objects at different scales. But recent deep learning object detectors have avoided pyramid representations, in part because they are compute and memory intensive. In this paper, we exploit the inherent multi-scale, pyramidal hierarchy of deep convolutional networks to construct feature pyramids with marginal extra cost. A top-down architecture with lateral connections is developed for building high-level semantic feature maps at all scales. This architecture, called a Feature Pyramid Network (FPN), shows significant improvement as a generic feature extractor in several applications. Using FPN in a basic Faster R-CNN system, our method achieves state-of-the-art single-model results on the COCO detection benchmark without bells and whistles, surpassing all existing single-model entries including those from the COCO 2016 challenge winners. In addition, our method can run at 5 FPS on a GPU and thus is a practical and accurate solution to multi-scale object detection. Code will be made publicly available.},
 author = {Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
 date = {09.12.2016},
 title = {Feature Pyramid Networks for Object Detection},
 url = {https://arxiv.org/pdf/1612.03144},
 file = {afa3c84b-ce21-4c9d-8c92-a851e71be353:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\afa3c84b-ce21-4c9d-8c92-a851e71be353.pdf:pdf}
}


@inproceedings{Long.2015,
 author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
 title = {Fully Convolutional Networks for Semantic Segmentation},
 url = {https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Long_Fully_Convolutional_Networks_2015_CVPR_paper.html},
 pages = {3431--3440},
 year = {2015},
 file = {b2861e9f-c6b8-48f8-9a17-fe9258a68989:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\b2861e9f-c6b8-48f8-9a17-fe9258a68989.pdf:pdf}
}


@inproceedings{M.K.Gellaboina.2009,
 abstract = {Symbol recognition is a well-known problem in the field of graphics. A symbol can be defined as a structure within document that has a particular meaning in the context of the application. Due to their representational power, graph structures are usually used to represent line drawings images.An accurate vectorization constitutes a first approach to solve this goal. But vectorization only gives the segments constituting the document and their geometrical attributes.Interpreting a document such as P{\&}ID (Process {\&} Instrumentation)diagram requires an additional stage viz. recognition of symbols in terms of its shape. Usually a P{\&}ID diagram contain several types of elements, symbols and structural connectivity. For those symbols that can be defined by a prototype pattern, we propose an iterative learning strategy based on Hopfield model to learn the symbols, for subsequent recognition in the P{\&}ID diagram. In a typical shape recognition problem one has to account for transformation invariance. Here the transformation invariance is circumvented by using an iterative learning approach which can learn symbols with high degree of correlation.},
 author = {{M. K. Gellaboina} and {V. G. Venkoparao}},
 title = {Graphic Symbol Recognition Using Auto Associative Neural Network Model},
 pages = {297--301},
 booktitle = {2009 Seventh International Conference on Advances in Pattern Recognition},
 year = {2009},
 doi = {10.1109/ICAPR.2009.45}
}


@article{MorenoGarcia.2017,
 abstract = {PDF | The demand for digitisation of complex engineering drawings becomes increasingly important for the industry given the pressure to improve the... | Find, read and cite all the research you need on ResearchGate},
 author = {Moreno-Garc{\'i}a, Carlos Francisco and Elyan, Eyad and Jayne, Chrisina},
 year = {2017},
 title = {Heuristics-Based Detection to Improve Text/Graphics Segmentation in Complex Engineering Drawings},
 url = {https://www.researchgate.net/publication/317661972_Heuristics-Based_Detection_to_Improve_TextGraphics_Segmentation_in_Complex_Engineering_Drawings},
 pages = {87--98},
 volume = {744},
 issn = {1865-0929},
 journal = {Engineering Applications of Neural Networks 2017},
 doi = {10.1007/978-3-319-65172-9{\textunderscore }8},
 file = {b0e44901-2bd7-445b-b14f-31f635f91bdc:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\b0e44901-2bd7-445b-b14f-31f635f91bdc.pdf:pdf}
}


@article{MorenoGarcia.2019,
 abstract = {Engineering drawings are commonly used across different industries such as oil and gas, mechanical engineering and others. Digitising these drawings is becoming increasingly important. This is mainly due to the legacy of drawings and documents that may provide rich source of information for industries. Analysing these drawings often requires applying a set of digital image processing methods to detect and classify symbols and other components. Despite the recent significant advances in image processing, and in particular in deep neural networks, automatic analysis and processing of these engineering drawings is still far from being complete. This paper presents a general framework for complex engineering drawing digitisation. A thorough and critical review of relevant literature, methods and algorithms in machine learning and machine vision is presented. Real-life industrial scenario on how to contextualise the digitised information from specific type of these drawings, namely piping and instrumentation diagrams, is discussed in details. A discussion of how new trends on machine vision such as deep learning could be applied to this domain is presented with conclusions and suggestions for future research directions.},
 author = {Moreno-Garc{\'i}a, Carlos Francisco and Elyan, Eyad and Jayne, Chrisina},
 year = {2019},
 title = {New trends on digitisation of complex engineering drawings},
 pages = {1695--1712},
 volume = {31},
 number = {6},
 issn = {1433-3058},
 journal = {Neural Computing and Applications},
 doi = {10.1007/s00521-018-3583-1},
 file = {5f56d3ee-7761-47ce-bb1c-f3829583278d:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\5f56d3ee-7761-47ce-bb1c-f3829583278d.pdf:pdf}
}


@article{Okazaki.1988,
 abstract = {A high-performance logic circuit diagram reader was developed for VLSI-CAD data input. Almost all logic circuit symbols include one or more loop structures. A description is given of an efficient method for recognition of these loop-structured symbols. The proposed method consists of two processes: symbol segmentation and symbol identification. Symbol identification is achieved by a powerful hybrid method which uses heuristics to mediate between template matching and feature extraction. The entire symbol recognition process is carried out under a decision-tree control strategy. The entire recognition system for circuit diagrams is briefly explained, including character string recognition and connecting line analysis.{\textless}{\textgreater}},
 author = {Okazaki, A. and Kondo, T. and Tsunekawa, S. and Kawamoto, E.},
 year = {1988},
 title = {An automatic circuit diagram reader with loop-structure-based symbol recognition},
 pages = {331--341},
 volume = {10},
 number = {3},
 issn = {1939-3539},
 journal = {IEEE Transactions on Pattern Analysis \& Machine Intelligence},
 doi = {10.1109/34.3898}
}


@article{ontotext.com.06.04.2020,
 abstract = {The knowledge graph represents a collection of interlinked descriptions of entities -- real-world objects, events or abstract concepts. They put data in context via linking and semantic metadata and this way provide a framework for data integration, unification, analytics and sharing.},
 author = {ontotext.com},
 year = {06.04.2020},
 title = {What is a Knowledge Graph?},
 url = {https://www.ontotext.com/knowledgehub/fundamentals/what-is-a-knowledge-graph/},
 urldate = {29.11.2020},
 journal = {Ontotext AD}
}


@inproceedings{Opmanis.2018,
 author = {Opmanis, Rudolfs},
 title = {Optical Graph Edge Recognition},
 url = {https://www.scitepress.org/papers/2018/65504/65504.pdf},
 urldate = {22.11.2020},
 pages = {184--191},
 publisher = {{SCITEPRESS - Science and Technology Publications, Lda}},
 isbn = {978-989-758-289-9},
 editor = {Telea, Alexandru and Kerren, Andreas and Braz, Jose and VISIGRAPP},
 booktitle = {VISIGRAPP 2018},
 year = {2018},
 address = {[Set{\'u}bal, Portugal]},
 doi = {10.5220/0006550401840191},
 file = {278d9ebf-bdb5-4689-a0be-371506e15a49:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\278d9ebf-bdb5-4689-a0be-371506e15a49.pdf:pdf}
}


@article{Pham.2014,
 abstract = {In this paper, we present a new approach for junction detection and characterization in line-drawing images. We formulate this problem as searching for optimal meeting points of median lines. In this context, the main contribution of the proposed approach is three-fold. First, a new algorithm for the determination of the support region is presented using the linear least squares technique, making it robust to digitization effects. Second, an efficient algorithm is proposed to detect and conceptually remove all distorted zones, retaining reliable line segments only. These line segments are then locally characterized to form a local structure representation of each crossing zone. Finally, a novel optimization algorithm is presented to reconstruct the junctions. Junction characterization is then simply derived. The proposed approach is very highly robust to common geometry transformations and can resist a satisfactory level of noise/degradation. Furthermore, it works very efficiently in terms of time complexity and requires no prior knowledge of the document content. Extensive evaluations have been performed to validate the proposed approach using other baseline methods. An application of symbol spotting is also provided, demonstrating quite good results.},
 author = {Pham, The-Anh and Delalandre, Mathieu and Barrat, Sabine and Ramel, Jean-Yves},
 year = {2014},
 title = {Accurate junction detection and characterization in line-drawing images},
 url = {http://www.sciencedirect.com/science/article/pii/S0031320313002793},
 pages = {282--295},
 volume = {47},
 number = {1},
 issn = {0031-3203},
 journal = {Pattern Recognition},
 doi = {10.1016/j.patcog.2013.06.027}
}


@misc{Qian.30.05.2019,
 abstract = {Gender bias exists in natural language datasets which neural language models tend to learn, resulting in biased text generation. In this research, we propose a debiasing approach based on the loss function modification. We introduce a new term to the loss function which attempts to equalize the probabilities of male and female words in the output. Using an array of bias evaluation metrics, we provide empirical evidence that our approach successfully mitigates gender bias in language models without increasing perplexity. In comparison to existing debiasing strategies, data augmentation, and word embedding debiasing, our method performs better in several aspects, especially in reducing gender bias in occupation words. Finally, we introduce a combination of data augmentation and our approach, and show that it outperforms existing strategies in all bias evaluation metrics.},
 author = {Qian, Yusu and Muaz, Urwa and Zhang, Ben and Hyun, Jae Won},
 date = {30.05.2019},
 title = {Reducing Gender Bias in Word-Level Language Models with a  Gender-Equalizing Loss Function},
 url = {https://arxiv.org/pdf/1905.12801},
 file = {ff2721b6-0e90-41cf-a790-5de5c0e8ec2a:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\ff2721b6-0e90-41cf-a790-5de5c0e8ec2a.pdf:pdf}
}


@inproceedings{R.Padilla.2020,
 abstract = {This work explores and compares the plethora of metrics for the performance evaluation of object-detection algorithms. Average precision (AP),for instance, is a popular metric for evaluating the accuracy of object detectors by estimating the area under the curve (AUC) of the precision $\times$ recall relationship. Depending on the point interpolation used in the plot, two different AP variants can be defined and, therefore, different results are generated. AP has six additional variants increasing the possibilities of benchmarking. The lack of consensus in different works and AP implementations is a problem faced by the academic and scientific communities. Metric implementations written in different computational languages and platforms are usually distributed with corresponding datasets sharing a given bounding-box description. Such projects indeed help the community with evaluation tools, but demand extra work to be adapted for other datasets and bounding-box formats. This work reviews the most used metrics for object detection detaching their differences, applications, and main concepts. It also proposes a standard implementation that can be used as a benchmark among different datasets with minimum adaptation on the annotation files.},
 author = {{R. Padilla} and {S. L. Netto} and {E. A. B. da Silva}},
 title = {A Survey on Performance Metrics for Object-Detection Algorithms},
 pages = {237--242},
 isbn = {2157-8702},
 booktitle = {2020 International Conference on Systems, Signals and Image Processing (IWSSIP)},
 year = {2020},
 doi = {10.1109/IWSSIP48289.2020.9145130}
}


@misc{Redmon.08.06.2015.v1,
 abstract = {We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance.  Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is far less likely to predict false detections where nothing exists. Finally, YOLO learns very general representations of objects. It outperforms all other detection methods, including DPM and R-CNN, by a wide margin when generalizing from natural images to artwork on both the Picasso Dataset and the People-Art Dataset.},
 author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
 date = {08.06.2015},
 year = 2015,
 title = {You Only Look Once: Unified, Real-Time Object Detection},
 url = {https://arxiv.org/pdf/1506.02640},
 file = {534a287b-e7a4-4f80-a4d7-9d16f7f38114:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\534a287b-e7a4-4f80-a4d7-9d16f7f38114.pdf:pdf}
}

@inproceedings{Redmon.08.06.2015,
  title={You only look once: Unified, real-time object detection},
  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={779--788},
  year={2016}
}


@misc{Redmon.09.04.2018,
 abstract = {We present some updates to YOLO! We made a bunch of little design changes to make it better. We also trained this new network that's pretty swell. It's a little bigger than last time but more accurate. It's still fast though, don't worry. At 320x320 YOLOv3 runs in 22 ms at 28.2 mAP, as accurate as SSD but three times faster. When we look at the old .5 IOU mAP detection metric YOLOv3 is quite good. It achieves 57.9 mAP@50 in 51 ms on a Titan X, compared to 57.5 mAP@50 in 198 ms by RetinaNet, similar performance but 3.8x faster. As always, all the code is online at https://pjreddie.com/yolo/},
 author = {Redmon, Joseph and Farhadi, Ali},
 year = 2018,
 date = {09.04.2018},
 title = {YOLOv3: An Incremental Improvement},
 url = {https://arxiv.org/pdf/1804.02767},
 file = {https://arxiv.org/pdf/1804.02767v1.pdf},
 file = {ed529719-ee9a-417f-bc6b-e1ce4e37fd6e:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\ed529719-ee9a-417f-bc6b-e1ce4e37fd6e.pdf:pdf}
}

@article{farhadi2018yolov3,
  title={Yolov3: An incremental improvement},
  author={Farhadi, Ali and Redmon, Joseph},
  journal={Computer Vision and Pattern Recognition, cite as},
  year={2018}
}

@misc{Redmon.09.04.2018b.v1,
 abstract = {We present some updates to YOLO! We made a bunch of little design changes to make it better. We also trained this new network that's pretty swell. It's a little bigger than last time but more accurate. It's still fast though, don't worry. At 320x320 YOLOv3 runs in 22 ms at 28.2 mAP, as accurate as SSD but three times faster. When we look at the old .5 IOU mAP detection metric YOLOv3 is quite good. It achieves 57.9 mAP@50 in 51 ms on a Titan X, compared to 57.5 mAP@50 in 198 ms by RetinaNet, similar performance but 3.8x faster. As always, all the code is online at https://pjreddie.com/yolo/},
 author = {Redmon, Joseph and Farhadi, Ali},
 date = {09.04.2018},
 year = 2018,
 title = {YOLOv3: An Incremental Improvement},
 url = {https://arxiv.org/pdf/1804.02767},
 file = {fcd7ee9c-7cbd-4d9a-b8a9-5d642b9c028b:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\fcd7ee9c-7cbd-4d9a-b8a9-5d642b9c028b.pdf:pdf}
}

@article{Redmon.09.04.2018b,
  title={{YOLOV3}: An Incremental Improvement},
  author={Farhadi, Ali and Redmon, Joseph},
  journal={Computer Vision and Pattern Recognition, cite as},
  year={2018}
}

@misc{Redmon.09.04.2018c,
 abstract = {We present some updates to YOLO! We made a bunch of little design changes to make it better. We also trained this new network that's pretty swell. It's a little bigger than last time but more accurate. It's still fast though, don't worry. At 320x320 YOLOv3 runs in 22 ms at 28.2 mAP, as accurate as SSD but three times faster. When we look at the old .5 IOU mAP detection metric YOLOv3 is quite good. It achieves 57.9 mAP@50 in 51 ms on a Titan X, compared to 57.5 mAP@50 in 198 ms by RetinaNet, similar performance but 3.8x faster. As always, all the code is online at https://pjreddie.com/yolo/},
 author = {Redmon, Joseph and Farhadi, Ali},
 date = {09.04.2018},
 title = {YOLOv3: An Incremental Improvement},
 url = {https://arxiv.org/pdf/1804.02767.pdf},
 urldate = {21.11.2020},
 file = {e2416504-b208-4bd7-8b28-86bced5d9f8b:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\e2416504-b208-4bd7-8b28-86bced5d9f8b.pdf:pdf}
}


@misc{Redmon.25.12.2016,
 abstract = {We introduce YOLO9000, a state-of-the-art, real-time object detection system that can detect over 9000 object categories. First we propose various improvements to the YOLO detection method, both novel and drawn from prior work. The improved model, YOLOv2, is state-of-the-art on standard detection tasks like PASCAL VOC and COCO. At 67 FPS, YOLOv2 gets 76.8 mAP on VOC 2007. At 40 FPS, YOLOv2 gets 78.6 mAP, outperforming state-of-the-art methods like Faster RCNN with ResNet and SSD while still running significantly faster. Finally we propose a method to jointly train on object detection and classification. Using this method we train YOLO9000 simultaneously on the COCO detection dataset and the ImageNet classification dataset. Our joint training allows YOLO9000 to predict detections for object classes that don't have labelled detection data. We validate our approach on the ImageNet detection task. YOLO9000 gets 19.7 mAP on the ImageNet detection validation set despite only having detection data for 44 of the 200 classes. On the 156 classes not in COCO, YOLO9000 gets 16.0 mAP. But YOLO can detect more than just 200 classes; it predicts detections for more than 9000 different object categories. And it still runs in real-time.},
 author = {Redmon, Joseph and Farhadi, Ali},
 date = {25.12.2016},
 title = {YOLO9000: Better, Faster, Stronger},
 url = {https://arxiv.org/pdf/1612.08242},
 file = {59ae4396-e737-413b-8cc6-ef207f36031f:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\59ae4396-e737-413b-8cc6-ef207f36031f.pdf:pdf}
}


@misc{Ren.04.06.2015,
 abstract = {State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features---using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model, our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available.},
 author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
 date = {04.06.2015},
 title = {Faster R-CNN: Towards Real-Time Object Detection with Region Proposal  Networks},
 url = {https://arxiv.org/pdf/1506.01497},
 file = {https://arxiv.org/pdf/1506.01497v3.pdf},
 file = {c905b304-97c7-4a4c-9daf-463e1aa3ddd4:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\c905b304-97c7-4a4c-9daf-463e1aa3ddd4.pdf:pdf}
}


@article{Ren.2018,
 abstract = {Modern object detectors always include two major parts: a feature extractor and a feature classifier as same as traditional object detectors. The deeper and wider convolutional architectures are adopted as the feature extractor at present. However, many notable object detection systems such as Fast/Faster RCNN only consider simple fully connected layers as the feature classifier. In this paper, we declare that it is beneficial for the detection performance to elaboratively design deep convolutional networks (ConvNets) of various depths for feature classification, especially using the fully convolutional architectures. In addition, this paper also demonstrates how to employ the fully convolutional architectures in the Fast/Faster RCNN. Experimental results show that a classifier based on convolutional layer is more effective for object detection than that based on fully connected layer and that the better detection performance can be achieved by employing deeper ConvNets as the feature classifier.},
 author = {Ren, Yun and Zhu, Changren and Xiao, Shunping},
 year = {2018},
 title = {Object Detection Based on Fast/Faster RCNN Employing Fully Convolutional Architectures},
 url = {https://www.hindawi.com/journals/mpe/2018/3598316/},
 pages = {1--7},
 volume = {2018},
 issn = {1024-123X},
 journal = {Mathematical Problems in Engineering},
 doi = {10.1155/2018/3598316},
 file = {0e0d41dd-3f0c-4ddf-8b53-b48424deb9a8:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\0e0d41dd-3f0c-4ddf-8b53-b48424deb9a8.pdf:pdf}
}


@article{Russakovsky.2015,
 abstract = {The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5~years of the challenge, and propose future directions and improvements.},
 author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and Fei-Fei, Li},
 year = {2015},
 title = {ImageNet Large Scale Visual Recognition Challenge},
 pages = {211--252},
 volume = {115},
 number = {3},
 issn = {1573-1405},
 journal = {International Journal of Computer Vision},
 doi = {10.1007/s11263-015-0816-y},
 file = {a487c9ce-b69c-4193-b69b-e7edfbc0b9b3:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\a487c9ce-b69c-4193-b69b-e7edfbc0b9b3.pdf:pdf}
}


@article{Saha.2016,
 abstract = {Skeletonization provides an effective and compact representation of objects, which is useful for object description, retrieval, manipulation, matching, registration, tracking, recognition, and compression. It also facilitates efficient assessment of local object properties, e.g., scale, orientation, topology, etc. Several computational approaches are available in literature toward extracting the skeleton of an object, some of which are widely different in terms of their principles. In this paper, we present a comprehensive and concise survey of different skeletonization algorithms and discuss their principles, challenges, and benefits. Topology preservation, parallelization, and multi-scale skeletonization approaches are discussed. Finally, various applications of skeletonization are reviewed and the fundamental challenges of assessing the performance of different skeletonization algorithms are discussed.},
 author = {Saha, Punam K. and Borgefors, Gunilla and {Di Sanniti Baja}, Gabriella},
 year = {2016},
 title = {A survey on skeletonization algorithms and their applications},
 url = {http://www.sciencedirect.com/science/article/pii/S0167865515001233},
 pages = {3--12},
 volume = {76},
 issn = {0167-8655},
 journal = {Pattern Recognition Letters},
 doi = {10.1016/j.patrec.2015.04.006}
}


@book{Saha.2017,
 abstract = {Front Cover -- Skeletonization -- Copyright -- Contents -- Contributors -- About the Editors -- Preface -- Part 1 Theory and Methods -- 1 Skeletonization and its applications - a review -- 1.1 Introduction -- 1.1.1 Basic Concepts -- 1.1.2 Background -- 1.2 Different Approaches of Skeletonization -- 1.2.1 Geometric Approaches -- 1.2.2 Curve Propagation Approaches -- 1.2.3 Digital Approaches -- Quench Points -- 1.3 Topology Preservation -- 1.4 Pruning -- 1.5 Multiscale Skeletonization -- 1.6 Parallelization -- 1.6.1 Subiterative Parallelization Schemes -- 1.6.2 Parallelization Using Minimal Nonsimple Sets -- 1.6.3 Parallelization Using P-Simple Points -- 1.7 Applications -- 1.8 Performance Evaluation -- 1.9 Conclusions -- References -- 2 Multiscale 2D medial axes and 3D surface skeletons by the image foresting transform -- 2.1 Introduction -- 2.2 Related Work -- 2.2.1 Definitions -- 2.2.2 Skeleton Regularization -- 2.3 Proposed Method -- 2.3.1 Multiscale Regularization-Strengths and Weaknesses -- 2.3.2 Image Foresting Transform -- 2.3.2.1 Single-Point Feature Transform -- 2.3.2.2 Shortest-Path Length Computation -- 2.3.3 Multiscale Skeletonization-Putting It All Together -- 2.4 Comparative Analysis -- 2.4.1 2D Medial Axes -- 2.4.2 3D Medial Surfaces -- 2.4.2.1 Global Comparison -- 2.4.2.2 Detailed Comparison -- 2.5 Conclusion -- References -- 3 Fuzzy skeleton and skeleton by influence zones: a review -- 3.1 Introduction -- 3.2 Distance-Based Approaches -- 3.3 Morphological Approaches to Compute the Centers of Maximal Balls -- 3.4 Morphological Thinning -- 3.5 Fuzzy Skeleton of Influence Zones -- 3.5.1 Definition Based on Fuzzy Dilations -- 3.5.2 Definitions Based on Distances -- 3.5.3 Illustrative Example (Reproduced from [8]) -- 3.6 Conclusion -- References -- 4 Unified part-patch segmentation of mesh shapes using surface skeletons



4.1 Introduction -- 4.2 Related Work -- 4.2.1 Skeletonization -- 4.2.2 Shape Segmentation -- 4.2.2.1 Part-Based Segmentation -- 4.2.2.2 Patch-Based Segmentation -- 4.2.3 Summary of Challenges -- 4.3 Method -- 4.3.1 Preliminaries -- 4.3.2 Regularized Surface Skeleton Computation -- 4.3.3 Cut-Space Computation -- 4.3.4 Cut-Space Partitioning -- 4.3.4.1 Histogram Valley Detection -- 4.3.4.2 Histogram-Based Cut Space Partitioning -- 4.3.5 Partitioning the Full Surface Skeleton -- 4.3.6 Partition Projection to Surface -- 4.3.7 Part-Based Partition Refinement -- 4.3.8 Unified (Part and Patch) Segmentation -- 4.3.8.1 Patch-Type Segmentation Using Surface Skeletons -- 4.3.8.2 Unification Desirable Properties -- 4.3.8.3 Unification Method -- 4.4 Results -- 4.5 Discussion -- 4.6 Conclusion -- References -- 5 Improving the visual aspect of the skeleton and simplifying its structure -- 5.1 Introduction -- 5.2 Preliminary Notions and Definitions -- 5.3 Tools Improving the Visual Aspect of the Skeleton -- 5.3.1 Zig-zag Straightening -- 5.3.2 Fusion of Close Branch Points -- 5.3.3 Pruning -- 5.4 Experimental Results on the Improvement of Skeleton Visual Aspect -- 5.5 Tools to Simplify Skeleton Structure -- 5.5.1 Polygonal Approximation -- 5.5.2 Building a Linearized Version of the Skeleton -- 5.6 Experimental Results on the Simplification of Skeleton Structure -- 5.7 Conclusion -- References -- 6 Curve skeletonization using minimum-cost path -- 6.1 Introduction -- 6.2 General Principles of Curve Skeletonization -- 6.2.1 Geodesic Distance Transform Based Methods -- 6.2.2 Direct Methods -- 6.2.3 Minimum-Cost Path Based Methods -- 6.3 Curve Skeletonization with Minimum-Cost Path -- 6.3.1 Overall Outline -- 6.3.2 Minimum-Cost Path -- 6.3.3 Centered Minimum-Cost Paths -- 6.3.4 Skeletal Branch Detection -- 6.3.5 Object Volume Marking -- 6.3.6 Skeletal Branch Significance



6.3.7 Termination Criterion -- 6.3.8 Algorithm Efficiency -- 6.4 Applications -- 6.4.1 Virtual Colonoscopy and Bronchoscopy -- 6.4.2 Anatomical Labeling of Human Airway Trees -- 6.4.3 Morphologic Assessment of Pulmonary Arteries -- 6.5 Conclusions -- References -- 7 Parallel skeletonization algorithms in the cubic grid based on critical kernels -- 7.1 Introduction -- 7.2 Voxel Complexes and Simple Voxels -- 7.3 Critical Cliques -- 7.4 Decreasing Rank Strategy -- 7.5 Asymmetric Thinning -- 7.5.1 Generic Parallel Asymmetric Thinning Scheme -- 7.5.2 Isthmus-Based Asymmetric Thinning -- 7.5.3 Comparison with Other Parallel Curve Skeletonization Methods -- 7.6 Symmetric Thinning -- 7.6.1 Generic Parallel Symmetric Thinning Scheme -- 7.6.2 Isthmus-Based Symmetric Thinning -- 7.7 Characterization of Critical Cliques and k-Isthmuses -- 7.8 Isthmus Persistence and Skeleton Filtering -- 7.9 Hierarchies of Skeletons -- 7.10 Complexity -- 7.11 Conclusion -- References -- 8 Critical kernels, minimal nonsimple sets, and hereditarily simple sets in binary images on n-dimensional polytopal complexes -- 8.1 Introduction -- 8.1.1 Background and Prior Work -- 8.1.2 Contributions of This Chapter -- 8.2 Preliminaries: Complexes, Polyhedra, and Binary Images -- 8.2.1 Convex Polytopes -- 8.2.2 Complexes and Pure Complexes -- 8.2.3 Polyhedra -- 8.2.4 Binary Images on Pure Polytopal Complexes -- 8.3 Nonempty Topologically Simple (NETS) Polyhedra -- 8.3.1 Properties of NETS Polyhedra -- 8.3.2 The Axioms That Specify NETS Polyhedra -- 8.3.3 In a Strongly Normal Collection of Nonempty Convex Polytopes, the Union of Any Element with Its Neighbors Is NETS -- 8.3.4 Possible Definitions of NETS Polyhedra Using Homology Groups -- 8.4 Consequences of the NETS Axioms -- 8.4.1 A 0- or 1-Dimensional Complex Is NETS Just If It Is a Tree



8.4.2 Collapsible Polyhedra Are NETS, and NETS Polyhedra Never Collapse to Non-NETS Polyhedra -- 8.4.3 A Polyhedron in the Plane or in the Boundary of a 3-Dimensional Convex Polytope Is NETS If and Only If It Is Collapsible -- 8.5 Simple, Hereditarily Simple, and Minimal Nonsimple Sets -- 8.5.1 Simple 1s, Attachment Complexes, and Attachment Sets -- 8.5.2 Definitions and Basic Properties of Simple, Hereditarily Simple, and Minimal Nonsimple Sets -- 8.6 Cliques, Cores, and the Critical Kernel -- 8.6.1 I-Induced Cliques and I-Essential Cells -- 8.6.2 I-Cores -- 8.6.3 I-Regular and I-Critical Cells -- the Critical Kernel of I -- 8.7 Characterizations of P-Simple 1s, Hereditarily Simple Sets, and Minimal Nonsimple Sets -- 8.8 A Proof of Theorem 8.5.5 and a Second Proof of the {\textquotedbl}If{\textquotedbl} Part of Theorem 8.7.1 Based on NETS-Collapsing -- 8.8.1 NETS-Collapsing and a Proof of Theorem 8.5.5 -- 8.8.2 I-Essential Complexes and Another Proof of the {\textquotedbl}If{\textquotedbl} Part of Theorem 8.7.1 -- 8.9 Concluding Remarks -- References -- Part 2 Applications -- 9 Skeletonization in natural images and its application to object recognition -- 9.1 Introduction -- 9.2 Related Works -- 9.3 Methodology -- 9.3.1 Network Architecture -- 9.3.2 Skeleton Extraction by Fusing Scale-Associated Side Output -- 9.3.2.1 Training Phase -- 9.3.2.2 Testing Phase -- 9.3.3 Understanding of the Proposed Method -- 9.4 Experimental Results -- 9.4.1 Implementation Details -- 9.4.2 Performance Comparison -- 9.4.2.1 Evaluation Protocol -- 9.4.2.2 SK506 -- 9.4.2.3 WH-SYMMAX -- 9.4.2.4 SYMMAX300 -- 9.4.2.5 Cross Dataset Generalization -- 9.4.2.6 Symmetric Part Segmentation -- 9.4.2.7 Object Proposal Detection -- 9.4.2.8 Road Detection -- 9.4.2.9 Text Line Proposal Generation -- 9.5 Conclusion -- Acknowledgments -- References



10 Characterization of trabecular bone plate-rod micro-architecture using skeletonization and digital topologic and geometric analysis -- 10.1 Introduction -- 10.2 Definitions and Notations -- 10.3 Skeletonization -- 10.4 Digital Topological Analysis -- 10.4.1 Surface-Surface Junction Line Extension -- 10.4.2 Detection of Junction Voxels Between Surfaces and Curves -- 10.5 Volumetric Topological Analysis -- 10.5.1 Geodesic Distance Transform -- 10.5.2 Feature Propagation and Representative -- 10.5.3 Applications -- 10.6 Conclusion -- References -- 11 Medial structure generation for registration of anatomical structures -- 11.1 Medial Maps for Reliable Extraction of Anatomical Medial Surfaces -- 11.2 Extracting Anatomical Medial Surfaces Using Medialness Maps -- 11.2.1 Gaussian Steerable Medial Maps -- 11.2.1.1 Nonmaxima Suppression Binarization -- 11.2.1.2 Parameter Setting -- 11.3 Validation Framework for Medial Anatomy Assessment -- 11.3.1 Synthetic Database -- 11.3.2 Medial Surface Quality Metrics -- 11.4 Validation Experiments -- 11.4.1 Medial Surface Quality -- 11.4.2 Reconstruction Power for Clinical Applications -- 11.5 Application to Cochlea Registration -- 11.5.1 Material and Methods -- 11.5.2 Skeletonization -- 11.5.3 Image Registration -- 11.5.3.1 Initial Rigid Alignment -- 11.5.3.2 Deformable Registration -- 11.5.3.3 Deformable Registration with Guidance from Skeleton -- 11.5.4 Evaluation -- 11.5.5 Results -- 11.6 Discussion -- Acknowledgments -- References -- 12 Skeleton-based fast, fully automated generation of vessel tree structure for clinical evaluation of blood vessel systems -- 12.1 Introduction -- 12.2 Medical Context -- 12.2.1 Clinical Evaluation of the Peripheral Arterial System -- 12.2.2 Need for Image Postprocessing -- 12.3 Background -- 12.3.1 Previous Methods -- 12.3.2 From Colon to Blood Vessels



12.4 Fast Skeleton-Based Generation of the Centerline Tree},
 year = {2017},
 title = {Skeletonization: Theory, Methods and Applications},
 address = {Saint Louis},
 publisher = {{Elsevier Science}},
 isbn = {978-0-08-101291-8},
 editor = {Saha, Punam K. and Borgefors, Gunilla and {Di Baja}, Gabriella Sanniti}
}


@incollection{Saha.2017b,
 abstract = {Skeletonization provides a compact yet effective representation of 2-D and 3-D objects, which is useful in many low- and high-level image-related tasks including object representation, retrieval, manipulation, matching, registration, tracking, recognition, and compression. Also, it facilitates efficient characterization of topology, geometry, scale, and other related local properties of an object. Despite that the notion of skeletonization is well defined in a continuous space, in the discrete world of image processing and computer vision, it is not, and, therefore, it is more often described using procedural approaches. Several computational approaches are available in the literature for extracting the skeleton of an object, some of which are widely different even at the level of their basic principles. In this chapter, we present a comprehensive and concise survey of different skeletonization principles and algorithms and discuss their properties, challenges, and benefits. Different important aspects of skeletonization, namely, topology preservation, skeleton simplification and pruning, multiscale skeletonization, and parallelization are discussed. Finally, various applications of skeletonization are reviewed, and the fundamental issues related to the analysis of performance of different skeletonization algorithms are debated.},
 author = {Saha, Punam K. and Borgefors, Gunilla and {Di Sanniti Baja}, Gabriella},
 title = {Chapter 1 - Skeletonization and its applications -- a review},
 url = {http://www.sciencedirect.com/science/article/pii/B978008101291800002X},
 pages = {3--42},
 publisher = {{Elsevier Science}},
 isbn = {978-0-08-101291-8},
 editor = {Saha, Punam K. and Borgefors, Gunilla and {Di Baja}, Gabriella Sanniti},
 booktitle = {Skeletonization},
 year = {2017},
 address = {Saint Louis},
 doi = {10.1016/B978-0-08-101291-8.00002-X}
}


@article{ShaoqingRen.v1,
 abstract = {Neural Information Processing Systems http://nips.cc/},
 author = {{Shaoqing Ren} and {Kaiming He} and {Ross Girshick} and {Jian Sun}},
 title = {Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
 url = {https://proceedings.neurips.cc/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf},
 urldate = {11.11.2020},
 file = {c00982f6-53b3-4daa-864f-bda43512f1ef:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\c00982f6-53b3-4daa-864f-bda43512f1ef.pdf:pdf}
}

@article{ShaoqingRen.,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={39},
  number={6},
  pages={1137--1149},
  year={2016},
  publisher={IEEE}
}


@article{Shorten.2019,
 abstract = {Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.},
 author = {Shorten, Connor and Khoshgoftaar, Taghi M.},
 year = {2019},
 title = {A survey on Image Data Augmentation for Deep Learning},
 pages = {1--48},
 volume = {6},
 number = {1},
 issn = {2196-1115},
 journal = {Journal of Big Data},
 doi = {10.1186/s40537-019-0197-0},
 file = {b05fac31-8c17-4640-bd0e-d7e91a74ceb7:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\b05fac31-8c17-4640-bd0e-d7e91a74ceb7.pdf:pdf}
}


@proceedings{Telea.2018,
 year = {2018},
 title = {VISIGRAPP 2018: Proceedings of the 13th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications : Funchal, Madeira, Portugal, January 27-29, 2018},
 address = {[Set{\'u}bal, Portugal]},
 publisher = {{SCITEPRESS - Science and Technology Publications, Lda}},
 isbn = {978-989-758-289-9},
 editor = {Telea, Alexandru and Kerren, Andreas and Braz, Jose and VISIGRAPP},
 institution = {{International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications} and VISIGRAPP and {International Conference on Information Visualization Theory and Applications} and IVAPP}
}


@misc{Tzutalin.2015,
 author = {Tzutalin},
 year = {2015},
 title = {LabelImg},
 url = {https://github.com/tzutalin/labelImg},
 publisher = {{Git code}}
}


@proceedings{Unknown.2018,
 year = {2018},
 title = {Proceedings of the 2018 International Conference on Big Data and Education},
 address = {[Place of publication not identified]},
 publisher = {ACM},
 isbn = {9781450363587},
 editor = {Unknown},
 doi = {10.1145/3206157}
}


@article{Venkatasubramanian.2019,
 abstract = {Click on the article title to read more.UR  - https://aiche.onlinelibrary.wiley.com/doi/full/10.1002/aic.16489},
 author = {Venkatasubramanian, Venkat},
 year = {2019},
 title = {The promise of artificial intelligence in chemical engineering: Is it here, finally?},
 pages = {466--478},
 volume = {65},
 number = {2},
 issn = {00011541},
 journal = {AIChE Journal},
 doi = {10.1002/aic.16489},
 file = {1e88eff7-527d-4924-8792-e6062e101cf6:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\1e88eff7-527d-4924-8792-e6062e101cf6.pdf:pdf}
}


@misc{Wiesner.,
 abstract = {Wiesner, Andreas; Morbach, Jan; Marquardt, Wolfgang},
 author = {Wiesner, Andreas and Marquardt, Wolfgang and Morbach, Jan},
 date = {2007},
 title = {An overview on OntoCAPE and its latest applications},
 number = {RWTH-CONV-187349},
 series = {Lehrstuhl f{\"u}r ProzesstechnikUR  - https://publications.rwth-aachen.de/record/115750},
 institution = {{American Institute of Chemical Engineering}}
}


@article{Yu.2019,
 abstract = {PDF | A piping and instrumentation diagram (P{\&}ID) is a key drawing widely used in the energy industry. In a digital P{\&}ID, all included objects are... | Find, read and cite all the research you need on ResearchGate},
 author = {Yu and Cha and Lee and Kim and Mun},
 year = {2019},
 title = {Features Recognition from Piping and Instrumentation Diagrams in Image Format Using a Deep Learning Network},
 url = {https://www.researchgate.net/publication/337453727_Features_Recognition_from_Piping_and_Instrumentation_Diagrams_in_Image_Format_Using_a_Deep_Learning_Network},
 pages = {4425},
 volume = {12},
 number = {23},
 issn = {1996-1073},
 journal = {Energies},
 doi = {10.3390/en12234425},
 file = {8a134326-fa3d-4582-b450-b6d6af83318d:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\8a134326-fa3d-4582-b450-b6d6af83318d.pdf:pdf}
}


@article{Yu.2019b,
 abstract = {A piping and instrumentation diagram (P{\&}ID) is a key drawing widely used in the energy industry. In a digital P{\&}ID, all included objects are classified and made amenable to computerized data management. However, despite being widespread, a large number of P{\&}IDs in the image format still in use throughout the process (plant design, procurement, construction, and commissioning) are hampered by difficulties associated with contractual relationships and software systems. In this study, we propose a method that uses deep learning techniques to recognize and extract important information from the objects in the image-format P{\&}IDs. We define the training data structure required for developing a deep learning model for the P{\&}ID recognition. The proposed method consists of preprocessing and recognition stages. In the preprocessing stage, diagram alignment, outer border removal, and title box removal are performed. In the recognition stage, symbols, characters, lines, and tables are detected. The objects for recognition are symbols, characters, lines, and tables in P{\&}ID drawings. A new deep learning model for symbol detection is defined using AlexNet. We also employ the connectionist text proposal network (CTPN) for character detection, and traditional image processing techniques for P{\&}ID line and table detection. In the experiments where two test P{\&}IDs were recognized according to the proposed method, recognition accuracies for symbol, characters, and lines were found to be 91.6{\%}, 83.1{\%}, and 90.6{\%} on average, respectively.},
 author = {Yu and Cha and Lee and Kim and Mun},
 year = {2019},
 title = {Features Recognition from Piping and Instrumentation Diagrams in Image Format Using a Deep Learning Network},
 url = {https://www.mdpi.com/1996-1073/12/23/4425},
 pages = {4425},
 volume = {12},
 number = {23},
 issn = {1996-1073},
 journal = {Energies},
 doi = {10.3390/en12234425},
 file = {527e2eb6-2ce9-41ae-931e-211e9dd93e19:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\527e2eb6-2ce9-41ae-931e-211e9dd93e19.pdf:pdf}
}


@article{Yu.2019c,
 abstract = {A piping and instrumentation diagram (P{\&}ID) is a key drawing widely used in the energy industry. In a digital P{\&}ID, all included objects are classified and made amenable to computerized data management. However, despite being widespread, a large number of P{\&}IDs in the image format still in use throughout the process (plant design, procurement, construction, and commissioning) are hampered by difficulties associated with contractual relationships and software systems. In this study, we propose a method that uses deep learning techniques to recognize and extract important information from the objects in the image-format P{\&}IDs. We define the training data structure required for developing a deep learning model for the P{\&}ID recognition. The proposed method consists of preprocessing and recognition stages. In the preprocessing stage, diagram alignment, outer border removal, and title box removal are performed. In the recognition stage, symbols, characters, lines, and tables are detected. The objects for recognition are symbols, characters, lines, and tables in P{\&}ID drawings. A new deep learning model for symbol detection is defined using AlexNet. We also employ the connectionist text proposal network (CTPN) for character detection, and traditional image processing techniques for P{\&}ID line and table detection. In the experiments where two test P{\&}IDs were recognized according to the proposed method, recognition accuracies for symbol, characters, and lines were found to be 91.6{\%}, 83.1{\%}, and 90.6{\%} on average, respectively.},
 author = {Yu and Cha and Lee and Kim and Mun},
 year = {2019},
 title = {Features Recognition from Piping and Instrumentation Diagrams in Image Format Using a Deep Learning Network},
 url = {https://www.mdpi.com/1996-1073/12/23/4425},
 pages = {4425},
 volume = {12},
 number = {23},
 issn = {1996-1073},
 journal = {Energies},
 doi = {10.3390/en12234425},
 file = {e26878ea-a612-4b59-ac2d-3710ec7c8b8f:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\e26878ea-a612-4b59-ac2d-3710ec7c8b8f.pdf:pdf}
}


@article{Zhang.1984b,
 author = {Zhang, T. Y. and Suen, C. Y.},
 year = {1984},
 title = {A fast parallel algorithm for thinning digital patterns},
 pages = {236--239},
 volume = {27},
 number = {3},
 issn = {0001-0782},
 journal = {Communications of the ACM},
 doi = {10.1145/357994.358023}
}


@article{Zhang.2019,
 abstract = {By recognizing similarities in flowsheets, engineers can understand ways in which to improve the design and efficiency of chemical processes. However, there is no prior literature on how to compare...},
 author = {Zhang, Tong and Sahinidis, Nikolaos V. and Siirola, Jeffrey J.},
 year = {2019},
 title = {Pattern recognition in chemical process flowsheets},
 url = {https://aiche.onlinelibrary.wiley.com/doi/full/10.1002/aic.16443},
 pages = {592--603},
 volume = {65},
 number = {2},
 issn = {00011541},
 journal = {AIChE Journal},
 doi = {10.1002/aic.16443},
 file = {7017797d-cc1f-4f70-b45f-4b7184174986:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\7017797d-cc1f-4f70-b45f-4b7184174986.pdf:pdf}
}


@misc{Zhao.15.07.2018.v1,
 abstract = {Due to object detection's close relationship with video analysis and image understanding, it has attracted much research attention in recent years. Traditional object detection methods are built on handcrafted features and shallow trainable architectures. Their performance easily stagnates by constructing complex ensembles which combine multiple low-level image features with high-level context from object detectors and scene classifiers. With the rapid development in deep learning, more powerful tools, which are able to learn semantic, high-level, deeper features, are introduced to address the problems existing in traditional architectures. These models behave differently in network architecture, training strategy and optimization function, etc. In this paper, we provide a review on deep learning based object detection frameworks. Our review begins with a brief introduction on the history of deep learning and its representative tool, namely Convolutional Neural Network (CNN). Then we focus on typical generic object detection architectures along with some modifications and useful tricks to improve detection performance further. As distinct specific detection tasks exhibit different characteristics, we also briefly survey several specific tasks, including salient object detection, face detection and pedestrian detection. Experimental analyses are also provided to compare various methods and draw some meaningful conclusions. Finally, several promising directions and tasks are provided to serve as guidelines for future work in both object detection and relevant neural network based learning systems.},
 author = {Zhao, Zhong-Qiu and Zheng, Peng and Xu, Shou-tao and Wu, Xindong},
 date = {15.07.2018},
 year = 2018,
 title = {Object Detection with Deep Learning: A Review},
 url = {https://arxiv.org/pdf/1807.05511},
 file = {a8409203-c973-4960-9884-1d357df6c182:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\a8409203-c973-4960-9884-1d357df6c182.pdf:pdf}
}


@article{Zhao.15.07.2018,
  title={Object detection with deep learning: A review},
  author={Zhao, Zhong-Qiu and Zheng, Peng and Xu, Shou-tao and Wu, Xindong},
  journal={IEEE transactions on neural networks and learning systems},
  volume={30},
  number={11},
  pages={3212--3232},
  year={2019},
  publisher={IEEE}
}


@misc{Zoph.26.06.2019,
 abstract = {Data augmentation is a critical component of training deep learning models. Although data augmentation has been shown to significantly improve image classification, its potential has not been thoroughly investigated for object detection. Given the additional cost for annotating images for object detection, data augmentation may be of even greater importance for this computer vision task. In this work, we study the impact of data augmentation on object detection. We first demonstrate that data augmentation operations borrowed from image classification may be helpful for training detection models, but the improvement is limited. Thus, we investigate how learned, specialized data augmentation policies improve generalization performance for detection models. Importantly, these augmentation policies only affect training and leave a trained model unchanged during evaluation. Experiments on the COCO dataset indicate that an optimized data augmentation policy improves detection accuracy by more than +2.3 mAP, and allow a single inference model to achieve a state-of-the-art accuracy of 50.7 mAP. Importantly, the best policy found on COCO may be transferred unchanged to other detection datasets and models to improve predictive accuracy. For example, the best augmentation policy identified with COCO improves a strong baseline on PASCAL-VOC by +2.7 mAP. Our results also reveal that a learned augmentation policy is superior to state-of-the-art architecture regularization methods for object detection, even when considering strong baselines. Code for training with the learned policy is available online at https://github.com/tensorflow/tpu/tree/master/models/official/detection},
 author = {Zoph, Barret and Cubuk, Ekin D. and Ghiasi, Golnaz and Lin, Tsung-Yi and Shlens, Jonathon and {Le V}, Quoc},
 date = {26.06.2019},
 title = {Learning Data Augmentation Strategies for Object Detection},
 url = {https://arxiv.org/pdf/1906.11172},
 file = {76614aae-9f37-46b5-82d9-d89c9f2d7373:C\:\\Users\\Maximilian Theisen\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\hdqwmkg840xn3q2ecg4ok9rtucd1vh9chq0lynm6y0xlyh6x33\\Citavi Attachments\\76614aae-9f37-46b5-82d9-d89c9f2d7373.pdf:pdf}
}

@inproceedings{mahajan2018exploring,
  title={Exploring the limits of weakly supervised pretraining},
  author={Mahajan, Dhruv and Girshick, Ross and Ramanathan, Vignesh and He, Kaiming and Paluri, Manohar and Li, Yixuan and Bharambe, Ashwin and van der Maaten, Laurens},
  LONGbooktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  booktitle={Europ. Conf. Computer Vision (ECCV)},
  pages={181--196},
  year={2018}
}

@article{nentwig2017survey,
  title={A survey of current link discovery frameworks},
  author={Nentwig, Markus and Hartung, Michael and Ngonga Ngomo, Axel-Cyrille and Rahm, Erhard},
  journal={Semantic Web},
  volume={8},
  number={3},
  pages={419--436},
  year={2017},
  publisher={IOS Press}
}

@article{kopcke2010frameworks,
  title={Frameworks for entity matching: A comparison},
  author={K{\"o}pcke, Hanna and Rahm, Erhard},
  journal={Data \& Knowledge Engineering},
  volume={69},
  number={2},
  pages={197--210},
  year={2010},
  publisher={Elsevier}
}

